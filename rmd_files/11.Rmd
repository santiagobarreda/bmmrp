\newpage
```{r, include = FALSE}
knitr::opts_chunk$set(
  dpi = 300, dev = "jpeg", collapse=TRUE
)
```
# Multiple quantitative predictors, dealing with large models, and Bayesian ANOVA

In this chapter we introduce models with multiple continuous predictors, and interactions between them. After that, we will have covered the modeling concepts necessary to fit most models of the sort used for experimental data. The models you fit to you own data will include some combination of the elements covered in the previous chapters, and can potentially result in large models with hundreds of parameters. Traditionally, models with many predictors have had three general problems:

  1) A model may return spurious values for the 'extra' predictors, leading to incorrect conclusions.
  2) The model may not fit/converge, meaning you can't get the model coefficients. 
  3) It can be difficult to interpret a model with *hundreds* of parameters.

In this chapter we're going to cover a Bayesian approach to working with large models. We're going to discuss how working with multilevel Bayesian models can naturally help us with problems (1) and (2) above, and we're going to discuss an easy way to approach the third problem also. 
  Before continuing, we should note that designs with many continuous predictors, factors, and interactions between these can result in very complicated models, which then have to be interpreted. However, the researcher has a big role to play in the complexity of the eventual analysis that they are faced with. Once when Santiago was buying a backpack for traveling, he was looking for the biggest backpack possible. One of the reviews said "1/5 stars, it was way too heavy when I filled it all the way up with my stuff". However, if we fill a backpack up with heavy things, it doesn't seem fair to blame the poor backpack when it becomes difficult to manage, does it? In the same way, if you are faced with a complex model that you then need to interpret, you shouldn't blame the model (or `brms`) for your predicament. In order to avoid a situation where you end up with data you can't analyze or a model you don't know how to interpret, it's worth considering the following questions before advancing to data collection stage of your experiment: 

  * How will I analyze the data? Will I be able to? 
  * What will the model structure be? 
  * What would different results 'mean'? How will this manifest in my regression model?
  * What kind of results am I expecting? 
  
## Models with multiple continuous predictors

- make clear each predictor is a dimension
- check out what Ive said about dimensions before

Our regressions so far have only involved a single quantitative predictor. This means that the relationship between the dependent variable and our predictor formed shapes with a single dimension: Lines. In the left and middle plots in figure \@ref(fig:11_1) we see the linear relationships between speaker vocal-tract length (VTL), and f0 (voice pitch), with apparent speaker height. In each case, the expected value for the y-axis variable is the value of the line at each x-axis location. The residual, that is the prediction error, for each observation is the vertical distance between the line the observation.   
  Rather than think of the effect of VTL and f0 on apparent height individually, we can think about apparent height, VTL, and f0 together at the same time. We can imagine that each point in figure \@ref(fig:11_1) has a specific value of f0, VTL, and apparent height. These three quantitative variables define a specific location in a 3-dimensional space. For example, consider any given location in the room you are sitting in right now. Any such location can be specified using a variable that determines is location along the width, depth, and height of the room. Imagine you had a clear plastic cube containing points arranged as in \@ref(fig:11_1) inside it, where each dimension along the cube represented one of the dimensions in the figure. Looking 'through' the cube at different orientations would result in arrangements just like the plots below. The first plot show the view through the VTL side, and the second plot shows the view down the f0 side, a 1/4 rotation of the cube. The final plot shows the view down through the top of the cube.  
  
```{r F11_1, fig.height = 3, fig.width = 8, fig.cap='(left). (middle). (right).', echo = FALSE}

###############################################################################
### Figure 11.1
###############################################################################

agg_data = aggregate (height~f0+vtl+C_v, data = bmmb::height_exp_old, FUN=mean)
agg_data = agg_data[nrow(agg_data):1,]

ptcex = agg_data[,4] - min(agg_data[,4])
ptcex = 1 + (ptcex / max(ptcex))*1.5

par (mfrow = c(1,3), mar = c(4,4,1,1))
plot (agg_data[,c(2,4)],pch=16,col = bmmb::cols[2:5][factor(agg_data[,3])], 
      cex=ptcex)
abline (lm(agg_data[,c(4)]~agg_data[,c(2)]),lwd=2,lty=2)
grid()
plot (agg_data[,c(1,4)],pch=16,col = bmmb::cols[2:5][factor(agg_data[,3])], cex=ptcex)
abline (lm(agg_data[,c(4)]~agg_data[,c(1)]),lwd=2,lty=2)
grid()

plot (agg_data[,c(1,2)],pch=16,col = bmmb::cols[2:5][factor(agg_data[,3])], 
      cex=ptcex)
grid()

```

It may be easier to see what we mean by considering figure \@ref(fig:11_2), which attempts to present our point in three dimensions. The left plot of figure \@ref(fig:11_2) corresponds to the left plot in figure \@ref(fig:11_1), while the right plot of figure \@ref(fig:11_2) corresponds to the middle plot in figure \@ref(fig:11_1). If we want to predict apparent height based on speaker f0 and VTL, that is basically asking: Can we predict the height of a point in our 3-dimensional space based on its x and y-axis location? 

```{r F11_2, fig.height = 5, fig.width = 8, fig.cap='A pairs plot of the continuous variables in our data, showing different sorts of relationships between our variables.', echo = FALSE}

################################################################################
### Figure 11.2
################################################################################
agg_data = aggregate (height~f0+vtl+C_v, data = bmmb::height_exp_old, FUN=mean)

par (mfrow = c(1,2), mar = c(0,1,0,2), oma = c(0,0,0,0))

tmp = agg_data[,c(2,1,4)]
s3d = scatterplot3d::scatterplot3d (tmp, color = bmmb::cols[2:5][factor(agg_data[,3])],
                     pch=16, angle = 55,type = "p",ylim=c(90,310), cex.symbols=rev(ptcex)*.9)
my.lm <- lm(height ~ f0+vtl, data = agg_data)

s3d = scatterplot3d::scatterplot3d (agg_data[,-3], color = bmmb::cols[2:5][factor(agg_data[,3])],
                     pch=16, angle = 55,type = "p",xlim=c(90,310), cex.symbols=rev(ptcex)*.9)
my.lm <- lm(height ~ f0+vtl, data = agg_data)
#s3d$plane3d(my.lm, col = 2)
```

When we have two quantitative predictors, our models predict values along **planes** rather than lines. For example, imagine the points in figure \@ref(fig:11_2) were floating in the room with you, arranged just as in the figure. You are given a large flat board (a *plane*) and asked to find the "best" position for the board. When we fit lines, we preferred those that tended to minimize the residuals, the y-axis distance of the points to the line. The same principle holds when we fit models with two (or more) quantitative predictors. A Regressions model that includes two continuous predictors tries to find the 'best' plane that passes through your points in the three-dimensional space. In general, the 'best' plane is the one that minimizes the distance from each point to the surface of the plane along the axis representing the dependent variable. Though it's a bit more complicated than this for multilevel models, this is still basically what's happening.  
  Planes are specified by three parameters, a slope for each dimensions and an intercept. In \@ref(11_1) we that the height of the plane along the $z$ axis is determined by an intercept ($a$) plus the product of the x-axis coordinate and its slope ($b$) and the product of the y-axis coordinate and its slope. When we fit a model that includes two quantitative predictors, the model represents the best planes using their $a$, $b$, and $c$ parameters. 
  
$$
\begin{equation}
z =  \mathrm{a} + \mathrm{b} \times x + \mathrm{c} \times y 
(\#eq:11.1)
\end{equation}
$$

  Just like our slope coefficients changed the slope of our lines, our slope coefficients now change the slope of our planes. Since the plane has two dimensions it has two slopes: A field can be downhill away from you, but also be up/downhill left to right. Our intercept coefficients will change the intercepts of our planes, sliding entire planes up/down without changing their slopes. An important aspect of the interpretation of our slope terms is that they are meant to reflect the effect of an independent change along one dimension. Another way to say this is that the slope of each predictor reflects the expected change according to that predictor when all other predictors are *held constant*. As a result, our models specifying planes can also be thought of a series of models specifying lines, as will be discussed below. 
  Our discussion above has been entirely about planes, however, your model can include any number of continuous predictors. The interpretation of these models is a simple continuation of the expansion of models specifying lines to those specifying planes. If your model has $n$ continuous predictors, your data specifies points in an $n+1$ dimensional space, where dimension $n+1$ represents the dependent variable. Residuals in such models would represent the difference between the surface of the $n$ dimensional shape specified by the predictors and the position of each point along the $n+1$ dimension.
  
### Interactions between continuous predictors

Imagine you are standing on a flat cement plaza (a plane). There is a design defect such that as you walk across the plaza, the floor becomes slightly sloped left to right. Further, as you walk across the plaza, the floor becomes progressively more sloped to one side. Rather than a plane, the shape of the floor of this plaza would be a **hyperbolic parabaloid**, more commonly known as a **saddle** shape (because of its resemblance to a horse saddle). The function for a saddle shape can be seen below, where the height of the surface is equal to the product of its $x$ and $y$ coordinates. 

$$
\begin{equation}
z =  x \times y 
(\#eq:11.2)
\end{equation}
$$

In figure \@ref(fig:11_3) we can see a comparison of a plane and two saddle shapes. In the middle left plot we can see the analogy of the plaza with the sloping floor. If we were walking "into" the plot the ground would first be sloping down left to right, but gradually changes so that it it sloping up left to right by the end of the surface. 

```{r F11_3, fig.height = 6, fig.width = 8, fig.cap='A pairs plot of the continuous variables in our data, showing different sorts of relationships between our variables.', echo = FALSE}

################################################################################
### Figure 11.3
################################################################################

f1 = function (a,b,c) a * 1 + b *1  
f2 = function (a,b,c) a*b*2
f3 = function (a,b,c) a * 1 + b *1 + a*b*2

x <- y <- seq(-1, 1, length= 12)

par (mfrow = c(3,3), mar = c(1,1,0,0), oma = c(0,0,0,0))

z <- outer(x, y, f1)
persp(x, y, z, col = bmmb::cols[2],theta = 0,zlim = c(-3,3))
persp(x, y, z, col = bmmb::cols[2],theta = -90,zlim = c(-3,3))
persp(x, y, z, col = bmmb::cols[2],theta = 45,zlim = c(-3,3))

z <- outer(x, y, f2)
persp(x, y, z, col = bmmb::cols[3],theta = 0,zlim = c(-3,3))
persp(x, y, z, col = bmmb::cols[3],theta = -90,zlim = c(-3,3))
persp(x, y, z, col = bmmb::cols[3],theta = 45,zlim = c(-3,3))

z <- outer(x, y, f3)
persp(x, y, z, col = bmmb::cols[4],theta = 0,zlim = c(-3,5))
persp(x, y, z, col = bmmb::cols[4],theta = -90,zlim = c(-3,5))
persp(x, y, z, col = bmmb::cols[4],theta = 45,zlim = c(-3,5))

```

We can combine a plane and a saddle shape, as in the bottom row of figure \@ref(fig:11_3). The general formula for such a shape is presented below, and we've placed the terms in parentheses just to make it easier to interpret the equation. 

$$
\begin{equation}
z =  \mathrm{a} + (\mathrm{b} \times x) + (\mathrm{c} \times y) + (\mathrm{d} \times xy)
(\#eq:11.3)
\end{equation}
$$

What does any of this mean for our regression models? We discussed above that models with two continuous predictors model variation in the dependent variable along planes. The 'interaction' between quantitative variables in regression models is represented by the **cross-product**, the multiple, of the two variables. So, the interaction of quantitative predictors results in a saddle shape as defined in \@ref(eq:11_2). When our models include effects for $x$, $y$, *and* their interactions, we are effectively modeling a surface that combined a plane and a saddle shape, as in \@ref(eq:11_3). 

Interaction terms represent conditional effects, and allow for the effect of a predictor to vary according to the value of some other predictor. When it comes to quantitative predictors, if two predictors interact it means that the slope of a predictor continuously increase/decreases as a function of the value of the other predictor.


When we include the interaction between quantitative predictors in our models we  

- independent dimension
- cross product
- centering is advised


## Data and research questions

Our previous model was good, but it was missing an obvious and important predictor: the fundamental frequency of the speaker's voice (f0). The fundamental frequency of a sound is the main acoustic correlate of perceived pitch. We know from previous studies that, in general, speakers with lower speaking f0s tend to be identified as taller. In this section, we're going to fit a model that tries to predict apparent height from VTL and f0, and the interaction of the two. 

```{r, warning=FALSE, message=FALSE}
library (brms)
library (bmmb)
options (contrasts = c('contr.sum','contr.sum'))

data (height_exp)
height_exp = height_exp[height_exp$R=='a',]
```

We center our continuous predictors, and also scale f0 so that it has about the same magnitude as the VTL effect.  

```{r}
height_exp$vtl_original = height_exp$vtl
height_exp$vtl = height_exp$vtl - mean (height_exp$vtl)

height_exp$f0_original = height_exp$f0 
height_exp$f0 = height_exp$f0 - mean(height_exp$f0)
height_exp$f0 = height_exp$f0 / 100
```

We're not going to have well-defined research questions this time. Instead, we have a sort of vague one that we will try to deal with:

Q1) What do we do with all these parameters? How do we know what to focus on and where to begin?

### Description of the model

We're going to begin with a models that includes all possible interactions between our predictors, and also includes listener-dependent versions of all of our 'fixed' effects predictors. Models of this sort are sometimes referred to as **maximal** models because they include all predictors, interactions, and 'random effects' supported by the data. Our model formula is:

`height ~ vtl*f0*A*G + (vtl*f0*A*G|L) + (1|S)`

We're going to use the same priors we used for our regression models in chapter 9. We won't present the full model description as this is way too long at this point.


```
height ~ Intercept + vtl + f0 + A + G + A1:G1 + vtl:f0 + vtl:A1 + vtl:G1 + f0:A1 + 
         f0:G1 + vtl:f0:A1 + vtl:f0:G1 + vtl:A1:G1 + f0:A1:G1 + vtl:f0:A1:G1
```


$$
\begin{equation}
\begin{split}
height_{[i]} \sim \mathrm{t}(\mu_{[i]},\sigma, \nu) \\ 
\mu_{[i]} = a_{[i]} +  b_{[i]} \times \mathrm{vtl}_{[i]} + c_{[i]} \times \mathrm{f0}_{[i]} + d_{[i]} \times \mathrm{f0}_{[i]} \times \mathrm{vtl}_{[i]} \\ \\
\mathrm{and \; more} \ldots
\end{split}
(\#eq:11.4)
\end{equation}
$$

 - anova-like decomposition. 
 - same along each dimension

```
a = Intercept + A         + G         + A1:G1 
b = vtl       + vtl:A1    + vtl:G1    + vtl:A1:G1
c = f0        + f0:A1     + f0:G1     + f0:A1:G1
d = vtl:f0    + vtl:f0:A1 + vtl:f0:G1 + vtl:f0:A1:G1
```




### Fitting the model

```{r, eval = FALSE}
# Fit the model yourself
set.seed (1)
options (contrasts = c('contr.sum','contr.sum'))

priors = c(brms::set_prior("student_t(3,160, 12)", class = "Intercept"),
           brms::set_prior("student_t(3,0, 12)", class = "b"),
           brms::set_prior("student_t(3,0, 12)", class = "sd"),
           brms::set_prior("lkj_corr_cholesky (2)", class = "cor"), 
           brms::set_prior("gamma(2, 0.1)", class = "nu"),
           brms::set_prior("student_t(3,0, 12)", class = "sigma"))

model_height_vtl_f0 =  
  brms::brm (height ~ vtl*f0*A*G + (vtl*f0*A*G|L) + (1|S), data = height_exp, chains = 4, cores = 4,
       warmup = 1000, iter = 5000, thin = 4, prior = priors, family = "student")
```
```{r, include = FALSE, eval = FALSE}
# Or download it from the GitHub page:
model_height_vtl_f0 = bmmb::get_model ('11_model_height_vtl_f0.RDS')
```
```{r, include = FALSE, eval = FALSE}
# saveRDS (model_height_vtl_f0, '../models/11_model_height_vtl_f0.RDS')
model_height_vtl_f0 = readRDS ('../models/11_model_height_vtl_f0.RDS')
```

We're going to leave a discussion of the properties of the model to the next section where we present some advantages of working with Bayesian models over some more 'traditional' approaches. 

### Advantages of Bayesian multilevel models for large models

At this point we have enough model components to build very large and complicated models, like the one we fit above. Traditionally, models with many predictors have presented three general problems. First, a model with 'too many' predictors may return spurious values for the 'extra' predictors. Sometimes these spurious values are difficult to distinguish from the 'real' parameters, leading to incorrect conclusions. Second, the model may not be able to fit/converge on a solutions, meaning you can't get the model coefficients. Regardless of the approach to parameter estimation, more-complicated models make it more and more difficult for any estimation to 'find' the optimal parameter values given the data. Third, it can be difficult to interpret a model with *hundreds* (or thousands) of parameters. This becomes especially problematic when considered together with problem (1), that some of these values may simply represent noise. In this section we're going to discuss how working with multilevel Bayesian models can naturally help us with problems (1) and (2) above. In the following section we will discuss how our models can also help us resolve the third problem above.  
  The Bayesian models fit by `brms` have three properties that help resolve the first two problems above. First, the use of prior probabilities and shrinkage, when properly applied, tend to 'pull' weakly-supported parameter values closer to the group mean (or to zero). This can help reduce many of the problems associated with models with large numbers of parameters (cite). Second, the fact that confidence intervals are provided for all parameters helps distinguish random variation from variation that is likely to consistently vary from zero. Third, the fact that our models do not try to find *the* best solution, but simply sample the posterior distribution, relieves much of the pressure associated with finding *the* best solution for models with large numbers of parameters. 
  To this point we have not discussed the `lmer` function very much, apart from in 'Frequentist corner' at the end of some chapters. The `lmer` function (linear mixed-effects regression) is an extremely popular and extremely useful function. In general, `lmer` and an equivalent model specified in `brms` should provide reasonably similar answers when fitting the same models. However, there are some important differences between the two approaches. First, rather than provide a samples of value for each parameter, `lmer` returns *point estimates* representing the *best* values of parameters. This can cause a problem when parameters are bounded, or grow without bound. For example, standard deviation parameters (e.g., $\sigma$) cannot be 0 or negative, but sometimes they are very, very small. So, when `lmer` tries to find the 'best' value, it can get closer, and closer, and closer to zero, leading to problems involving calculations with very small values (e.g., as $x$ approaches $0$, $1/x$ approaches $\infty$). In contrast, Bayesian models don't try to find the single 'best' value but instead collect a series of samples. As a result, the models are less likely to encounter problems when they try to estimate values that are very close to boundaries (they just 'bounce' of the boundary as they randomly walk!). A second difference between the `lmer` estimation method and that of our Bayesian multilevel models is that `lmer` doesn't use prior probabilities to estimate any of it's parameters. This can cause some problems when estimating a large number of parameters without enough data. In contrast, `brms` applies 'shrinkage' to all its parameters (at least in principle), which can help avoid some of the problems encountered by `lmer`. 
  We're going to compare the output of `lmer` and `brms` for the model we fit above. Just to be clear, our intention in comparing `lmer` and `brms` is not to compare different statistical *philosophies* or epistemological claims. Our aim is much, much more modest than that. We simply wish to compare `brms`, an approach that 1) uses priors, 2) provides confidence intervals, and 3) estimates based on posterior samples, to one that does not (`lmer`). 
  Below we fit a model equivalent to `model_height_vtl_f0` using `lmer`.

```{r, eval = FALSE}
lme_model_height_vtl_f0 =
  lme4::lmer (height ~ vtl*f0*A*G + (vtl*f0*A*G|L) + (1|S), 
              data=height_exp,verbose = TRUE,
              control=lme4::lmerControl(optCtrl=list(maxfun=20000),optimizer="bobyqa"))
```
```{r, include = FALSE, eval = FALSE}
# Or download it from the GitHub page:
lme_model_height_vtl_f0 = bmmb::get_model ('11_lme_model_height_vtl_f0.RDS')
```
```{r, include = FALSE, eval = FALSE}
#saveRDS (lme_model_height_vtl_f0, '11_lme_model_height_vtl_f0.RDS')
lme_model_height_vtl_f0 = readRDS ('../models/11_lme_model_height_vtl_f0.RDS')
```

We won't show the model print statements they are both quite large, but we compare the estimates of our fixed effects in figure \@ref(fig:F11_4). Clearly, the two approaches provide very similar for the model fixed effects. That's reassuring! If results differed dramatically for approximately the same model based on the software used, we would need to think very carefully about the causes and possible meaning of these differences.
  Since our model has a large number of parameters we are going to focus on interpreting those that seem likely to result in 'meaningful' differences in apparent height. We define meaning differences as those that 1) are likely to be different from zero, *and* 2) have magnitudes of at least around 1 cm (about 0.5 inches). We establih this lower limit simply based off the fact that people may describe themselves as 175 cm (or 5'10.5") but rarely make distinctions smaller than that (e.g. people rarely distinguish 5'10.5" and 5'10.75"). 
  Our model suggests non-zero slopes for our plane along the VTL (mean = 3.09, s.d. = 0.63, 95% C.I = [1.84, 4.34]) and f0 dimensions (mean = -3.34, s.d. = 1.27, 95% C.I = [-5.88, -0.86]). However, the `vtl:f0` interaction does not seem to matter at all (mean = -0.72, s.d. = 0.96, 95% C.I = [-2.65, 1.17]). This means that, overall, our responses can be defined by a plane along f0 and VTL without curving the plane into a saddle shape. The `vtl:A1` interaction suggests a differing use of VTL based on apparent adultness, but there do not appear to be any other meaningful interactions between VTL, f0 and the other predictors. In terms of intercept terms (i.e. those not interacting with quantitative predictors), there is a large effect for apparent age (mean = 7.04, s.d. = 1.13, 95% C.I = [4.85, 9.28]) but no main effect for apparent gender (mean = -0.06, s.d. = 0.71, 95% C.I = [-1.43, 1.35]). However, the interaction between apparent age and apparent gender (`A1:G1`) had a 95% credible interval that did not overlap with zero and had a posterior mean value of -1.49 cm (s.d. = 0.51, 95% C.I = [-2.48, -0.44]). This indicates that although apparent gender had an average effect of about 0 cm on apparent height it may have had meaningful, but opposite, effects based on the apparent gender of the speaker. 
  In order to interpret our predictors in the presence of interactions, we need to consider the simple effects. For example, in order to consider the `vtl:A1` interaction we need to consider the simple effect of VTL for apparent children, and then for apparent adults. This is done in exactly the same manner as outlined in chapter 9 and 10 for quantitative predictors, independently for each predictor or interaction (i.e. cross-product) between predictors.  We're not going to go over the interpretation of the coefficients and the reconstruction of the simple effects here, as this has been discussed in detail elsewhere (section X). 

```{r F11_4, fig.height = 3.5, fig.width = 8, fig.cap='', echo = FALSE}

################################################################################
### Figure 11.4
################################################################################
pts = fixef (lme_model_height_vtl_f0)[-1]
err_bars = summary (lme_model_height_vtl_f0)$coefficients[-1,2]

par (mfrow = c(1,1), mar = c(6,4,1,1))
bmmb::brmplot (fixef (model_height_vtl_f0)[-1,], ylim = c(-7,10),las=2)
points ((1:15)+.2, pts, cex=1.5,lwd=2,col=2,pch=16)
segments((1:15)+.2, pts-2*err_bars,(1:15)+.2, pts+2*err_bars,lwd=2,col=2)

abline (h = c(-1,1), lty = 3, col = bmmb::cols[6],lwd=2)
```

Figure \@ref(fig:F11_5) presents some ways in which the information provided by `lmer` and `brms` differ. In the top row we see a comparison of the 'random effects' standard deviation estimates provided by our two models, and the error terms estimated by our two models. For example, the standard deviation of the listener f0 'random effect' ($\sigma_{f0 \colon L}$) represents the variation around zero of the listener-specific effects for f0 in each model. As we can see, the models provide reasonably similar standard deviation estimates for most parameters. However, note that the `brm` models provide credible intervals for all parameters, while the `lmer` models only provide point estimates for these parameters. The lack of intervals on parameter estimates makes it difficult to 'rule out' variance parameters since they will *never* equal exactly zero. So, we will always have non-zero numbers for these parameters, and 'secretly' some of these are zero or nearly zero. In addition, variance components very close to zero can cause problems when estimating our models. For example, fitting our model with `lmer` resulted in the following error: 

`boundary (singular) fit: see help('isSingular')`

Which warns us that some of the variance components we are trying to estimate are quite small. Because `bmrs` simply samples from the posterior and doesn't try to find *the* best model parameters, it does not run into these problems. In addition, we can use our credible intervals to figure out which variance components are unlikely to matter: Variance components whose credible intervals are concentrated near zero. There are several such components in the figure below. In the *best case*, many of these components reflect a tiny amount of systematic variation in our outcomes and so are unlikely to matter much. Notice that the magnitude of the standard deviations makes it difficult to predict which standard deviation parameters are distinguishable from zero. This makes the point estimates of limited utility for this purpose in the absence of intervals around our estimates.
  In the middle panel of figure \@ref(fig:F11_5) we see a comparison of the listener-dependent `A1` 'random effects' estimated using the two approaches. Just as with the estimates of the fixed effect in In the middle panel of figure \@ref(fig:F11_4) we see a close alignment between the two. However, just as for our standard deviation terms we see that a lack of intervals around our estimates makes it difficult to compare our parameter estimates to specific values (such as zero). 

```{r, F11_5, fig.height = 6, fig.width = 8, fig.cap='', echo = FALSE}

################################################################################
### Figure 11.5
################################################################################

Ssd = attr(VarCorr(lme_model_height_vtl_f0)[[1]],'stddev')
Lsd = attr(VarCorr(lme_model_height_vtl_f0)[[2]],'stddev')
lmer_vars = c(Lsd, Ssd, sigma(lme_model_height_vtl_f0))
vars_final = bmmb::getsds(model_height_vtl_f0)

layout (m=1:3, heights = c(.4,.3,.3))
par (mar = c(7,4,.5,1))
bmmb::brmplot (vars_final, ylim = c(0,7), las = 2,cex.axis=1.3,
               col=bmmb::cols[1+as.numeric(factor(vars_final$group))])
points (lmer_vars, cex=2,lwd=2,col=4,pch=4)

pts = ranef(lme_model_height_vtl_f0)$L[,4]

par (mar = c(.5,4,.5,1))
bmmb::brmplot (ranef(model_height_vtl_f0)$L[,,4],labels="", col = 2)
points ((1:15), pts, cex=2,lwd=2,col=4,pch=4)


corrs_lme = attr(VarCorr(lme_model_height_vtl_f0)$L,"correlation")
corrs_lme = corrs_lme[lower.tri (corrs_lme)]
corrs_brms = bmmb::getcorrs(model_height_vtl_f0, "L")

bmmb::brmplot (corrs_brms, ylim = c(-.97,.97), las = 2, labels = "",line=FALSE,col=2)
abline (h=0)
points (corrs_lme, cex=1.25,lwd=2,pch=4, col = 4)

```

In the bottom panel of figure \@ref(fig:F11_5) we compare the correlations for the listener random effects. Since there were 16 listener-dependent parameters, we needed to estimate 120 unique correlations between these effects. As with our standard deviation parameters, `brms` gives us intervals while `lmer` returns point estimates. In addition, for the first time we see a substantial difference between the estimates provided by `lmer` and those provided by `brms`. This is likely a result of the fact that `lmer` does not apply something like partial pooling to its correlation estimates, either through the use of prior probabilities or other mechanisms. As a result, we see that the `lmer` estimates vary substantially around 0 while the `brms` estimates are all close to zero, and mostly have intervals that include zero. We see that in this case our Bayesian model protects us by: 1) Providing credible intervals for all parameters, letting us accept values of zero as likely, and 2) the LKJ prior we used for our random effect correlation matrices pulls weakly-supported correlations to zero, thereby protecting against spurious results. 
  The fact that most of our correlation estimates are nearly zero not only lets us rule some out, but also focuses our attention to those correlations that deviate from this pattern. For example, the third correlation from the left in the bottom panel of figure \@ref(fig:F11_5) represents the correlation between the listener-dependent intercepts and effects for apparent age. Although its 95% credible interval includes some very small values near zero (mean = -0.38, s.d. = 0.17, 95% C.I = [-0.69, -0.01]), it seems reasonable that this correlation may in fact be negative and non-zero. In fact, we found this correlation in a previous model (section X) and also discussed why we think this correlation 'makes sense' (section X). 
  
## Bayesian Analysis of Variance

The information we considered in the previous section can be used to considered which predictors, or groups of predictors, might be important in our models. This approach becomes increasingly more useful as our models increase in complexity and end up with dozens or hundreds of parameters. This approach is presented is presented by Gelman and colleagues in Gelman anova paper, Gelman and hill chapter 22, and Gelman et al BDA3 chapter. 
  The analysis of variance (ANOVA) is a set of modeling techniques meant to help understands the components and sources of variation in a dependent variables. We're not going to talk about a 'traditional' ANOVA in any detail here, as it would involve the introduction of a *parallel universe* of statistical concepts and jargon that has not been discussed in this book. There are many excellent treatments on the subject including myers and well and cite others. That being said, at its core ANOVA consists of thinking of variation in the dependent variable as the sum of variation of a set of **components of variation** related to the predictors in our model. For example, we can think of the total variation in apparent height judgments as related to variation according to apparent age, listener-dependent intercepts, and so on, until we get to all the variance we *can't* explain, and we just call that the *error* ($\sigma$). 
  A 'traditional' ANOVA tries to **decompose** variation into independent components so that it can relate combinations of these as ratios in order to carry out different statistical tests. That approach is fundamentally different to the sorts of things we have been doing with our multilevel models. However, the general approach of decomposing variation in our dependent variable into separate components is very useful, especially for larger models. Here's what Gelman and Hill have to say about the analysis of variance in the context of multilevel models:

> "When moving to multilevel modeling, the key idea we want to take from the analysis of variance is the estimation of the importance of different batches of predictors (“components of variation” in ANOVA terminology). As usual, we focus on estimation rather than testing: instead of testing the null hypothesis that a variance component is zero, we estimate the standard deviation of the corresponding batch of coefficients. If this standard deviation is estimated to be small, then the source of variation is minor—we do not worry about whether it is exactly zero. In the social science and public health examples that we focus on, it can be a useful research goal to identify important sources of variation, but it is rare that anything is truly zero." (p. 490)

> "the standard deviation of a set of coefficients gives a sense of their predictive importance in the model. An analysis-of-variance plot, which shows the relative scale of different variance components, can be a useful tool in understanding a model." (p. 492)

  These standard deviations directly reflect the amount of variation in these parameters in our model. Parameters that vary a lot reflect large effects on our data. These will be represented by large standard deviations. In contrast, parameters that do not vary much will be represented by small standard deviations. These parameters do not have a large effect on our data (since they do not vary much). For example, we can see in figure \@ref(fig:F11_5) that the standard deviation of listener-dependent intercepts ($\sigma_L$) is much larger than the listener-dependent VTL by apparent gender interaction ($\sigma_{VTL \colon G \colon L}$). We can see that this directly relates to the variation of each batch of 'random effects' around zero, as shown in figure \@ref(fig:F11_6). As a result of this, we can take one look at figure \@ref(fig:F11_5) and see that although there are a large number of predictors, only a couple are having any meaningful effect on apparent height judgments. 
  
```{r, F11_6, fig.height = 3, fig.width = 8, fig.cap='', echo = FALSE}

################################################################################
### Figure 11.6
################################################################################

par (mfrow = c(1,1), mar = c(4,4,1,1))

brmplot (ranef (model_height_vtl_f0)$L[,,"Intercept"], col = bmmb::cols[9], 
         line=TRUE)
brmplot (ranef (model_height_vtl_f0)$L[,,"vtl:G1"], add = TRUE, 
         nudge = 0.1, labels = "", col = bmmb::cols[14],pch=17)
```
  
Gelman and Hill distinguish between two types of standard deviations for a 'random' effect with $J$ levels (p. 459) (emphasis ours):

> "• The **superpopulation** standard deviation , which represents the variation among the modeled probability distribution from which the were drawn, is relevant for determining the uncertainty about the value of a new group not in the original set of J." 

> "• The **finite-population** standard deviation of the particular J values of [$\alpha_{[subj]}$] describes variation within the existing data." 

  So, the *finite-population* standard deviation terms are reflect the variation we observe in our actual model parameters. This concept can be extended to both batches of 'random' effects estimated with adaptive partial pooling and to 'fixed' effects estimated without it. Tthe *superpopulation* standard deviation estimates correspond to the specific $\sigma$ term estimated by our model for different batches of 'random' effects, and no analogue exists for our 'fixed' effects. The authors note that (p. 464):

> "The superpopulation [σ] and finite-population [s] standard deviations are not two different statistical “estimators” of a common quantity; rather, they are two different quantities that can both be estimated from the multilevel model. We can get a point estimate and uncertainty intervals for both. In general, the point estimates of σ and s will be similar to each other, but s will have less uncertainty than σ. That is, the variation is more precisely estimated for the finite population than the superpopulation. This makes sense because we have more information about the units we observe than the full population from which they are sampled."

Gelman and colleagues suggest the following general process, that can be referred to as a **Bayesian analysis of variance**, or **BANOVA**:

  1) Fit the model with the structure you think is required to capture the variation in the data. 
  
  2) Calculate the superpopulation and finite-population standard deviations for predictors or groups of predictors. 
  
  3) Make a plot comparing the magnitudes of different predictors, and of the uncertainty in the estimates. The authors refer to this as an **
  
  4) Us the ANOVA plot to make inferences about the relative importance of your predictors, and to guide your analysis. 
  
We could potentially add a fifth step: 5) refit reduced model if some components show little to no importance or variation across clusters, and if you have some compelling reason to do so. This step is not strictly necessary, but we will consider it as a possibility. 
  
### Getting the standard deviations from our models 'manually'

The superpopulation standard deviation is our model's estimate of the standard deviations of different batches of parameters. We can extract the superpopulation standard deviations using the `VarCorr` function. This function returns all sort of information about the variance anf correlation parameters estimated by our model. In the second line below we specify that we only want information related to the standard deviation (`"sd"`) of our listener effects (`"L"`).

```{r, cache = TRUE, collapse = TRUE, eval = FALSE}
brms::VarCorr(model_height_vtl_f0)

brms::VarCorr(model_height_vtl_f0)[["L"]][["sd"]]
```

We can also get information regarding our error standard deviation using `Varcorr` as seen below:

```{r, cache = TRUE, collapse = TRUE}
brms::VarCorr(model_height_vtl_f0)$residual$sd
```

The `bmmb` package contains a function called `getsds` that collects estimates of all standard deviations estimated by the model, including the error:

```{r}
getsds (model_height_vtl_f0)
```

Getting the finite-sample standard deviations is a bit trickier. To calculate the standard deviations of different batches of parameters you need to calculate the standard deviation for each batch, *for each sample*. This means you end up with as many samples of the finite-sample standard deviation based on each set of posterior samples. The code below shows how to calculate the finite-population standard deviations for item based on the random effects parameter estimates. 

```{r, cache = TRUE, collapse = TRUE, eval = FALSE}
# extract matrix representing all random effects from our model
listener_intercepts = ranef(model_height_vtl_f0, summary = FALSE)[["L"]][,,"Intercept"]

# the output is a 3d matrix. dimensions are:
str (listener_intercepts)

# we need to find the standard deviation for the item random effects for each 
listener_intercepts_finite = apply (listener_intercepts,1,bmmb::rms)

# the output is a 2d matrix. dimensions are:
# we summarize the output into a matrix where each row represents a single
item_ranefs_finite = posterior_summary (item_ranefs_finite)
```

For the fixed effects, we can use the absolute value of the parameters when these are each a single 'degree of freedom' (i.e. a single parameter). The code below shows how to get the fixed effects standard deviation estimates. 

```{r, cache = TRUE, collapse = TRUE, eval = FALSE}
# get individual parameter samples
fixefs_finite = fixef(maximal_brms, summary = FALSE)

# summarize absolute value
fixefs_finite = posterior_summary (abs (fixefs_finite))
```

In cases where we also have batches of fixed effect predictors, the finite-sample standard deviation of these can be estimated using the same approach used for the random effects shown above. Finally, we can estimate the finite-sample error by getting the model residuals, and then calculating the standard deviation of the residuals for each set of samples as shown below.

```{r, cache = TRUE, collapse = TRUE, eval = FALSE}
# get residuals
sigma_finite = residuals (maximal_brms, summary = FALSE)

# find standard deviation for each set of samples
sigma_finite = apply (sigma_finite, 1, sd)

# summarize
sigma_finite = posterior_summary (sigma_finite)

# name row, because it has no name by default
row.names(sigma_finite) = 'sigma'
```

### Using the `banova` function

The `bmmb` package contains a function called `banova` that can get the finite-sample or superpopulation standard deviations for you. The output is a single dataframe that contains a summary of the standard deviations for fixed and random effects, and the error term if the model contains one. Below we use the function to get both kinds of standard deviation, compared in 

```{r, cache = TRUE, include = FALSE}
banova_height_vtl_f0_finite = banova (model_height_vtl_f0, superpopulation = FALSE)
banova_height_vtl_f0_super = banova (model_height_vtl_f0, superpopulation = TRUE)
```

The output of the `banova` function can be used to make a Bayesian ANOVA plot of our model. If we were to do this right after fitting the model, we would have a pretty good idea of what matters and what doesn't in our data. 

```{r F11_7, fig.height = 4.5, fig.width = 8, fig.cap='', echo = FALSE}

################################################################################
### Figure 11.7
################################################################################

par (mar = c(.125,4,.125,.125), mfrow = c(2,1), oma = c(6.5,0,1,0))
banovaplot (banova_height_vtl_f0_finite[-2,], las = 2,line=FALSE,labels = "",
            yaxs="i", ylim = c(0,10))
abline (h=0)
box()
banovaplot (banova_height_vtl_f0_super[-2,], las = 2, line=FALSE,yaxs="i",
            ylim = c(0,10))
abline (h=0)
box()

```

The process Gelman proposes is potentially more complicated that what I'm doing here. For example, consider the random effects for a factor like vowel category. Imagine there are four categories, so four levels, for each of 50 listeners. The process I've described treats each of the 50 random effects for each vowel separately (i.e., 4 groups of 50 vowel random effects). The process described by Gelman would treat the 200 vowel random effects (across the four vowels) as one 'batch' of coefficients. This single batch would reflect all of the $Listener \colon Vowel$ interaction. The way we are approaching instead separates each $Listener \colon Vowel$ 'simple effect' and treats it separately. The main reason to do it the way way I've shown above is because it can be done easily for all models, and you get roughly equivalent information from the analysis. If you do want to investigate the variation associated with entire clusters of multiple predictors at a time, please see the Gelman articles linked to above, as there are a few important details that are not discussed here (e.g., the need to 'recover' missing parameters, the need to calculate 'degrees of freedom', etc.).

### Fitting and comparing the reduced model

Our initial model formula was:

`height ~ f0*vtl*A*G + (f0*vtl*A*G|L) + (f0*vtl*A*G|S)`

Which expands to:

```
height ~ vtl + f0 + A + G + A1:G1 + vtl:f0 + vtl:A1 + vtl:G1 + f0:A1 + f0:G1 + 
         vtl:f0:A1 + vtl:f0:G1 + vtl:A1:G1 + f0:A1:G1 + vtl:f0:A1:G1 + 
         (vtl + f0 + A + G + A1:G1 + vtl:f0 + vtl:A1 + vtl:G1 + f0:A1 + f0:G1 + 
         vtl:f0:A1 + vtl:f0:G1 + vtl:A1:G1 + f0:A1:G1 + vtl:f0:A1:G1|L) + (1|S)
```
Because we include all interactions and listener 'random effects' of these, we're basically saying that we think its possible for every predictor to affect every other predictor, and for all of this to vary in a listener-dependent manner. We might instead consider the following model formula which includes only those effects we (arbitrarily) deemed 'large enough' based on figures above. 

`height ~ f0 + vtl + A*G + vtl:A1 + (f0 + vtl + A*G + vtl:A1|L) + (1|S)`

Since these are the predictors that varied most betwee listeners and also affected our dependent variable the most, in some situations we may be justified in fitting a 'final' model that includes only the important components. We fit the reduced model below:

```{r, eval = FALSE}
# Fit the model yourself
set.seed (1)
options (contrasts = c('contr.sum','contr.sum'))

priors = c(brms::set_prior("student_t(3,160, 12)", class = "Intercept"),
           brms::set_prior("student_t(3,0, 12)", class = "b"),
           brms::set_prior("student_t(3,0, 12)", class = "sd"),
           brms::set_prior("lkj_corr_cholesky (2)", class = "cor"), 
           brms::set_prior("gamma(2, 0.1)", class = "nu"),
           brms::set_prior("student_t(3,0, 12)", class = "sigma"))

model_height_vtl_f0_reduced =  
  brms::brm (height ~ f0+vtl+A*G+vtl:A + (f0+vtl+A*G+vtl:A|L) + (1|S),
             data = height_exp, chains = 4, cores = 4, warmup = 1000, 
             iter = 5000, thin = 4, prior = priors, family = "student")
```
```{r, include = FALSE, eval = FALSE}
# Or download it from the GitHub page:
model_height_vtl_f0_reduced = bmmb::get_model ('11_model_height_vtl_f0_reduced.RDS')
```
```{r, include = FALSE, eval = FALSE}
# saveRDS (model_height_vtl_f0_reduced, '../models/11_model_height_vtl_f0_reduced.RDS')
model_height_vtl_f0_reduced = readRDS ('../models/11_model_height_vtl_f0_reduced.RDS')
```

We can see that the fixed effects shared in common are very similar, as are the estimates of the random effects for the listener-dependent parameters.  

```{r F11_8, fig.height = 3, fig.width = 8, fig.cap='(left) . (right) .', echo = FALSE}

################################################################################
### Figure 11.8
################################################################################

sds_reduced = getsds(model_height_vtl_f0_reduced)
sds = getsds(model_height_vtl_f0)
use = rownames(sds) %in% rownames(sds_reduced)
sds = sds[use,]

par (mfrow = c(1,2), mar = c(4,4,1,1))
layout (m = t(c(1,2)),widths = c(.55,.45))
brmplot (fixef (model_height_vtl_f0)[c(2,3,4,5,7,11),], ylim = c(-6,10),las=2,
         ylab = "Centimeters")
brmplot (fixef (model_height_vtl_f0_reduced)[c(3,2,4,5,7,6),],
         add = TRUE, nudge = 0.2, col = 2,labels = "")
abline (h=0)

brmplot (sds, las = 2, ylab = "Centimeters")
brmplot (sds_reduced, add = TRUE, col = 2, nudge = .2, labels = "")

```

We use cross-validation to compare the expected model out-of-sample prediction: 

```{r, cache = TRUE}
model_height_vtl_f0 = add_criterion (model_height_vtl_f0, "loo")
model_height_vtl_f0_reduced = add_criterion (model_height_vtl_f0_reduced, "loo")
```

And see that the reduced model has a lower $\mathrm{elpd}$, but that the differences is only about 1.5 standard errors, making it not very reliable. 

```{r}
loo_compare (model_height_vtl_f0,model_height_vtl_f0_reduced) 
```

We can also consider the variance explained ($R^2$) by each model:

```{r}
bmmb::r2_bayes(model_height_vtl_f0)
bmmb::r2_bayes(model_height_vtl_f0_reduced)
```

And see that all of the extra complexity included in our full model gains us less than 1% additional variance explained. All of this suggests that a researcher would be justified in fitting and interpreting the reduced model for their research. However, we are inclined to agree with Gelman and colleagues that there is value in fitting a model that includes all of the realistic variation that may be included in our data, and that is supportable by our data. This means fitting and reporting the larger model. As we have seen, the 'extra' predictors do not seem to affect the parameters we do care about very much. In addition, where they are slightly different it is impossible to 'prove' which values are closer to the 'truth' based only on the performance of the models. In addition, being able to say "these parameters are near zero/show no between-listener variation" is useful information that we lose when we rely only on the reduced model. Of course, we could say something like "we fit a larger model that showed all these effects are zero but we are not presenting it here". However, if we do want to say something like this it may make sense to present the full model to the reader so that they may make their own conclusions and use the information as they see fit. 

## Fitting a multivariate logistic regression model

We're now going to fit a logistic regression model with two quantitative predictors and an interaction between them. We're also going to inspect the model using the principle of BANOVA outlined in the previous section. Before continuing we want to talk briefly about the geometry of the models we will be fitting. A logistic regression model with two continuous predictors specifies planes along a third dimension ($z$) representing the logit of the probability of observing a 'success' (a value of 1). When the value on the surface of these planes is negative, the model predicts a response of 0, and when the value of the plane is positive the model predicts a 1. We can imagine the plane such that $z=0$ representing a probability of 0.5. The planes represented by our models will intersect with these planes, forming a line at this intersection. Since these lines represent a division of our planes into sections with values greater than 0 (expected response 1) and sections with values less than 0 (expected response 0). Thus, the lines formed by the intersection of these planes represent the *category boundary* as defined by our model. When we want to know the probability expected for any given x and y axis location, we can transform the value on the plane using the inverse logit function. When the predicted logits are transformed to probabilities, our model defines a curved shape rather than a flat plane as seen in the bottom row of figure \@ref(fig:11_9). Although these surfaces are are not flat, their intersection with the plane at $z=0.5$ (i.e. the plane where logit = 0) will still form straight lines. 

```{r F11_9, fig.height = 4, fig.width = 8, fig.cap=' -- ', echo = FALSE}

################################################################################
### Figure 11.9
################################################################################

f1 = function (a,b,c) a * 1 + b *1  
x <- y <- seq(-3, 3, length= 12)

par (mfrow = c(2,3), mar = c(1,1,0,0), oma = c(0,0,0,0))

z <- outer(x, y, f1)
persp(x, y, z, col = cols[3],theta = 0,zlim = c(-6.5,6.5))
persp(x, y, z, col = cols[3],theta = -90,zlim = c(-6.5,6.5))
persp(x, y, z, col = cols[3],theta = 45,zlim = c(-6.5,6.5))

z <- outer(x, y, f1)
persp(x, y, ztop(z), col = cols[4],theta = 0,zlim = c(0,1))
persp(x, y, ztop(z), col = cols[4],theta = -90,zlim = c(0,1))
persp(x, y, ztop(z), col = cols[4],theta = 45,zlim = c(-0,1))

```

When our models include interactions between quantitative predictors (i.e. terms representing their cross-products), our predicted values no longer vary along planes. Instead, the surface will resemble a saddle shape based on the sign of the parameter and its magnitude relative to the slopes of the relevant quantitative predictors in the model. Since these shapes can fall and then rise again, a surface of this kind may intersect with the plane at $z=0$ in more than one location (seen in figure \@ref(fig:11_10)). The intersection between a saddle shape and the plane where $z=0$ will not be a straight line. Instead, it will be a **hyperbola** a shape that resembles a pair of parabolas that approach, but never cross an asymptote. We will return to this issue when we consider the territorial maps implied by our models later on. 

```{r F11_10, fig.height = 4, fig.width = 8, fig.cap=' -- ', echo = FALSE}

################################################################################
### Figure 11.10
################################################################################

f1 = function (a,b,c) a * 1 + b *1 + a*b*1  

x <- y <- seq(-3, 3, length= 12)

par (mfrow = c(2,3), mar = c(1,1,0,0), oma = c(0,0,0,0))

z <- outer(x, y, f1)
persp(x, y, z, col = cols[5],theta = 0,zlim = c(-9.5,15.5))
persp(x, y, z, col = cols[5],theta = -90,zlim = c(-9.5,15.5))
persp(x, y, z, col = cols[5],theta = 45,zlim = c(-9.5,15.5))

z <- outer(x, y, f1)
persp(x, y, ztop(z), col = cols[6],theta = 0,zlim = c(0,1))
persp(x, y, ztop(z), col = cols[6],theta = -90,zlim = c(0,1))
persp(x, y, ztop(z), col = cols[6],theta = 45,zlim = c(-0,1))

```

### Data and research questions

We load our packages and set our contrasts. We also load our experimental data, focusing on the natural, unmodified resonance. 

```{r, warning=FALSE, message=FALSE}
library (brms)
library (bmmb)
options (contrasts = c('contr.sum','contr.sum'))

data (height_exp)
height_exp = height_exp[height_exp$R=='a',]
```

Below we add our dependent variable `F`. This variable equals 1 when the listener indicated hearing a female speaker and 0 when the listener indicated hearing a male speaker. As with our previous model we center our quantitative variables and divide f0 by 100 to make the expected regression coefficient more similar in magnitude

```{r}
# our dependent variable
height_exp$F = as.numeric (height_exp$G == 'f')

height_exp$vtl_original = height_exp$vtl
height_exp$vtl = height_exp$vtl - mean (height_exp$vtl)

height_exp$f0_original = height_exp$f0 
height_exp$f0 = height_exp$f0 - mean(height_exp$f0)
height_exp$f0 = height_exp$f0 / 100
```

Our research questions are:

Q1) Do listeners use VTL, f0, and the interaction between them to determine speaker gender?

Q2) Does apparent speaker age influence the use of the above mentioned acoustic cues?

### Description of the model

Our model formula is very much like the one we used for our first model in this chapter, however, since we are predicting apparent femaleness we obviously do not include apparent gender as a predictor. Our formula will be:

`F ~ vtl*f0*A + (vtl*f0*A|L) + (1|S)`

We'll use the same priors we used for our logistic models last chapter. Since we scaled f0 so that a change of 1 corresponds to 100 Hz, this value represents about half the difference between adult males and females. For this reason, we think it's reasonable to use a prior of the same magnitude as we used for our VTL parameter. We will omit our model specification since it is quite large and very similar to the one above for `model_height_vtl_f0` and those presented in chapter 10. 

### Fitting and the model and applying a Bayesian ANOVA

Below we fit our model:

```{r, eval = FALSE}

model_gender_vtl_f0 =
  brm (F ~ vtl*f0*A + (vtl*f0*A|L) + (1|S), data=height_exp, 
       chains=4, cores=4, family="bernoulli", 
       warmup=1000, iter = 5000, thin = 4,  
       prior = c(set_prior("student_t(3, 0, 3)", class = "Intercept"),
                 set_prior("student_t(3, 0, 3)", class = "b"),
                 set_prior("student_t(3, 0, 3)", class = "sd"),
                 set_prior("lkj_corr_cholesky (2)", class = "cor")))
```
```{r, include = FALSE, eval = FALSE}
# Or download it from the GitHub page:
model_gender_vtl_f0 = bmmb::get_model ('11_model_gender_vtl_f0.RDS')
```
```{r, include = FALSE, eval = FALSE}
# saveRDS (model_gender_vtl_f0, '../models/11_model_gender_vtl_f0.RDS')
model_gender_vtl_f0 = readRDS ('../models/11_model_gender_vtl_f0.RDS')
```

We can consider the model fixed effects using `brmplot` in figure \@ref(fig:11_10)., and beside that we make a BANOVA plot that compares the fixed effects, the finite-sample standard deviations for 'batches' our random effects parameters, and the residual error.

```{r, include = FALSE}
banova_gender_vtl_f0 = bmmb::banova (model_gender_vtl_f0)
```

```{r F11_11, fig.height = 3, fig.width = 8, fig.cap='--', echo = FALSE}

par ( mfrow = c(1,2), mar = c(5.5,3,1,1))
layout (m= t(c(1,2)), widths = c(.4,.6))
bmmb::brmplot (fixef(model_gender_vtl_f0), line = TRUE, las = 2)
banovaplot (banova_gender_vtl_f0, line = TRUE, las = 2)
```

In figure above we see a relatively complex model, with an important role for both f0 and VTL. We also so that unlike for our model predicting apparent height above, this model features a prominent f0 by VTL interaction (`vtl:f0`), and an interaction between this and apparent age (`vtl:f0:A1`). 

- go over results, convert predicted logits to percents
- some examples of simple effects and hypothesis function. 


### Categorization in two dimensions

To find the intersection of the surfaces defined by our models and the plane at $z=0$, we can use some basic algebra. We take the equation defining the general shape:

$$
\begin{equation}
z =  \mathrm{a} + (\mathrm{b} \times x) + (\mathrm{c} \times y) + (\mathrm{d} \times xy)
(\#eq:11_5)
\end{equation}
$$

To find the equation for a line



$$
\begin{equation}
\begin{split}
0 =  \mathrm{a} + (\mathrm{b} \times x) + (\mathrm{c} \times y) + (0 \times xy) \\
y =  (-\mathrm{b} \times x - \mathrm{a}) /  (\mathrm{c} \times y) + (0 \times xy)
\end{split}
(\#eq:11_5)
\end{equation}
$$


$$
\begin{equation}
\begin{split}
0 =  \mathrm{a} + (\mathrm{b} \times x) + (\mathrm{c} \times y) + (d \times xy) \\
y =  (-\mathrm{b} \times x - \mathrm{a}) / (d \times x + c)
\end{split}
(\#eq:11_5)
\end{equation}
$$


Then we can divide the column representing the overall intercept by the column representing the overall slope. The result is a vector of individual samples from the posterior distribution of the $x$ intercept of the line, i.e. the category boundary along the VTL dimension. We refer to specific columns by using the same names seen in the print statement for the fixed effects. Note that to find the $x$ intercept for the adult and child lines we combine parameters in the same way as when we found the age-dependent lines above.  

```{r, collapse = TRUE}
# get fixed effect parameters
samples = fixef (model_gender_vtl_f0, summary = FALSE)

# get a,b,c,d coefficients for overall surface
a_all = mean (samples[,"Intercept"])
b_all = mean (samples[,"vtl"])
c_all = mean (samples[,"f0"])
d_all = mean (samples[,"vtl:f0"])

# get a,b,c,d coefficients for adult surface
a_adult = mean (samples[,"Intercept"] + samples[,"A1"])
b_adult = mean (samples[,"vtl"] + samples[,"vtl:A1"])
c_adult = mean (samples[,"f0"] + samples[,"f0:A1"])
d_adult = mean (samples[,"vtl:f0"] + samples[,"vtl:f0:A1"])

# get a,b,c,d coefficients for child surface
a_child = mean (samples[,"Intercept"] - samples[,"A1"])
b_child = mean (samples[,"vtl"] - samples[,"vtl:A1"])
c_child = mean (samples[,"f0"] - samples[,"f0:A1"])
d_child = mean (samples[,"vtl:f0"] - samples[,"vtl:f0:A1"])
```


```{r F11_12, fig.width = 8, fig.height = 3.5, fig.cap = "(left) Average perceived height for each speaker as a function of average f0. (middle) The same relationship as the left but only males are plotted. (right) Only females are plotted.", echo = FALSE, eval = FALSE}

################################################################################
### Figure 11.12
################################################################################

# y = (-b*x - a - z) / (dx+c)
# fixef(model_gender_vtl_f0)

mu_vtl = mean (height_exp$vtl_original)
mu_f0 = mean (height_exp$f0_original)

aggd = aggregate (cbind ( height, A=="a", G=="f", vtl,f0, vtl) ~ S + C_v, 
                      data = height_exp, FUN = mean)
aggd$C = ""
aggd$C[aggd[,4]>= 0.5 & aggd[,5]>= 0.5] = "w"
aggd$C[aggd[,4]>= 0.5 & aggd[,5]<= 0.5] = "m"
aggd$C[aggd[,4]<= 0.5 & aggd[,5]>= 0.5] = "g"
aggd$C[aggd[,4]<= 0.5 & aggd[,5]<= 0.5] = "b"
#table(aggd$C)

par (mfrow = c(1,3), mar = c(4,2,1,1), oma = c(1,4,0,0))

plot (aggd$vtl,aggd$f0, cex =1.2, col = cols[c(2:5)][factor(aggd$C)], 
      xlim=c(-2.5,3),  pch=16,lwd=2, xlab = "",
      ylab="Height (inches)")
grid()
points (aggd$vtl, aggd$f0, cex =1.2, pch=16,lwd=2,
      col = cols[c(2:5)][factor(aggd$C)])

legend (1,300, legend = c("Boys","Girls","Men","Women"),lwd=2,lty=0,
        col = cols[2:5], bty='n',pch=16,pt.cex=1.5)

curve ((-b_all*x - a_all) / (c_all), from = -3, to = 3, add = TRUE)
#curve ((-b_all*x - a_all) / (d_all*x+c_all), from = -3, to = -.53, add = TRUE)
#curve ((-b_all*x - a_all) / (d_all*x+c_all), from = -.52, to = 4, add = TRUE)

curve ((-b_adult*x - a_adult)/ (c_adult), from = -3, to = 3, add = TRUE)
#curve ((-b_adult*x - a_adult) / (d_adult*x+c_adult), from = -3, to = -.53, add = TRUE)
#curve ((-b_adult*x - a_adult) / (d_adult*x+c_adult), from = -.52, to = 4, add = TRUE)

curve ((-b_child*x - a_child)/ (c_child), from = -3, to = 3, add = TRUE)
#curve ((-b_child*x - a_child) / (d_child*x+c_child), from = -3, to = -.53, add = TRUE)
#curve ((-b_child*x - a_child) / (d_child*x+c_child), from = -.52, to = 4, add = TRUE)


plot (aggd$vtl,aggd$f0, cex =1.2, col = cols[c(2:5)][factor(aggd$C)], 
      pch=16,lwd=2, xlab = "",ylab="Height (inches)")
grid()
points (aggd$vtl, aggd$f0, cex =1.2, pch=16,lwd=2,
      col = cols[c(2:5)][factor(aggd$C)])

#curve ((-b_all*x - a_all) / (c_all), from = -3, to = 3, add = TRUE)
curve ((-b_all*x - a_all) / (d_all*x+c_all), from = -6, to = -.53, add = TRUE)
curve ((-b_all*x - a_all) / (d_all*x+c_all), from = -.52, to = 6, add = TRUE)

#curve ((-b_adult*x - a_adult)/ (c_adult), from = -3, to = 3, add = TRUE)
curve ((-b_adult*x - a_adult) / (d_adult*x+c_adult), from = -6, to = -c_adult/d_adult, add = TRUE)
curve ((-b_adult*x - a_adult) / (d_adult*x+c_adult), from = -c_adult/d_adult, to = 6, add = TRUE)

#curve ((-b_child*x - a_child)/ (c_child), from = -3, to = 3, add = TRUE)
curve ((-b_child*x - a_child) / (d_child*x+c_child), from = -6, to = -c_child/d_child, add = TRUE)
curve ((-b_child*x - a_child) / (d_child*x+c_child), from = -c_child/d_child, to = 6, add = TRUE)

plot (aggd$vtl,aggd$f0, cex =1.2, col = cols[c(2:5)][factor(aggd$C)], 
      pch=16,lwd=2, xlab = "",xlim = c(-4,4),ylim = c(-2,2),
      ylab="Height (inches)")
grid()
points (aggd$vtl, aggd$f0, cex =1.2, pch=16,lwd=2,
      col = cols[c(2:5)][factor(aggd$C)])

#curve ((-b_all*x - a_all) / (c_all), from = -3, to = 3, add = TRUE)
curve ((-b_all*x - a_all) / (d_all*x+c_all), from = -6, to = -.53, add = TRUE)
curve ((-b_all*x - a_all) / (d_all*x+c_all), from = -.52, to = 6, add = TRUE)

#curve ((-b_adult*x - a_adult)/ (c_adult), from = -3, to = 3, add = TRUE)
curve ((-b_adult*x - a_adult) / (d_adult*x+c_adult), from = -6, to = -c_adult/d_adult, add = TRUE)
curve ((-b_adult*x - a_adult) / (d_adult*x+c_adult), from = -c_adult/d_adult, to = 6, add = TRUE)

#curve ((-b_child*x - a_child)/ (c_child), from = -3, to = 3, add = TRUE)
curve ((-b_child*x - a_child) / (d_child*x+c_child), from = -6, to = -c_child/d_child, add = TRUE)
curve ((-b_child*x - a_child) / (d_child*x+c_child), from = -c_child/d_child, to = 6, add = TRUE)

```

does this matter? yes and no. does it matter that the earth is not round but our maps mostly act like it is? its flat enough in the area that we are using our map for, and so we can act like its flat. what do we want to do with our model? inspect only the region of the boundary where we have data? Or leally understand whats going ion in general even in area where we dont hae data but are fairly likely e know whats going on. 




```{r, eval = FALSE}
model_height_vtl_f0 = add_criterion(model_height_vtl_f0,"loo")
model_height_vtl_f0 = add_criterion(model_height_vtl_f0,"loo")
model_random_slopes_complex = add_criterion(model_random_slopes_complex,"loo")

loo_compare (model_height_vtl_f0, model_height_vtl_f0,model_random_slopes_complex)

```


```{r, include = TRUE, eval = FALSE}
# Or download it from the GitHub page:
model_random_slopes_complex = bmmb::get_model ('9_model_random_slopes_complex.RDS')
```
```{r, include = FALSE, eval = FALSE}
model_random_slopes_complex = readRDS ('../models/9_model_random_slopes_complex.RDS')
```



```{r, eval = FALSE}
qq = banova (model_height_vtl_f0, superpopulation = TRUE)

```

```{r, eval = FALSE}
par (mar = c(8,4,1,1))
banovaplot (qq[-2,], las = 2)
```




```{r, eval = FALSE}
qq = banova (model_gender_vtl_f0, superpopulation = TRUE)

```

```{r, eval = FALSE}
par (mar = c(8,4,1,1))
banovaplot (qq, las = 2)
```



```{r, include = FALSE, eval = FALSE}
# Or download it from the GitHub page:
model_gender_vtl_f0_int = bmmb::get_model ('11_model_gender_vtl_f0_int.RDS')
```
```{r, include = FALSE, eval = FALSE}
# saveRDS (model_gender_vtl_f0_int, '../models/11_model_gender_vtl_f0_int.RDS')
model_gender_vtl_f0_int = readRDS ('../models/11_model_gender_vtl_f0_int.RDS')
```



