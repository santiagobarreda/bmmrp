\newpage
```{r, include = FALSE}
knitr::opts_chunk$set(
  dpi = 300, dev = "jpeg", collapse=TRUE
)
#options(knitr.duplicate.label = "allow")
```
# Multiple quantitative predictors, dealing with large models, and Bayesian ANOVA

In this chapter we introduce models with multiple continuous predictors, and interactions between them. After that, we will have covered the modeling concepts necessary to fit most models of the sort used for experimental data. The models you fit to you own data will include some combination of the elements covered in the previous chapters, and can potentially result in large models with hundreds of parameters. Traditionally, models with many predictors have had three general problems:

  1) A model may return spurious values for the 'extra' predictors, leading to incorrect conclusions.
  2) The model may not fit/converge, meaning you can't get the model coefficients. 
  3) It can be difficult to interpret a model with *hundreds* of parameters.

In this chapter we're going to cover a Bayesian approach to working with large models. We're going to discuss how working with multilevel Bayesian models can naturally help us with problems (1) and (2) above, and we're going to discuss an easy way to approach the third problem also. 
  Before continuing, we should note that designs with many continuous predictors, factors, and interactions between these can result in very complicated models, which then have to be interpreted. However, the researcher has a big role to play in the complexity of the eventual analysis that they are faced with. Once when Santiago was buying a backpack for traveling, he was looking for the biggest backpack possible. One of the reviews said "1/5 stars, it was way too heavy when I filled it all the way up with my stuff". However, if we fill a backpack up with heavy things, it doesn't seem fair to blame the poor backpack when it becomes difficult to manage, does it? In the same way, if you are faced with a complex model that you then need to interpret, you shouldn't blame the model (or `brms`) for your predicament. In order to avoid a situation where you end up with data you can't analyze or a model you don't know how to interpret, it's worth considering the following questions before advancing to data collection stage of your experiment: 

  * How will I analyze the data? Will I be able to? 
  * What will the model structure be? 
  * What would different results 'mean'? How will this manifest in my regression model?
  * What kind of results am I expecting? 
  
## Models with multiple continuous predictors

- make clear each predictor is a dimension
- check out what Ive said about dimensions before

Our regressions so far have only involved a single quantitative predictor. This means that the relationship between the dependent variable and our predictor formed shapes with a single dimension: Lines. In the left and middle plots in figure \@ref(fig:F11-1) we see the linear relationships between speaker vocal-tract length (VTL), and f0 (voice pitch), with apparent speaker height. In each case, the expected value for the y-axis variable is the value of the line at each x-axis location. The residual, that is the prediction error, for each observation is the vertical distance between the line the observation.   
  Rather than think of the effect of VTL and f0 on apparent height individually, we can think about apparent height, VTL, and f0 together at the same time. We can imagine that each point in figure \@ref(fig:F11-1) has a specific value of f0, VTL, and apparent height. These three quantitative variables define a specific location in a 3-dimensional space. For example, consider any given location in the room you are sitting in right now. Any such location can be specified using a variable that determines is location along the width, depth, and height of the room. Imagine you had a clear plastic cube containing points arranged as in \@ref(fig:F11-1) inside it, where each dimension along the cube represented one of the dimensions in the figure. Looking 'through' the cube at different orientations would result in arrangements just like the plots below. The first plot show the view through the VTL side, and the second plot shows the view down the f0 side, a 1/4 rotation of the cube. The final plot shows the view down through the top of the cube.  
  
```{r F11-1, fig.height = 3, fig.width = 8, fig.cap='(left) Average apparent height reported for each speaker plotted against speaker VTL. Point size reflects average apparent height. (middle) Same as the left plot but comparing apparent height to f0. (right) A comparison of VTL and f0 for each speaker.', echo = FALSE, cache = TRUE}

###############################################################################
### Figure 11-1
###############################################################################

agg_data = aggregate (height~f0+vtl+C_v, data = bmmb::exp_data, FUN=mean)
agg_data = agg_data[nrow(agg_data):1,]

ptcex = agg_data[,4] - min(agg_data[,4])
ptcex = 1 + (ptcex / max(ptcex))*1.5

par (mfrow = c(1,3), mar = c(4,4,1,1))
plot (agg_data[,c(2,4)],pch=16,col = bmmb::cols[2:5][factor(agg_data[,3])], 
      cex=ptcex)
abline (lm(agg_data[,c(4)]~agg_data[,c(2)]),lwd=2,lty=2)
grid()
plot (agg_data[,c(1,4)],pch=16,col = bmmb::cols[2:5][factor(agg_data[,3])], cex=ptcex)
abline (lm(agg_data[,c(4)]~agg_data[,c(1)]),lwd=2,lty=2)
grid()

plot (agg_data[,c(1,2)],pch=16,col = bmmb::cols[2:5][factor(agg_data[,3])], 
      cex=ptcex)
grid()

```

It may be easier to see what we mean by considering figure \@ref(fig:F11-2), which attempts to present our point in three dimensions. The left plot of figure \@ref(fig:F11-2) corresponds to the left plot in figure \@ref(fig:F11-1), while the right plot of figure \@ref(fig:F11-2) corresponds to the middle plot in figure \@ref(fig:F11-1). If we want to predict apparent height based on speaker f0 and VTL, that is basically asking: Can we predict the height of a point in our 3-dimensional space based on its x and y-axis location? 

```{r F11-2, fig.height = 5, fig.width = 8, fig.cap='(left) A three-dimensional plot of the variables presented in the figure above. (right) The same as the left plot but the cube has been rotated 90 debrees counter-clockwise.', echo = FALSE, cache = TRUE}

################################################################################
### Figure 11.2
################################################################################
agg_data = aggregate (height~f0+vtl+C_v, data = bmmb::exp_data, FUN=mean)

par (mfrow = c(1,2), mar = c(0,1,0,2), oma = c(0,0,0,0))

tmp = agg_data[,c(2,1,4)]
s3d = scatterplot3d::scatterplot3d (tmp, color = bmmb::cols[2:5][factor(agg_data[,3])],
                     pch=16, angle = 55,type = "p",ylim=c(90,310), cex.symbols=rev(ptcex)*.9)
my.lm <- lm(height ~ f0+vtl, data = agg_data)

s3d = scatterplot3d::scatterplot3d (agg_data[,-3], color = bmmb::cols[2:5][factor(agg_data[,3])],
                     pch=16, angle = 55,type = "p",xlim=c(90,310), cex.symbols=rev(ptcex)*.9)
my.lm <- lm(height ~ f0+vtl, data = agg_data)
#s3d$plane3d(my.lm, col = 2)
```

When we have two quantitative predictors, our models predict values along **planes** rather than lines. For example, imagine the points in figure \@ref(fig:F11-2) were floating in the room with you, arranged just as in the figure. You are given a large flat board (a *plane*) and asked to find the "best" position for the board. When we fit lines, we preferred those that tended to minimize the residuals, the y-axis distance of the points to the line. The same principle holds when we fit models with two (or more) quantitative predictors. A Regressions model that includes two continuous predictors tries to find the 'best' plane that passes through your points in the three-dimensional space. In general, the 'best' plane is the one that minimizes the distance from each point to the surface of the plane along the axis representing the dependent variable. Though it's a bit more complicated than this for multilevel models, this is still basically what's happening.  
  Planes are specified by three parameters, a slope for each dimensions and an intercept. In \@ref(eq:11-1) we that the height of the plane along the $z$ axis is determined by an intercept ($a$) plus the product of the x-axis coordinate and its slope ($b$) and the product of the y-axis coordinate and its slope. When we fit a model that includes two quantitative predictors, the model represents the best planes using their $a$, $b$, and $c$ parameters. 
  
$$
\begin{equation}
z =  \mathrm{a} + \mathrm{b} \times x + \mathrm{c} \times y 
(\#eq:11-1)
\end{equation}
$$

  Just like our slope coefficients changed the slope of our lines, our slope coefficients now change the slope of our planes. Since the plane has two dimensions it has two slopes: A field can be downhill away from you, but also be up/downhill left to right. Our intercept coefficients will change the intercepts of our planes, sliding entire planes up/down without changing their slopes. An important aspect of the interpretation of our slope terms is that they are meant to reflect the effect of an independent change along one dimension. Another way to say this is that the slope of each predictor reflects the expected change according to that predictor when all other predictors are *held constant*. As a result, our models specifying planes can also be thought of a series of models specifying lines, as will be discussed below. 
  Our discussion above has been entirely about planes, however, your model can include any number of continuous predictors. The interpretation of these models is a simple continuation of the expansion of models specifying lines to those specifying planes. If your model has $n$ continuous predictors, your data specifies points in an $n+1$ dimensional space, where dimension $n+1$ represents the dependent variable. Residuals in such models would represent the difference between the surface of the $n$ dimensional shape specified by the predictors and the position of each point along the $n+1$ dimension.
  
### Interactions between continuous predictors

Imagine you are standing on a flat cement plaza (a plane). There is a design defect such that as you walk across the plaza, the floor becomes slightly sloped left to right. Further, as you walk across the plaza, the floor becomes progressively more sloped to one side. Rather than a plane, the shape of the floor of this plaza would be a **hyperbolic parabaloid**, more commonly known as a **saddle** shape (because of its resemblance to a horse saddle). The function for a saddle shape can be seen below, where the height of the surface is equal to the product of its $x$ and $y$ coordinates. 

$$
\begin{equation}
z =  x \times y 
(\#eq:F11-2)
\end{equation}
$$

In figure \@ref(fig:F11-3) we can see a comparison of a plane and two saddle shapes. In the middle left plot we can see the analogy of the plaza with the sloping floor. If we were walking "into" the plot the ground would first be sloping down left to right, but gradually changes so that it it sloping up left to right by the end of the surface. 

```{r F11-3, fig.height = 6, fig.width = 8, fig.cap='(top row) Three perspectives of the same plane. (middle row) Three perspectives of the same saddle shape. (bottom row) Three perspectives of the sum of the plane and the saddle shape in the top two rows.', echo = FALSE, cache = TRUE}

################################################################################
### Figure 11.3
################################################################################

f1 = function (a,b,c) a * 1 + b *1  
f2 = function (a,b,c) a*b*2
f3 = function (a,b,c) a * 1 + b *1 + a*b*2

x <- y <- seq(-1, 1, length= 12)

par (mfrow = c(3,3), mar = c(1,1,0,0), oma = c(0,0,0,0))

z <- outer(x, y, f1)
persp(x, y, z, col = bmmb::cols[2],theta = 0,zlim = c(-3,3))
persp(x, y, z, col = bmmb::cols[2],theta = -90,zlim = c(-3,3))
persp(x, y, z, col = bmmb::cols[2],theta = 45,zlim = c(-3,3))

z <- outer(x, y, f2)
persp(x, y, z, col = bmmb::cols[3],theta = 0,zlim = c(-3,3))
persp(x, y, z, col = bmmb::cols[3],theta = -90,zlim = c(-3,3))
persp(x, y, z, col = bmmb::cols[3],theta = 45,zlim = c(-3,3))

z <- outer(x, y, f3)
persp(x, y, z, col = bmmb::cols[4],theta = 0,zlim = c(-3,5))
persp(x, y, z, col = bmmb::cols[4],theta = -90,zlim = c(-3,5))
persp(x, y, z, col = bmmb::cols[4],theta = 45,zlim = c(-3,5))

```

We can combine a plane and a saddle shape, as in the bottom row of figure \@ref(fig:F11-3). The general formula for such a shape is presented below, and we've placed the terms in parentheses just to make it easier to interpret the equation. 

$$
\begin{equation}
z =  \mathrm{a} + (\mathrm{b} \times x) + (\mathrm{c} \times y) + (\mathrm{d} \times xy)
(\#eq:F11-3)
\end{equation}
$$

What does any of this mean for our regression models? We discussed above that models with two continuous predictors model variation in the dependent variable along planes. The 'interaction' between quantitative variables in regression models is represented by the **cross-product**, the multiple, of the two variables. So, the interaction of quantitative predictors results in a saddle shape as defined in \@ref(eq:F11-2). When our models include effects for $x$, $y$, *and* their interactions, we are effectively modeling a surface that combined a plane and a saddle shape, as in \@ref(eq:F11-3). 

Interaction terms represent conditional effects, and allow for the effect of a predictor to vary according to the value of some other predictor. When it comes to quantitative predictors, if two predictors interact it means that the slope of a predictor continuously increase/decreases as a function of the value of the other predictor.


When we include the interaction between quantitative predictors in our models we  

- independent dimension
- cross product
- centering is advised


## Data and research questions

Our previous model was good, but it was missing an obvious and important predictor: the fundamental frequency of the speaker's voice (f0). The fundamental frequency of a sound is the main acoustic correlate of perceived pitch. We know from previous studies that, in general, speakers with lower speaking f0s tend to be identified as taller. In this section, we're going to fit a model that tries to predict apparent height from VTL and f0, and the interaction of the two. 

```{r, warning=FALSE, message=FALSE}
library (brms)
library (bmmb)
options (contrasts = c('contr.sum','contr.sum'))

data (exp_data)
```

We center our continuous predictors, and also scale f0 so that it has about the same magnitude as the VTL effect.  

```{r}
exp_data$vtl_original = exp_data$vtl
exp_data$vtl = exp_data$vtl - mean (exp_data$vtl)

exp_data$f0_original = exp_data$f0 
exp_data$f0 = exp_data$f0 - mean(exp_data$f0)
exp_data$f0 = exp_data$f0 / 100
```

We're not going to have well-defined research questions this time. Instead, we have a sort of vague one that we will try to deal with:

Q1) What do we do with all these parameters? How do we know what to focus on and where to begin?

### Description of the model

We're going to begin with a models that includes all possible interactions between our predictors, and also includes listener-dependent versions of all of our 'fixed' effects predictors. Models of this sort are sometimes referred to as **maximal** models because they include all predictors, interactions, and 'random effects' supported by the data. Our model formula is:

`height ~ vtl*f0*A*G + (vtl*f0*A*G|L) + (1|S)`

We're going to use the same priors we used for our regression models in chapter 9. We won't present the full model description as this is way too long at this point. However, we can talk about all of our model coefficients and what they mean for our model. And below is an 'expanded' version of our model that spell out all of the included parameters.

```
height ~ Intercept + vtl + f0 + A + G + A:G1 + vtl:f0 + vtl:A + vtl:G1 + f0:A + 
         f0:G1 + vtl:f0:A + vtl:f0:G1 + vtl:A:G1 + f0:A:G1 + vtl:f0:A:G1
```

We can group these parameters together based on the way they affect the surfaces [@@ - SB - shapes? whats the general term I should be using here?] represented by our model: Intercept parameters (`a`), VTL slope parameters (`b`), f0 parameters (`c`), and VTL:f0 interaction parameters (`d`).

```
a = Intercept + A        + G        + A:G 
b = vtl       + vtl:A    + vtl:G    + vtl:A:G
c = f0        + f0:A     + f0:G     + f0:A:G
d = vtl:f0    + vtl:f0:A + vtl:f0:G + vtl:f0:A:G
```

We said we weren't going to provide a formal definition of this model,but if we had the first few lines might have looked something like this: 

$$
\begin{equation}
\begin{split}
height_{[i]} \sim \mathrm{t}(\mu_{[i]},\sigma, \nu) \\ 
\mu_{[i]} = a_{[i]} +  (b_{[i]} \times \mathrm{vtl}_{[i]}) + (c_{[i]} \times \mathrm{f0}_{[i]}) + (d_{[i]} \times \mathrm{f0}_{[i]} \times \mathrm{vtl}_{[i]}) \\ \\
\mathrm{and \; more} \ldots
\end{split}
(\#eq:11-4)
\end{equation}
$$

And the lines below that would have described $a$, $b$, $c$, and $d$ as the sum of the model. Notice that there is a symmetry to the parameters for each 'dimension' in our model. Each one contains a 'main effect' term (`Intercept,A, G, A:G`), an interaction with apparent age (`A, vtl:A, f0:A, vtl:f0:A`), an interaction with apparent gender (`G, vtl:G, f0:G, vtl:f0:G`), and an interaction with apparent age *and* gender (`A:G, vtl:A:G, f0:A:G, vtl:f0:A:G`). 

### Fitting the model

```{r, eval = FALSE}
# Fit the model yourself
set.seed (1)
options (contrasts = c('contr.sum','contr.sum'))

priors = c(brms::set_prior("student_t(3,160, 12)", class = "Intercept"),
           brms::set_prior("student_t(3,0, 12)", class = "b"),
           brms::set_prior("student_t(3,0, 12)", class = "sd"),
           brms::set_prior("lkj_corr_cholesky (2)", class = "cor"), 
           brms::set_prior("gamma(2, 0.1)", class = "nu"),
           brms::set_prior("student_t(3,0, 12)", class = "sigma"))

model_height_vtl_f0 =  
  brms::brm (height ~ vtl*f0*A*G + (vtl*f0*A*G|L) + (1|S), data = exp_data, chains = 4, cores = 4,
       warmup = 1000, iter = 5000, thin = 4, prior = priors, family = "student")
```
```{r, include = TRUE, eval = FALSE}
# Or download it from the GitHub page:
model_height_vtl_f0 = bmmb::get_model ('11_model_height_vtl_f0.RDS')
```
```{r, include = FALSE, eval = TRUE}
# saveRDS (model_height_vtl_f0, '../models/11_model_height_vtl_f0.RDS')
model_height_vtl_f0 = readRDS ('../models/11_model_height_vtl_f0.RDS')
```

We're going to leave a discussion of the properties of the model to the next section where we present some advantages of working with Bayesian models over some more 'traditional' approaches. 

### Advantages of Bayesian multilevel models for large models

At this point we have enough model components to build very large and complicated models, like the one we fit above. Traditionally, models with many predictors have presented three general problems. First, a model with 'too many' predictors may return spurious values for the 'extra' predictors. Sometimes these spurious values are difficult to distinguish from the 'real' parameters, leading to incorrect conclusions. Second, the model may not be able to fit/converge on a solutions, meaning you can't get the model coefficients. Regardless of the approach to parameter estimation, more-complicated models make it more and more difficult for any estimation to 'find' the optimal parameter values given the data. Third, it can be difficult to interpret a model with *hundreds* (or thousands) of parameters. This becomes especially problematic when considered together with problem (1), that some of these values may simply represent noise. In this section we're going to discuss how working with multilevel Bayesian models can naturally help us with problems (1) and (2) above. In the following section we will discuss how our models can also help us resolve the third problem above.  
  The Bayesian models fit by `brms` have three properties that help resolve the first two problems above. First, the use of prior probabilities and shrinkage, when properly applied, tend to 'pull' weakly-supported parameter values closer to the group mean (or to zero). This can help reduce many of the problems associated with models with large numbers of parameters (cite). Second, the fact that confidence intervals are provided for all parameters helps distinguish random variation from variation that is likely to consistently vary from zero. Third, the fact that our models do not try to find *the* best solution, but simply sample the posterior distribution, relieves much of the pressure associated with finding *the* best solution for models with large numbers of parameters. 
  To this point we have not discussed the `lmer` function very much, apart from in 'Frequentist corner' at the end of some chapters. The `lmer` function (linear mixed-effects regression) is an extremely popular and extremely useful function. In general, `lmer` and an equivalent model specified in `brms` should provide reasonably similar answers when fitting the same models. However, there are some important differences between the two approaches. First, rather than provide a samples of value for each parameter, `lmer` returns *point estimates* representing the *best* values of parameters. This can cause a problem when parameters are bounded, or grow without bound. For example, standard deviation parameters (e.g., $\sigma$) cannot be 0 or negative, but sometimes they are very, very small. So, when `lmer` tries to find the 'best' value, it can get closer, and closer, and closer to zero, leading to problems involving calculations with very small values (e.g., as $x$ approaches $0$, $1/x$ approaches $\infty$). In contrast, Bayesian models don't try to find the single 'best' value but instead collect a series of samples. As a result, the models are less likely to encounter problems when they try to estimate values that are very close to boundaries (they just 'bounce' of the boundary as they randomly walk!). A second difference between the `lmer` estimation method and that of our Bayesian multilevel models is that `lmer` doesn't use prior probabilities to estimate any of it's parameters. This can cause some problems when estimating a large number of parameters without enough data. In contrast, `brms` applies 'shrinkage' to all its parameters (at least in principle), which can help avoid some of the problems encountered by `lmer`. 
  We're going to compare the output of `lmer` and `brms` for the model we fit above. Just to be clear, our intention in comparing `lmer` and `brms` is not to compare different statistical *philosophies* or epistemological claims. Our aim is much, much more modest than that. We simply wish to compare `brms`, an approach that 1) uses priors, 2) provides confidence intervals, and 3) estimates based on posterior samples, to one that does not (`lmer`). 
  Below we fit a model equivalent to `model_height_vtl_f0` using `lmer`.

```{r, eval = FALSE}
lme_model_height_vtl_f0 =
  lme4::lmer (height ~ vtl*f0*A*G + (vtl*f0*A*G|L) + (1|S), 
              data=exp_data,verbose = TRUE,
              control=lme4::lmerControl(optCtrl=list(maxfun=20000),optimizer="bobyqa"))
```
```{r, include = TRUE, eval = FALSE}
# Or download it from the GitHub page:
lme_model_height_vtl_f0 = bmmb::get_model ('11_lme_model_height_vtl_f0.RDS')
```
```{r, include = FALSE, eval = TRUE}
#saveRDS (lme_model_height_vtl_f0, '11_lme_model_height_vtl_f0.RDS')
lme_model_height_vtl_f0 = readRDS ('../models/11_lme_model_height_vtl_f0.RDS')
```

We won't show the model print statements they are both quite large, but we compare the estimates of our fixed effects in figure \@ref(fig:F11-4). Clearly, the two approaches provide very similar for the model fixed effects. That's reassuring! If results differed dramatically for approximately the same model based on the software used, we would need to think very carefully about the causes and possible meaning of these differences.
  Since our model has a large number of parameters we are going to focus on interpreting those that seem likely to result in 'meaningful' differences in apparent height. We define meaning differences as those that 1) are likely to be different from zero, *and* 2) have magnitudes of at least around 1 cm (about 0.5 inches). We establih this lower limit simply based off the fact that people may describe themselves as 175 cm (or 5'10.5") but rarely make distinctions smaller than that (e.g. people rarely distinguish 5'10.5" and 5'10.75"). 
  Our model suggests non-zero slopes for our plane along the VTL (mean = 3.09, s.d. = 0.63, 95% C.I = [1.84, 4.34]) and f0 dimensions (mean = -3.34, s.d. = 1.27, 95% C.I = [-5.88, -0.86]). However, the `vtl:f0` interaction does not seem to matter at all (mean = -0.72, s.d. = 0.96, 95% C.I = [-2.65, 1.17]). This means that, overall, our responses can be defined by a plane along f0 and VTL without curving the plane into a saddle shape. The `vtl:A1` interaction suggests a differing use of VTL based on apparent adultness, but there do not appear to be any other meaningful interactions between VTL, f0 and the other predictors. In terms of intercept terms (i.e. those not interacting with quantitative predictors), there is a large effect for apparent age (mean = 7.04, s.d. = 1.13, 95% C.I = [4.85, 9.28]) but no main effect for apparent gender (mean = -0.06, s.d. = 0.71, 95% C.I = [-1.43, 1.35]). However, the interaction between apparent age and apparent gender (`A1:G1`) had a 95% credible interval that did not overlap with zero and had a posterior mean value of -1.49 cm (s.d. = 0.51, 95% C.I = [-2.48, -0.44]). This indicates that although apparent gender had an average effect of about 0 cm on apparent height it may have had meaningful, but opposite, effects based on the apparent gender of the speaker. 
  In order to interpret our predictors in the presence of interactions, we need to consider the simple effects. For example, in order to consider the `vtl:A1` interaction we need to consider the simple effect of VTL for apparent children, and then for apparent adults. This is done in exactly the same manner as outlined in chapter 9 and 10 for quantitative predictors, independently for each predictor or interaction (i.e. cross-product) between predictors.  We're not going to go over the interpretation of the coefficients and the reconstruction of the simple effects here, as this has been discussed in detail elsewhere (section X). 

```{r F11-4, fig.height = 3.5, fig.width = 8, fig.cap='A comparison of fixed effect estimates provided by the brms (red) and lmer (black) models. The brms intervals are the 95% credible intervals, those for lmer are twice the standard error of the parameter estimate.', echo = FALSE, cache = TRUE}

################################################################################
### Figure 11.4
################################################################################
pts = fixef (lme_model_height_vtl_f0)[-1]
err_bars = summary (lme_model_height_vtl_f0)$coefficients[-1,2]

par (mfrow = c(1,1), mar = c(6,4,1,1))
bmmb::brmplot (fixef (model_height_vtl_f0)[-1,], ylim = c(-7,10),las=2)
points ((1:15)+.2, pts, cex=1.5,lwd=2,col=2,pch=16)
segments((1:15)+.2, pts-2*err_bars,(1:15)+.2, pts+2*err_bars,lwd=2,col=2)

abline (h = c(-1,1), lty = 3, col = bmmb::cols[6],lwd=2)
```

Figure \@ref(fig:F11-5) presents some ways in which the information provided by `lmer` and `brms` differ. In the top row we see a comparison of the 'random effects' standard deviation estimates provided by our two models, and the error terms estimated by our two models. For example, the standard deviation of the listener f0 'random effect' ($\sigma_{f0 \colon L}$) represents the variation around zero of the listener-specific effects for f0 in each model. As we can see, the models provide reasonably similar standard deviation estimates for most parameters. However, note that the `brm` models provide credible intervals for all parameters, while the `lmer` models only provide point estimates for these parameters. The lack of intervals on parameter estimates makes it difficult to 'rule out' variance parameters since they will *never* equal exactly zero. So, we will always have non-zero numbers for these parameters, and 'secretly' some of these are zero or nearly zero. In addition, variance components very close to zero can cause problems when estimating our models. For example, fitting our model with `lmer` resulted in the following error: 

`boundary (singular) fit: see help('isSingular')`

Which warns us that some of the variance components we are trying to estimate are quite small. Because `bmrs` simply samples from the posterior and doesn't try to find *the* best model parameters, it does not run into these problems. In addition, we can use our credible intervals to figure out which variance components are unlikely to matter: Variance components whose credible intervals are concentrated near zero. There are several such components in the figure below. In the *best case*, many of these components reflect a tiny amount of systematic variation in our outcomes and so are unlikely to matter much. Notice that the magnitude of the standard deviations makes it difficult to predict which standard deviation parameters are distinguishable from zero. This makes the point estimates of limited utility for this purpose in the absence of intervals around our estimates.
  In the middle panel of figure \@ref(fig:F11-5) we see a comparison of the listener-dependent `A1` 'random effects' estimated using the two approaches. Just as with the estimates of the fixed effect in In the middle panel of figure \@ref(fig:F11-4) we see a close alignment between the two. However, just as for our standard deviation terms we see that a lack of intervals around our estimates makes it difficult to compare our parameter estimates to specific values (such as zero). 

```{r, F11-5, fig.height = 6, fig.width = 8, fig.cap='Points and intervals represent means and 95% credible intervals for brms parameter estimates for `model_height_vtl_f0`. Crosses indicate point estimates provided in `lme_model_height_vtl_f0`. (top) Estimates of random effect standard deviations. (middle) Estimates for the listener dependent effects of apparent age. (bottom) Estimates of correlations between random effects.', echo = FALSE, cache = TRUE}

################################################################################
### Figure 11.5
################################################################################

Ssd = attr(VarCorr(lme_model_height_vtl_f0)[[1]],'stddev')
Lsd = attr(VarCorr(lme_model_height_vtl_f0)[[2]],'stddev')
lmer_vars = c(Lsd, Ssd, sigma(lme_model_height_vtl_f0))
vars_final = bmmb::getsds(model_height_vtl_f0)

layout (m=1:3, heights = c(.4,.3,.3))
par (mar = c(7,4,.5,1))
bmmb::brmplot (vars_final, ylim = c(0,8.5), las = 2,cex.axis=1.3,
               col=bmmb::cols[14],yaxs="i")
points (lmer_vars, cex=3,lwd=3,col=bmmb::cols[2],pch=4)

pts = ranef(lme_model_height_vtl_f0)$L[,4]

par (mar = c(.5,4,.5,1))
bmmb::brmplot (ranef(model_height_vtl_f0)$L[,,4],labels="", col = bmmb::cols[8])
points ((1:15), pts, cex=3,lwd=3,col=bmmb::cols[7],pch=4)


corrs_lme = attr(VarCorr(lme_model_height_vtl_f0)$L,"correlation")
corrs_lme = corrs_lme[lower.tri (corrs_lme)]
corrs_brms = bmmb::getcorrs(model_height_vtl_f0, "L")

bmmb::brmplot (corrs_brms, ylim = c(-.97,.97), las = 2, labels = "",line=FALSE,col=bmmb::cols[4])
abline (h=0)
points (corrs_lme, cex=1.5,lwd=3,pch=4, col = bmmb::cols[12])

```

In the bottom panel of figure \@ref(fig:F11-5) we compare the correlations for the listener random effects. Since there were 16 listener-dependent parameters, we needed to estimate 120 unique correlations between these effects. As with our standard deviation parameters, `brms` gives us intervals while `lmer` returns point estimates. In addition, for the first time we see a substantial difference between the estimates provided by `lmer` and those provided by `brms`. This is likely a result of the fact that `lmer` does not apply something like partial pooling to its correlation estimates, either through the use of prior probabilities or other mechanisms. As a result, we see that the `lmer` estimates vary substantially around 0 while the `brms` estimates are all close to zero, and mostly have intervals that include zero. We see that in this case our Bayesian model protects us by: 1) Providing credible intervals for all parameters, letting us accept values of zero as likely, and 2) the LKJ prior we used for our random effect correlation matrices pulls weakly-supported correlations to zero, thereby protecting against spurious results. 
  The fact that most of our correlation estimates are nearly zero not only lets us rule some out, but also focuses our attention to those correlations that deviate from this pattern. For example, the third correlation from the left in the bottom panel of figure \@ref(fig:F11-5) represents the correlation between the listener-dependent intercepts and effects for apparent age. Although its 95% credible interval includes some very small values near zero (mean = -0.38, s.d. = 0.17, 95% C.I = [-0.69, -0.01]), it seems reasonable that this correlation may in fact be negative and non-zero. In fact, we found this correlation in a previous model (section X) and also discussed why we think this correlation 'makes sense' (section X). 
  
## Bayesian Analysis of Variance

The information we considered in the previous section can be used to considered which predictors, or groups of predictors, might be important in our models. This approach becomes increasingly more useful as our models increase in complexity and end up with dozens or hundreds of parameters. This approach is presented is presented by Gelman and colleagues in Gelman anova paper, Gelman and hill chapter 22, and Gelman et al BDA3 chapter. 
  The analysis of variance (ANOVA) is a set of modeling techniques meant to help understands the components and sources of variation in a dependent variables. We're not going to talk about a 'traditional' ANOVA in any detail here, as it would involve the introduction of a *parallel universe* of statistical concepts and jargon that has not been discussed in this book. There are many excellent treatments on the subject including myers and well and cite others. That being said, at its core ANOVA consists of thinking of variation in the dependent variable as the sum of variation of a set of **components of variation** related to the predictors in our model. For example, we can think of the total variation in apparent height judgments as related to variation according to apparent age, listener-dependent intercepts, and so on, until we get to all the variance we *can't* explain, and we just call that the *error* ($\sigma$). 
  
  - what we did above was an anova-like decomposition. 
  
  A 'traditional' ANOVA tries to **decompose** variation into independent components so that it can relate combinations of these as ratios in order to carry out different statistical tests. That approach is fundamentally different to the sorts of things we have been doing with our multilevel models. However, the general approach of decomposing variation in our dependent variable into separate components is very useful, especially for larger models. Here's what Gelman and Hill have to say about the analysis of variance in the context of multilevel models:

> "When moving to multilevel modeling, the key idea we want to take from the analysis of variance is the estimation of the importance of different batches of predictors (“components of variation” in ANOVA terminology). As usual, we focus on estimation rather than testing: instead of testing the null hypothesis that a variance component is zero, we estimate the standard deviation of the corresponding batch of coefficients. If this standard deviation is estimated to be small, then the source of variation is minor—we do not worry about whether it is exactly zero. In the social science and public health examples that we focus on, it can be a useful research goal to identify important sources of variation, but it is rare that anything is truly zero." (p. 490)

> "the standard deviation of a set of coefficients gives a sense of their predictive importance in the model. An analysis-of-variance plot, which shows the relative scale of different variance components, can be a useful tool in understanding a model." (p. 492)

  These standard deviations directly reflect the amount of variation in these parameters in our model. Parameters that vary a lot reflect large effects on our data. These will be represented by large standard deviations. In contrast, parameters that do not vary much will be represented by small standard deviations. These parameters do not have a large effect on our data (since they do not vary much). For example, we can see in figure \@ref(fig:F11-5) that the standard deviation of listener-dependent intercepts ($\sigma_L$) is much larger than the listener-dependent VTL by apparent gender interaction ($\sigma_{VTL \colon G \colon L}$). We can see that this directly relates to the variation of each batch of 'random effects' around zero, as shown in figure \@ref(fig:F11-6). Whether or not $\sigma_{VTL \colon G \colon L}$ is exactly zero, we can look at figure \@ref(fig:F11-6) and see that this predictor does not predict much variation in our dependent variable. As a result of this, we can take one look at figure \@ref(fig:F11-5) and see that although there are a large number of predictors, only a couple are having any meaningful effect on apparent height judgments. 
  
```{r, F11-6, fig.height = 3, fig.width = 8, fig.cap='Listener-dependent intercepts (circles) and `vtl:G1` interactions (triangles).', echo = FALSE, cache = TRUE}

################################################################################
### Figure 11.6
################################################################################

par (mfrow = c(1,1), mar = c(4,4,1,1))

brmplot (ranef (model_height_vtl_f0)$L[,,"Intercept"], col = bmmb::cols[9], 
         line=TRUE)
brmplot (ranef (model_height_vtl_f0)$L[,,"vtl:G1"], add = TRUE, 
         nudge = 0.1, labels = "", col = bmmb::cols[10],pch=17)
```
  
Gelman and Hill distinguish between two types of standard deviations for a 'random' effect with $J$ levels (p. 459) (emphasis ours):

> "• The **superpopulation** standard deviation , which represents the variation among the modeled probability distribution from which the were drawn, is relevant for determining the uncertainty about the value of a new group not in the original set of J." 

> "• The **finite-population** standard deviation of the particular J values of [$\alpha_{[subj]}$] describes variation within the existing data." 

  So, the *finite-population* standard deviation terms are reflect the variation we observe in our actual model parameters. This concept can be extended to both batches of 'random' effects estimated with adaptive partial pooling and to 'fixed' effects estimated without it. Tthe *superpopulation* standard deviation estimates correspond to the specific $\sigma$ term estimated by our model for different batches of 'random' effects, and no analogue exists for our 'fixed' effects. The authors note that (p. 464):

> "The superpopulation [σ] and finite-population [s] standard deviations are not two different statistical “estimators” of a common quantity; rather, they are two different quantities that can both be estimated from the multilevel model. We can get a point estimate and uncertainty intervals for both. In general, the point estimates of σ and s will be similar to each other, but s will have less uncertainty than σ. That is, the variation is more precisely estimated for the finite population than the superpopulation. This makes sense because we have more information about the units we observe than the full population from which they are sampled."

Gelman and colleagues suggest the following general process, that can be referred to as a **Bayesian analysis of variance**, or **BANOVA**:

  1) Fit the model with the structure you think is required to capture the variation in the data. 
  
  2) Calculate the superpopulation and finite-population standard deviations for predictors or groups of predictors. 
  
  3) Make a plot comparing the magnitudes of different predictors, and of the uncertainty in the estimates. The authors refer to this as an **
  
  4) Us the ANOVA plot to make inferences about the relative importance of your predictors, and to guide your analysis. 
  
We could potentially add a fifth step: 5) refit reduced model if some components show little to no importance or variation across clusters, and if you have some compelling reason to do so. This step is not strictly necessary, but we will consider it as a possibility. 
  
### Getting the standard deviations from our models 'manually'

The superpopulation standard deviation is our model's estimate of the standard deviations of different batches of parameters. We can extract the superpopulation standard deviations using the `VarCorr` function. This function returns all sort of information about the variance anf correlation parameters estimated by our model. In the second line below we specify that we only want information related to the standard deviation (`"sd"`) of our listener effects (`"L"`).

```{r, cache = TRUE, collapse = TRUE, eval = FALSE, cache = TRUE}
brms::VarCorr(model_height_vtl_f0)

brms::VarCorr(model_height_vtl_f0)[["L"]][["sd"]]
```

We can also get information regarding our error standard deviation using `Varcorr` as seen below:

```{r, cache = TRUE, collapse = TRUE, cache = TRUE}
brms::VarCorr(model_height_vtl_f0)$residual$sd
```

The `bmmb` package contains a function called `getsds` that collects estimates of all standard deviations estimated by the model, including the error:


```{r}
getsds (model_height_vtl_f0)
```


Getting the finite-sample standard deviations is a bit trickier. To calculate the standard deviations of different batches of parameters you need to calculate the standard deviation for each batch, *for each sample*. This means you end up with as many samples of the finite-sample standard deviation based on each set of posterior samples. The code below shows how to calculate the finite-population standard deviations for item based on the random effects parameter estimates. 

```{r, cache = TRUE, collapse = TRUE, eval = TRUE}
# extract matrix representing all random effects from our model
listener_intercepts = ranef(model_height_vtl_f0, summary = FALSE)[["L"]][,,"Intercept"]

# the output is a 3d matrix. dimensions are:
str (listener_intercepts)

# we need to find the standard deviation for the item random effects for each 
listener_intercepts_finite = apply (listener_intercepts,1,bmmb::rms)

# the output is a 2d matrix. dimensions are:
# we summarize the output into a matrix where each row represents a single
listener_intercepts_finite = posterior_summary (listener_intercepts_finite)
```

For the fixed effects, we can use the absolute value of the parameters when these are each a single 'degree of freedom' (i.e. a single parameter). The code below shows how to get the fixed effects standard deviation estimates. 

```{r, cache = TRUE, collapse = TRUE, eval = TRUE, cache = TRUE}
# get individual parameter samples
fixefs_finite = fixef(model_height_vtl_f0, summary = FALSE)

# summarize absolute value
fixefs_finite = posterior_summary (abs (fixefs_finite))
```

In cases where we also have batches of fixed effect predictors, the finite-sample standard deviation of these can be estimated using the same approach used for the random effects shown above. Finally, we can estimate the finite-sample error by getting the model residuals, and then calculating the standard deviation of the residuals for each set of samples as shown below.

```{r, cache = TRUE, collapse = TRUE, eval = TRUE}
# get residuals
sigma_finite = residuals (model_height_vtl_f0, summary = FALSE)

# find standard deviation for each set of samples
sigma_finite = apply (sigma_finite, 1, sd)

# summarize
sigma_finite = posterior_summary (sigma_finite)

# name row, because it has no name by default
row.names(sigma_finite) = 'sigma'
```

### Using the `banova` function

The `bmmb` package contains a function called `banova` that can get the finite-sample or superpopulation standard deviations for you. The output is a single dataframe that contains a summary of the standard deviations for fixed and random effects, and the error term if the model contains one. Below we use the function to get both kinds of standard deviation, compared in 

```{r, cache = TRUE, include = FALSE, cache = TRUE}
banova_height_vtl_f0_finite = banova (model_height_vtl_f0, superpopulation = FALSE)
banova_height_vtl_f0_super = banova (model_height_vtl_f0, superpopulation = TRUE)
```

The output of the `banova` function can be used too make a Bayesian ANOVA plot of our model. If we were to do this right after fitting the model, we would have a pretty good idea of what matters and what doesn't in our data. 

```{r F11-7, fig.height = 4.5, fig.width = 8, fig.cap='(top) Finite sample BANOVA plot for `model_height_vtl_f0`. (bottom) The superpopulation BANOVA plot for the same model.', echo = FALSE}

################################################################################
### Figure 11.7
################################################################################

par (mar = c(.125,4,.125,.125), mfrow = c(2,1), oma = c(6.5,0,1,0))
banovaplot (banova_height_vtl_f0_finite[-2,], las = 2,line=FALSE,labels = "",
            yaxs="i", ylim = c(0,10))
abline (h=0)
box()
banovaplot (banova_height_vtl_f0_super[-2,], las = 2, line=FALSE,yaxs="i",
            ylim = c(0,10))
abline (h=0)
box()

```

The process Gelman proposes is potentially more complicated that what I'm doing here. For example, consider the random effects for a factor like vowel category. Imagine there are four categories, so four levels, for each of 50 listeners. The process I've described treats each of the 50 random effects for each vowel separately (i.e., 4 groups of 50 vowel random effects). The process described by Gelman would treat the 200 vowel random effects (across the four vowels) as one 'batch' of coefficients. This single batch would reflect all of the $Listener \colon Vowel$ interaction. The way we are approaching instead separates each $Listener \colon Vowel$ 'simple effect' and treats it separately. The main reason to do it the way way I've shown above is because it can be done easily for all models, and you get roughly equivalent information from the analysis. If you do want to investigate the variation associated with entire clusters of multiple predictors at a time, please see the Gelman articles linked to above, as there are a few important details that are not discussed here (e.g., the need to 'recover' missing parameters, the need to calculate 'degrees of freedom', etc.).

### Fitting and comparing the reduced model

Our initial model formula was:

`height ~ f0*vtl*A*G + (f0*vtl*A*G|L) + (f0*vtl*A*G|S)`

Because we include all interactions and listener 'random effects' of these, we're basically saying that we think its possible for every predictor to affect every other predictor, and for all of this to vary in a listener-dependent manner. We might instead consider the following model formula which includes only those effects we (arbitrarily) deemed 'large enough' based on figures above. 

`height ~ f0 + vtl + A*G + vtl:A1 + (f0 + vtl + A*G + vtl:A1|L) + (1|S)`

Since these are the predictors that varied most between listeners and also affected our dependent variable the most, in some situations we may be justified in fitting a 'final' model that includes only the important components. We fit the reduced model below:

```{r, eval = FALSE}
# Fit the model yourself
set.seed (1)
options (contrasts = c('contr.sum','contr.sum'))

priors = c(brms::set_prior("student_t(3,160, 12)", class = "Intercept"),
           brms::set_prior("student_t(3,0, 12)", class = "b"),
           brms::set_prior("student_t(3,0, 12)", class = "sd"),
           brms::set_prior("lkj_corr_cholesky (2)", class = "cor"), 
           brms::set_prior("gamma(2, 0.1)", class = "nu"),
           brms::set_prior("student_t(3,0, 12)", class = "sigma"))

model_height_vtl_f0_reduced =  
  brms::brm (height ~ f0+vtl+A*G+vtl:A + (f0+vtl+A*G+vtl:A|L) + (1|S),
             data = exp_data, chains = 4, cores = 4, warmup = 1000, 
             iter = 5000, thin = 4, prior = priors, family = "student")
```
```{r, include = TRUE, eval = FALSE}
# Or download it from the GitHub page:
model_height_vtl_f0_reduced = bmmb::get_model ('11_model_height_vtl_f0_reduced.RDS')
```
```{r, include = FALSE, eval = TRUE}
# saveRDS (model_height_vtl_f0_reduced, '../models/11_model_height_vtl_f0_reduced.RDS')
model_height_vtl_f0_reduced = readRDS ('../models/11_model_height_vtl_f0_reduced.RDS')
```

We can see that the fixed effects shared in common are very similar, as are the estimates of the random effects for the listener-dependent parameters.  

```{r F11-8, fig.height = 3, fig.width = 8, fig.cap='(left) . (right) .', echo = FALSE, cache = TRUE}

################################################################################
### Figure 11.8
################################################################################

sds_reduced = getsds(model_height_vtl_f0_reduced)
sds = getsds(model_height_vtl_f0)
use = rownames(sds) %in% rownames(sds_reduced)
sds = sds[use,]

par (mfrow = c(1,2), mar = c(4,4,1,1))
layout (m = t(c(1,2)),widths = c(.55,.45))
brmplot (fixef (model_height_vtl_f0)[c(2,3,4,5,7,11),], ylim = c(-6,10),las=2,
         ylab = "Centimeters")
brmplot (fixef (model_height_vtl_f0_reduced)[c(3,2,4,5,7,6),],
         add = TRUE, nudge = 0.2, col = 2,labels = "")
abline (h=0)

brmplot (sds, las = 2, ylab = "Centimeters")
brmplot (sds_reduced, add = TRUE, col = 2, nudge = .2, labels = "")

```

We use cross-validation to compare the expected model out-of-sample prediction: 

```{r, cache = TRUE}
model_height_vtl_f0 = add_criterion (model_height_vtl_f0, "loo")
model_height_vtl_f0_reduced = add_criterion (model_height_vtl_f0_reduced, "loo")
```

And see that the reduced model has a lower $\mathrm{elpd}$, but that the differences is only about 1.5 standard errors, making it not very reliable. 

```{r}
loo_compare (model_height_vtl_f0,model_height_vtl_f0_reduced) 
```

We can also consider the variance explained ($R^2$) by each model:

```{r}
bmmb::r2_bayes(model_height_vtl_f0)
bmmb::r2_bayes(model_height_vtl_f0_reduced)
```

And see that all of the extra complexity included in our full model gains us less than 1% additional variance explained. All of this suggests that a researcher would be justified in fitting and interpreting the reduced model for their research. However, we are inclined to agree with Gelman and colleagues that there is value in fitting a model that includes all of the realistic variation that may be included in our data, and that is supportable by our data. This means fitting and reporting the larger model. As we have seen, the 'extra' predictors do not seem to affect the parameters we do care about very much. In addition, where they are slightly different it is impossible to 'prove' which values are closer to the 'truth' based only on the performance of the models. In addition, being able to say "these parameters are near zero/show no between-listener variation" is useful information that we lose when we rely only on the reduced model. Of course, we could say something like "we fit a larger model that showed all these effects are zero but we are not presenting it here". However, if we do want to say something like this it may make sense to present the full model to the reader so that they may make their own conclusions and use the information as they see fit. 

## Fitting a multivariate logistic regression model

We're now going to fit a logistic regression model with two quantitative predictors and an interaction between them. We're also going to inspect the model using the principle of BANOVA outlined in the previous section. Before continuing we want to talk briefly about the geometry of the models we will be fitting. A logistic regression model with two continuous predictors specifies planes along a third dimension ($z$) representing the logit of the probability of observing a 'success' (a value of 1). When the value on the surface of these planes is negative, the model predicts a response of 0, and when the value of the plane is positive the model predicts a 1. We can imagine the plane such that $z=0$ representing a probability of 0.5. The planes represented by our models will intersect with these planes, forming a line at this intersection. Since these lines represent a division of our planes into sections with values greater than 0 (expected response 1) and sections with values less than 0 (expected response 0). Thus, the lines formed by the intersection of these planes represent the *category boundary* as defined by our model. When we want to know the probability expected for any given x and y axis location, we can transform the value on the plane using the inverse logit function. When the predicted logits are transformed to probabilities, our model defines a curved shape rather than a flat plane as seen in the bottom row of figure \@ref(fig:11.9). Although these surfaces are are not flat, their intersection with the plane at $z=0.5$ (i.e. the plane where logit = 0) will still form straight lines. 

```{r F11-9, fig.height = 4, fig.width = 8, fig.cap='(top) Threee perspectives on a plane that specifies logits along its z axis. (bottom) The same plane after undergoing to antilogit transform, now expressing probabilities along the z axis.', echo = FALSE, cache = TRUE}

################################################################################
### Figure 11.9
################################################################################

f1 = function (a,b,c) a * 1 + b *1  
x <- y <- seq(-3, 3, length= 12)

par (mfrow = c(2,3), mar = c(1,1,0,0), oma = c(0,0,0,0))

z <- outer(x, y, f1)
persp(x, y, z, col = bmmb::cols[3],theta = 0,zlim = c(-6.5,6.5))
persp(x, y, z, col = bmmb::cols[3],theta = -90,zlim = c(-6.5,6.5))
persp(x, y, z, col = bmmb::cols[3],theta = 45,zlim = c(-6.5,6.5))

z <- outer(x, y, f1)
persp(x, y, ztop(z), col = bmmb::cols[4],theta = 0,zlim = c(0,1))
persp(x, y, ztop(z), col = bmmb::cols[4],theta = -90,zlim = c(0,1))
persp(x, y, ztop(z), col = bmmb::cols[4],theta = 45,zlim = c(-0,1))

```

When our models include interactions between quantitative predictors (i.e. terms representing their cross-products), our predicted values no longer vary along planes. Instead, the surface will resemble a saddle shape based on the sign of the parameter and its magnitude relative to the slopes of the relevant quantitative predictors in the model. Since these shapes can fall and then rise again, a surface of this kind may intersect with the plane at $z=0$ in more than one location (seen in figure \@ref(fig:F11-10)). The intersection between a saddle shape and the plane where $z=0$ will not be a straight line. Instead, it will be a **hyperbola** a shape that resembles a pair of parabolas that approach, but never cross an asymptote. We will return to this issue when we consider the territorial maps implied by our models later on. 

```{r F11-10, fig.height = 4, fig.width = 8, fig.cap='(top) Threee perspectives on a saddle shape that specifies logits along its z axis. (bottom) The same saddle shape after undergoing to antilogit transform, now expressing probabilities along the z axis.', echo = FALSE, cache = TRUE}

################################################################################
### Figure 11-10
#######################\#########################################################

f1 = function (a,b,c) a * 1 + b *1 + a*b*1  

x <- y <- seq(-3, 3, length= 12)

par (mfrow = c(2,3), mar = c(1,1,0,0), oma = c(0,0,0,0))

z <- outer(x, y, f1)
persp(x, y, z, col = bmmb::cols[5],theta = 0,zlim = c(-9.5,15.5))
persp(x, y, z, col = bmmb::cols[5],theta = -90,zlim = c(-9.5,15.5))
persp(x, y, z, col = bmmb::cols[5],theta = 45,zlim = c(-9.5,15.5))

z <- outer(x, y, f1)
persp(x, y, ztop(z), col = bmmb::cols[6],theta = 0,zlim = c(0,1))
persp(x, y, ztop(z), col = bmmb::cols[6],theta = -90,zlim = c(0,1))
persp(x, y, ztop(z), col = bmmb::cols[6],theta = 45,zlim = c(-0,1))

```

### Data and research questions

We load our packages and set our contrasts. We also load our experimental data, focusing on the natural, unmodified resonance. 

```{r, warning=FALSE, message=FALSE}
library (brms)
library (bmmb)
options (contrasts = c('contr.sum','contr.sum'))

data (exp_data)
```

Below we add our dependent variable `F`. This variable equals 1 when the listener indicated hearing a female speaker and 0 when the listener indicated hearing a male speaker. As with our previous model we center our quantitative variables and divide f0 by 100 to make the expected regression coefficient more similar in magnitude

```{r}
# our dependent variable
exp_data$F = as.numeric (exp_data$G == 'f')

exp_data$vtl_original = exp_data$vtl
exp_data$vtl = exp_data$vtl - mean (exp_data$vtl)

exp_data$f0_original = exp_data$f0 
exp_data$f0 = exp_data$f0 - mean(exp_data$f0)
exp_data$f0 = exp_data$f0 / 100
```

Our research questions are:

Q1) Do listeners use VTL, f0, and the interaction between them to determine speaker gender?

Q2) Does apparent speaker age influence the use of the above mentioned acoustic cues?

Q3) Is there a lot of between-speaker variation in perceptual behavior?


### Description of the model

Our model formula is very much like the one we used for our first model in this chapter, however, since we are predicting apparent femaleness we obviously do not include apparent gender as a predictor. Our formula will be:

`F ~ vtl*f0*A + (vtl*f0*A|L) + (1|S)`

We'll use the same priors we used for our logistic models last chapter. Since we scaled f0 so that a change of 1 corresponds to 100 Hz, this value represents about half the difference between adult males and females. For this reason, we think it's reasonable to use a prior of the same magnitude as we used for our VTL parameter. We will omit our model specification since it is quite large and very similar to the one above for `model_height_vtl_f0` and those presented in chapter 10. 

### Fitting and the model and applying a Bayesian ANOVA

Below we fit our model:

```{r, eval = FALSE}
# Fit the model yourself
set.seed (1)
options (contrasts = c('contr.sum','contr.sum'))

model_gender_vtl_f0 =
  brm (F ~ vtl*f0*A + (vtl*f0*A|L) + (1|S), data=exp_data, 
       chains=4, cores=4, family="bernoulli", 
       warmup=1000, iter = 5000, thin = 4,  
       prior = c(set_prior("student_t(3, 0, 3)", class = "Intercept"),
                 set_prior("student_t(3, 0, 3)", class = "b"),
                 set_prior("student_t(3, 0, 3)", class = "sd"),
                 set_prior("lkj_corr_cholesky (2)", class = "cor")))
```
```{r, include = TRUE, eval = FALSE}
# Or download it from the GitHub page:
model_gender_vtl_f0 = bmmb::get_model ('11_model_gender_vtl_f0.RDS')
```
```{r, include = FALSE, eval = TRUE}
# saveRDS (model_gender_vtl_f0, '../models/11_model_gender_vtl_f0.RDS')
model_gender_vtl_f0 = readRDS ('../models/11_model_gender_vtl_f0.RDS')
```

We can consider the model fixed effects using `brmplot` in figure \@ref(fig:F11-10)., and beside that we make a BANOVA plot that compares the fixed effects, the finite-sample standard deviations for 'batches' our random effects parameters, and the residual error.

```{r, include = FALSE}
banova_gender_vtl_f0 = bmmb::banova (model_gender_vtl_f0)
```

```{r F11-11, fig.height = 3, fig.width = 8, fig.cap='(left) A plot showing the fixed effects estimates for `model_gender_vtl_f0`. (right) a BANOVA plot of the same model.', echo = FALSE, cache = TRUE}

################################################################################
### Figure 11-11
################################################################################

par ( mfrow = c(1,2), mar = c(5.5,3,1,1))
layout (mat= t(c(1,2)), widths = c(.4,.6))
bmmb::brmplot (brms::fixef(model_gender_vtl_f0), line = TRUE, las = 2)
bmmb::banovaplot (banova_gender_vtl_f0, line = TRUE, las = 2)
```

In the figure above we see a relatively complex model, with an important role for both f0 and VTL. We also so that unlike for our model predicting apparent height above, this model features a prominent f0 by VTL interaction (`vtl:f0`), and an interaction between this and apparent age (`vtl:f0:A1`). 

- go over results, convert predicted logits to percents
- some examples of simple effects and hypothesis function. 


### Categorization in two dimensions

To find the intersection of the surfaces defined by our models and the plane at $z=0$, we can use some basic algebra. We take the equation defining the general shape:

$$
\begin{equation}
z =  \mathrm{a} + (\mathrm{b} \times x) + (\mathrm{c} \times y) + (\mathrm{d} \times xy)
(\#eq:F11-5)
\end{equation}
$$

First, we consider the intersection of the plane at $z=0$ and a plane defined by our model. To do this we set both $z=0$ and $d=0$, and solve for $y$ as shown below. 

$$
\begin{equation}
\begin{split}
0 =  \mathrm{a} + (\mathrm{b} \times x) + (\mathrm{c} \times y) + (0 \times xy) \\
y =  -(\mathrm{b} \times x - \mathrm{a}) / \mathrm{c}
\end{split}
(\#eq:F11-5)
\end{equation}
$$

Second, we consider the intersection of the plane at $z=0$ and the saddle shape defined by our model. To do this we set only $z=0$, and solve for $y$ again as shown below. 

$$
\begin{equation}
\begin{split}
0 =  \mathrm{a} + (\mathrm{b} \times x) + (\mathrm{c} \times y) + (d \times xy) \\
y =  (-\mathrm{b} \times x - \mathrm{a}) / (d \times x + c)
\end{split}
(\#eq:F11-5)
\end{equation}
$$

Below we get the samples for our fixed effects parameters from our model and add up the appropriate parameters to calculate our $a, b, c$ and $d$ parameters for all speakers, for apparent adults, and for apparent children. In each case, we combine the necessary parameters first and then find the average across the samples of the parameter. 

```{r, collapse = TRUE}
# get fixed effect parameters
samples = brms::fixef (model_gender_vtl_f0, summary = FALSE)

# get a,b,c,d coefficients for overall surface
a_all = mean (samples[,"Intercept"])
b_all = mean (samples[,"vtl"])
c_all = mean (samples[,"f0"])
d_all = mean (samples[,"vtl:f0"])

# get a,b,c,d coefficients for adult surface
a_adult = mean (samples[,"Intercept"] + samples[,"A1"])
b_adult = mean (samples[,"vtl"] + samples[,"vtl:A1"])
c_adult = mean (samples[,"f0"] + samples[,"f0:A1"])
d_adult = mean (samples[,"vtl:f0"] + samples[,"vtl:f0:A1"])

# get a,b,c,d coefficients for child surface
a_child = mean (samples[,"Intercept"] - samples[,"A1"])
b_child = mean (samples[,"vtl"] - samples[,"vtl:A1"])
c_child = mean (samples[,"f0"] - samples[,"f0:A1"])
d_child = mean (samples[,"vtl:f0"] - samples[,"vtl:f0:A1"])
```

We can use these parameters to generate curves representing the boundaries between expected female and expected male responses. We do this for our linear (equation X) and hyperbolic (equation X) boundaries in the left and middle panels of figure below. You may notice small lines in the top left corner of the middle plot below. We can see what these are when we 'zoom out' in the right plot of the figure. As a result of these 'double' shapes we get two sections in our space associated with male speakers, one in the bottom right associated with lower frequencies, and one in the top right associated with higher frequencies. 

```{r F11-12, fig.width = 8, fig.height = 3, fig.cap = "(left) Each point represents a single speaker, labels indicate most common group classification. Curves indicate male/female boundaries for adults (green), children (orange), and overall (blue). (right) The same as the left figure but zoomed out more.", echo = FALSE, cache = FALSE}

################################################################################
### Figure 11-12
################################################################################

# y = (-b*x - a - z) / (dx+c)
# fixef(model_gender_vtl_f0)

tmp = bmmb::exp_data
tmp = tmp[tmp$R=='a',]

tmp$vtl_original = tmp$vtl
mu_vtl = mean (tmp$vtl_original)
tmp$vtl = tmp$vtl - mean (tmp$vtl)

tmp$f0_original = tmp$f0 
mu_f0 = mean (tmp$f0_original)
tmp$f0 = tmp$f0 - mean(tmp$f0)
tmp$f0 = tmp$f0 / 100

aggd = aggregate (cbind ( height, A=="a", G=="f", vtl,f0, vtl) ~ S + C_v, 
                      data = tmp, FUN = mean)
aggd$C = ""
aggd$C[aggd[,4]>= 0.5 & aggd[,5]>= 0.5] = "w"
aggd$C[aggd[,4]>= 0.5 & aggd[,5]<= 0.5] = "m"
aggd$C[aggd[,4]<= 0.5 & aggd[,5]>= 0.5] = "g"
aggd$C[aggd[,4]<= 0.5 & aggd[,5]<= 0.5] = "b"
#table(aggd$C)

tab = table (tmp$S, tmp$C)
mod_cat = apply (tab, 1,which.max)

par (mfrow = c(1,2), mar = c(4,.25,.5,.25), oma = c(0,4,0,0))

plot (aggd$vtl,aggd$f0, cex =1.2, col = bmmb::cols[c(2:5)][factor(aggd$C)], 
      pch=16,lwd=2, xlab = "",ylab="Height (inches)")
grid()
points (aggd$vtl, aggd$f0, cex =1.2, pch=16,lwd=2,
      col = bmmb::cols[c(2:5)][factor(aggd$C)])

curve ((-b_all*x - a_all) / (d_all*x+c_all), from = -6, to = -c_all/d_all, 
       add = TRUE,lwd=2,col=bmmb::cols[7])
curve ((-b_all*x - a_all) / (d_all*x+c_all), from = -c_all/d_all, 
       to = 6, add = TRUE,lwd=2,col=bmmb::cols[7])

curve ((-b_adult*x - a_adult) / (d_adult*x+c_adult), from = -6, to = -c_adult/d_adult-.05, add = TRUE,
       lwd=2, lty=2,col=bmmb::cols[10])
curve ((-b_adult*x - a_adult) / (d_adult*x+c_adult), from = -c_adult/d_adult+.05, to = 6, add = TRUE,
       lwd=2, lty=2,col=bmmb::cols[10])

curve ((-b_child*x - a_child) / (d_child*x+c_child), from = -6, to = -c_child/d_child, add = TRUE,
       lwd=2, lty=2,col=bmmb::cols[8])
curve ((-b_child*x - a_child) / (d_child*x+c_child), from = -c_child/d_child, to = 6, add = TRUE,
       lwd=2, lty=2,col=bmmb::cols[8])

plot (aggd$vtl,aggd$f0, cex =1.2, col = bmmb::cols[c(2:5)][factor(aggd$C)], 
      pch=16,lwd=2, xlab = "",ylab="Height (inches)",xlim = c(-4,4),ylim = c(-2,2),
      yaxt='n')
grid()
points (aggd$vtl, aggd$f0, cex =1.2, pch=16,lwd=2,
      col = bmmb::cols[c(2:5)][factor(aggd$C)])

curve ((-b_all*x - a_all) / (d_all*x+c_all), from = -6, to = -c_all/d_all, add = TRUE,lwd=2,col=bmmb::cols[7])
curve ((-b_all*x - a_all) / (d_all*x+c_all), from = -c_all/d_all, to = 6, add = TRUE,lwd=2,col=bmmb::cols[7])

curve ((-b_adult*x - a_adult) / (d_adult*x+c_adult), from = -6, to = -c_adult/d_adult-.05, add = TRUE,
       lwd=2, lty=2,col=bmmb::cols[10])
curve ((-b_adult*x - a_adult) / (d_adult*x+c_adult), from = -c_adult/d_adult+.05, to = 6, add = TRUE,
       lwd=2, lty=2,col=bmmb::cols[10])

curve ((-b_child*x - a_child) / (d_child*x+c_child), from = -6, to = -c_child/d_child, add = TRUE,
       lwd=2, lty=2,col=bmmb::cols[8])
curve ((-b_child*x - a_child) / (d_child*x+c_child), from = -c_child/d_child, to = 6, add = TRUE,
       lwd=2, lty=2,col=bmmb::cols[8])

```

The high-frequency region suggests that speakers with a very high f0 and a very short VTL are likely to be identified as females. Note that we don't have any speakers in this region and so we can only guess what listeners might have done. However, common sense suggests that for adult speakers at least, speakers with a very short VTL and a very high f0 are not very likely to be identified as male. Does this matter? Yes and no. Does it matter that the earth is not flat but our maps mostly act like it is? If it's *flat enough* in the area described by our map, then maybe not. So, we have to decide what we want to do with our model. If we only want to understand behavior at the boundary region where we mostly have a lot of data, then the high-frequency male region maybe doesn't matter. On the other hand, if we want to understand how listener might be using this acoustic information in general, we might be worried that our model represents listener behavior in the general case so that the behavior of the model should 'make sense' even for data we don't have. If this is the case then maybe we need to drop the cross-product from our model because it results in a model that can't possibly capture what listener are doing in general. Below we fit a reduced model without the interaction between f0 and VTL. 

```{r, eval = FALSE}
# Fit the model yourself
set.seed (1)
options (contrasts = c('contr.sum','contr.sum'))

model_gender_vtl_f0_reduced =
  brm (F ~ (vtl+f0)*A + ((vtl+f0)*A|L) + (1|S), data=exp_data, 
       chains=4, cores=4, family="bernoulli", 
       warmup=1000, iter = 5000, thin = 4,  
       prior = c(set_prior("student_t(3, 0, 3)", class = "Intercept"),
                 set_prior("student_t(3, 0, 3)", class = "b"),
                 set_prior("student_t(3, 0, 3)", class = "sd"),
                 set_prior("lkj_corr_cholesky (2)", class = "cor")))
```
```{r, include = FALSE, eval = FALSE}
# Or download it from the GitHub page:
model_gender_vtl_f0_reduced = bmmb::get_model ('11_model_gender_vtl_f0_reduced.RDS')
```
```{r, include = FALSE, eval = TRUE}
# saveRDS (model_gender_vtl_f0_reduced, '../models/11_model_gender_vtl_f0_reduced.RDS')
model_gender_vtl_f0_reduced = readRDS ('../models/11_model_gender_vtl_f0_reduced.RDS')
```

And find our $a,b,c$ and $d$ parameters for our model. There is no $d$ parameter this time since there is no cross-product term. 

```{r, collapse = TRUE}
# get fixed effect parameters
samples = brms::fixef (model_gender_vtl_f0_reduced, summary = FALSE)

# get a,b,c coefficients for overall plane
a_all_reduced = mean (samples[,"Intercept"])
b_all_reduced = mean (samples[,"vtl"])
c_all_reduced = mean (samples[,"f0"])

# get a,b,c coefficients for adult plane
a_adult_reduced = mean (samples[,"Intercept"] + samples[,"A1"])
b_adult_reduced = mean (samples[,"vtl"] + samples[,"vtl:A1"])
c_adult_reduced = mean (samples[,"f0"] + samples[,"f0:A1"])

# get a,b,c coefficients for child plane
a_child_reduced = mean (samples[,"Intercept"] - samples[,"A1"])
b_child_reduced = mean (samples[,"vtl"] - samples[,"vtl:A1"])
c_child_reduced = mean (samples[,"f0"] - samples[,"f0:A1"])
```

We use these parameters to plot the category boundaries in our stimulus space. Figure below compares the linear boundaries implied by our reduced model to those implied by our full model, ignoring the $d$ coefficients. We can see that in the absence of the cross-product, the boundaries for children and adults differ substantially in their slope. The change in slope indicates that f0 differences matter less for children than they do for adults. We can also see that the linear boundaries do not differ much in slope for our model that *does* include a cross-product. This is likely because either the cross-product, or the interaction of this with apparent age, is able to capture whatever difference our reduced model represents with these differences in slope.  

```{r F11-13, fig.width = 8, fig.height = 3, fig.cap = "(left) Each point represents a single speaker, labels indicate most common group classification. Lines indicate male/female boundaries for adults (green), children (orange), and overall (blue). (right) The same as the left figure but zoomed out more.", echo = FALSE, cache = TRUE}

################################################################################
### Figure 11-13
################################################################################


fixef_1 = brms::fixef (model_gender_vtl_f0)
fixef_2 = brms::fixef (model_gender_vtl_f0_reduced)

# y = (-b*x - a - z) / (dx+c)
# fixef(model_gender_vtl_f0)

tmp = bmmb::exp_data
tmp = tmp[tmp$R=='a',]

tmp$vtl_original = tmp$vtl
mu_vtl = mean (tmp$vtl_original)
tmp$vtl = tmp$vtl - mean (tmp$vtl)

tmp$f0_original = tmp$f0 
mu_f0 = mean (tmp$f0_original)
tmp$f0 = tmp$f0 - mean(tmp$f0)
tmp$f0 = tmp$f0 / 100

aggd = aggregate (cbind ( height, A=="a", G=="f", vtl,f0, vtl) ~ S + C_v, 
                      data = tmp, FUN = mean)
aggd$C = ""
aggd$C[aggd[,4]>= 0.5 & aggd[,5]>= 0.5] = "w"
aggd$C[aggd[,4]>= 0.5 & aggd[,5]<= 0.5] = "m"
aggd$C[aggd[,4]<= 0.5 & aggd[,5]>= 0.5] = "g"
aggd$C[aggd[,4]<= 0.5 & aggd[,5]<= 0.5] = "b"
#table(aggd$C)

tab = table (tmp$S, tmp$C)
mod_cat = apply (tab, 1,which.max)

par (mfrow = c(1,2), mar = c(4,.25,.5,.25), oma = c(0,4,0,0))

plot (aggd$vtl,aggd$f0, cex =1.2, col = bmmb::cols[c(2:5)][factor(aggd$C)], 
      xlim=c(-2.5,3),  pch=16,lwd=2, xlab = "",
      ylab="Height (inches)")
grid()
points (aggd$vtl, aggd$f0, cex =1.2, pch=16,lwd=2,
      col = bmmb::cols[c(2:5)][aggd$C])

legend (1,300, legend = c("Boys","Girls","Men","Women"),lwd=2,lty=0,
        col = bmmb::cols[2:5], bty='n',pch=16,pt.cex=1.5)

curve ((-b_all_reduced*x - a_all_reduced) / (c_all_reduced), from = -3, to = 3, add = TRUE,lwd=2,col=bmmb::cols[7])
curve ((-b_adult_reduced*x - a_adult_reduced)/ (c_adult_reduced), from = -3, to = 3, add = TRUE,lwd=2, lty=2,col=bmmb::cols[10])
curve ((-b_child_reduced*x - a_child_reduced)/ (c_child_reduced), from = -3, to = 3, add = TRUE,lwd=2, lty=2,col=bmmb::cols[8])

plot (aggd$vtl,aggd$f0, cex =1.2, col = bmmb::cols[c(2:5)][factor(aggd$C)], 
      xlim=c(-2.5,3),  pch=16,lwd=2, xlab = "",yaxt='n',
      ylab="Height (inches)")
grid()
points (aggd$vtl, aggd$f0, cex =1.2, pch=16,lwd=2,
      col = bmmb::cols[c(2:5)][aggd$C])

legend (1,300, legend = c("Boys","Girls","Men","Women"),lwd=2,lty=0,
        col = bmmb::cols[2:5], bty='n',pch=16,pt.cex=1.5)


curve ((-b_all*x - a_all) / (c_all), from = -3, to = 3, add = TRUE,lwd=2,col=bmmb::cols[7])
curve ((-b_adult*x - a_adult)/ (c_adult), from = -3, to = 3, add = TRUE,lwd=2, lty=2,col=bmmb::cols[10])
curve ((-b_child*x - a_child)/ (c_child), from = -3, to = 3, add = TRUE,lwd=2, lty=2,col=bmmb::cols[8])
```

### Model selection and misspecification

We can use cross-validation to investigate whether which of our two models is preferable.  

```{r, eval = FALSE, cache = TRUE}
model_gender_vtl_f0 = brms::add_criterion(model_gender_vtl_f0,"loo")
model_gender_vtl_f0_reduced = brms::add_criterion(model_gender_vtl_f0_reduced,"loo")
```

The comparison suggests that the model that includes the interaction does a better job of explaining our data and is also expected to better predict our-of-sample data. 

- explain loo, elpd, p_loo

```{r, eval = TRUE}
brms::loo_compare (model_gender_vtl_f0, model_gender_vtl_f0_reduced)
```

However, we got the following error message we adding the `loo` criterion to our models:

`Warning: Found 201 observations with a pareto_k > 0.7 in model 'model_gender_vtl_f0'. It is recommended to set 'moment_match = TRUE' in order to perform moment matching for problematic observations.`

When we add the `loo` criterion to our model, `brms` (and stan) don't actually fit a new model for every left our data point. Instead, as discussed in section X ([@@ SB - find this and check out what I said]), there is a way to approximate what the model would look like had we refit it without the one data point. It does this using something called **Pareto smoother importance sampling** (PSIS). The Pareto-$\hat{k}$ statistic is a diagnostic for this method that helps you check how well the assumptions underlying the leave-one-out simulation are holding up (Vehtari, Gelman and Gabry, 2017). Basically, the $\hat{k}$ statistic is a measure of how unusual a given observation is. A very unusual observation is highly influential on your parameter estimates and will have a higher value of $\hat{k}$. If an observation is too unusual, then the estimate of the elpd component for that observation may not be reliable. The general rule of thumb is that values of $\hat{k}$ that are less than 0.5 are 'good', values between 0.5 and 0.7 are 'ok' (not so great but not bad either), and values greater than 0.7 are 'bad'. In part, the reason for the vagueness in the language and boundaries between good and ok $\hat{k}$ values is that these are an *approximation*, and there are many reasons for these values to vary based on the nature of the data and the structure of the model.   
  Aki Vehtari (cite webpage) outlines three general situations where the Pareto $\hat{k}$ statistics can be large:

1) p_loo is *much smaller* than number of parameters: The model is likely to be misspecified. 

2) p_loo is *less than* the number of parameters: If the number of parameters is relatively large relative to the number of observations (e.g. p > n/5) then the model may be too flexible, or your priors may be too weak. 

3) p_loo is *greater than* the number of parameters: The model is likely to be *'badly'* misspecified. There are two situations related to this. 
  
In each case, a posterior predictive check may help understand the issues, as can inspecting the distribution of Pareto $\hat{k}$ statistics.

```{r}
# number of estimated parameters
ncol (bmmb::get_samples(model_gender_vtl_f0))

# number of observations
nrow (model_gender_vtl_f0$data)

# information related to loo creiterion
model_gender_vtl_f0$criteria$loo$estimates
```

Based on the information above, we believe that we fall into the second case. Our `p_loo` is only about 40% as large as our number of parameters. Although we do have more than 5 times as many observations (2085) as estimated parameters (306), the ratio of 6.81 is not much greater than 5. In addition, we think there is a possibility that the model is **misspecified**. We have said repeatedly that no model can really be 'proven' to be the 'rel' model, and even that it's not totally clear what it would mean for a formalism like regression to represent the 'real' process underlying our observations. Given this, it seems that every model is 'misspecified' to some extent, making the critique of one specific model model as being misspecified somewhat odd. We can say that in this context, misspecification refers to a difference between your model and reality that causes noticeable 'misbehavior' in your model. What might this misbehavior look like? We think a good example of this is in our hyperbolic category boundaries seen in figure above. We noted at the time that these boundaries defied all logic and were unlikely to represent listener behavior. In other words, the model did not correctly reflect the underlying process we are trying to understand: Listener judgments of apparent gender based on speech acoustics and apparent speaker age.

First, we get the Pareto $\hat{k}$ estimates for our initial model:

```{r, cache = TRUE}
pareto_k = model_gender_vtl_f0$criteria$loo$diagnostics$pareto_k
```

We plot these below, and compare them to the same values for our reduced model. When plotting these, we noted that there was a pattern across listeners such that $\hat{k}$ values were highest for adult male speakers.  

```{r F11-14, fig.width = 8, fig.height = 3, fig.cap = "(left) Pareto k estimates for data points in `model_gender_vtl_f0`. (right) Pareto k estimates for data points in `model_gender_vtl_f0_reduced`.", echo = FALSE, cache = TRUE}

################################################################################
### Figure 11-14
################################################################################
point_col = tapply (exp_data$C_v, exp_data$S,findmode)
point_col = as.numeric(factor(point_col))

par (mfrow = c(1,2), mar = c(1,.5,1,.5), oma = c(0,4,0,0))

plot (model_gender_vtl_f0$criteria$loo$diagnostics$pareto_k, ylab="", 
      ylim = c(0,1.5),col=bmmb::cols[1+point_col],pch=16, xaxt='n')
abline (h = c(0.5,.7,1), col = deeppurple, lwd = 2, lty=2)
plot (model_gender_vtl_f0_reduced$criteria$loo$diagnostics$pareto_k, ylab="", 
      ylim = c(0,1.5),col=bmmb::cols[1+point_col],pch=16, yaxt='n', xaxt='n')
abline (h = c(0.5,.7,1), col = deeppurple, lwd = 2, lty=2)
mtext (side = 2, "Pareto k", outer = TRUE, line= 2.5, cex = 1.3)
```

We made posterior predictions for each model, taking the average across all posterior samples: 

```{r, cache = TRUE}
p_preds = predict (model_gender_vtl_f0)
```

And plot these in the left plot of figure below. It's clear that the main issue seems to be for males who are predicted to be female 0%, or nearly 0% of the time. In fact, several men *were* identified as women 0% of the time. Since a probability of 0 implies, in the limit, a logit of negative infinity, the model appears to have a hard time finding reasonable values for some parameters. We considered a  boxplot of Pareto k values by speaker (not presented here) which showed that a small number of individual men were responsible for most high k values. We found that several of these men had the lowest f0 values from among our speakers. In the middle plot we present each speaker plotted according to their f0 and VTL, where point size reflects the average Pareto $\hat{k}$ value for each speaker.

```{r F11-15, fig.width = 8, fig.height = 3, fig.cap = "(left) Pareto k estimates for data points in `model_gender_vtl_f0` plotted against the predicted probability of a female response for each data point. (middle) Adult male and female speakers plotted according to voice characteristics. Point size reflects Pareto k values. (right) A 'topographic map' of our predicted surface for adult speakers. The same points as in the middle figure. Black lines indicate female/male category boundaries (i.e. logit = 0). Red lines indicate 2-logit decreases in expected values, green lines indicate 2-logit increases in expected values.", echo = FALSE, cache = TRUE}

################################################################################
### Figure 11-15
################################################################################

tmp = bmmb::exp_data
tmp = tmp[tmp$R=='a',]

tmp$vtl_original = tmp$vtl
mu_vtl = mean (tmp$vtl_original)
tmp$vtl = tmp$vtl - mean (tmp$vtl)

tmp$f0_original = tmp$f0 
mu_f0 = mean (tmp$f0_original)
tmp$f0 = tmp$f0 - mean(tmp$f0)
tmp$f0 = tmp$f0 / 100

point_col = tapply (tmp$C_v, tmp$S,findmode)
point_col = as.numeric(factor(point_col))

par (mfrow = c(1,3), mar = c(4,4,1,1))

plot (p_preds[,1], model_gender_vtl_f0$criteria$loo$diagnostics$pareto_k,
      col=bmmb::cols[1+point_col],pch=16, ylim = c(0,1.5),
      xlab="Expected Probbility of a Female Response",ylab="Pareto k")

aggd = aggregate (pareto_k ~ f0 + vtl + S + A_v, data = tmp, FUN = mean)
aggd = aggd[aggd$A_v=="a",]

tmp = tmp[tmp$A_v=="a",]
point_col = tapply (tmp$C_v, tmp$S,findmode)
point_col = as.numeric(factor(point_col))+2

plot(aggd[,2:1], cex = aggd$pareto_k*4, col = cols[1+point_col], pch=16,lwd=2,
     xlab = "Vocal-tract length (cm)", xlim = c(-2.2,3), 
     ylim = c(-1.2,1.1), ylab = "f0 (Hz)")

curve ((-b_adult*x - a_adult) / (d_adult*x+c_adult), from = -6, 
       to = -c_adult/d_adult-.01, add = FALSE, lwd=2, lty=1,col=1, xlim = c(-2.2,3), ylim = c(-1.2,1.1))
curve ((-b_adult*x - a_adult) / (d_adult*x+c_adult), from = -c_adult/d_adult+0.01, 
     to = 6, add = TRUE, lwd=2, lty=1,col=1)

colors = colorRampPalette(c("blue",bmmb::cols[4],bmmb::darkorange))(13)
for (i in seq(-62,-2,2)){
  curve ((-b_adult*x - a_adult - i) / (d_adult*x+c_adult), from = -6, 
         to = -c_adult/d_adult-0.01, add = TRUE, lwd=1, lty=1,col=bmmb::cols[5])
  curve ((-b_adult*x - a_adult - i) / (d_adult*x+c_adult), from = -c_adult/d_adult+0.01, 
       to = 6, add = TRUE, lwd=1, lty=1,col=bmmb::cols[5])
}

for (i in seq(2,62,2)){
  curve ((-b_adult*x - a_adult - i) / (d_adult*x+c_adult), from = -6, 
         to = -c_adult/d_adult-0.01, add = TRUE, lwd=1, lty=1,col=bmmb::cols[4])
  curve ((-b_adult*x - a_adult - i) / (d_adult*x+c_adult), from = -c_adult/d_adult+0.01, 
       to = 6, add = TRUE, lwd=1, lty=1,col=bmmb::cols[4])
  
}
points(aggd[,2:1], cex = 1, col = "grey40", pch=16,lwd=2)
```

Based on figure above, we can see that the problematic male voices are those with extreme values of VTL and, in particular f0. If we think of our saddle shapes (see figure X), they can have areas where $z$ values (i.e., the dependent variable) can rise or fall extremely rapidly. For example, we can see in the right plot of figure above that the most problematic male voices were in a region that includes very high values that rise rapidly based on small differences in f0 and VTL. So, it appears that in this case we have some male speakers whose probability of being identified as female is very low, implying very negative logit values, in a region of our surface that is curved such that extremely negative predicted values are possible. Combining this with or relatively small number of observations (given the complexity/flexibility of our model) results in the situation we see above. 
  To resolve this situation we could fit a model with tighter priors, which may have the result of providing more constrained parameter estimates. However, it may be the case that our model is simply too flexible given the amount of data we have. Independently of all of this, we are still concerned with the very basic problem that the high-frequency region associated with male responses (presented in figure X) defies common sense and is probably wrong. As a result of this, we're not going to try to 'fix' the more complicated model but simply abandon it, relying instead on the reduced model that does not include the VTL by f0 interaction. 
  
### Answering our research questions

As a reminder, the questions we posed above in section X are: 

Q1) Do listeners use VTL, f0, and the interaction between them to determine speaker gender?

Q2) Does apparent speaker age influence the use of the above mentioned acoustic cues?

Q3) Is there a lot of between-speaker variation in perceptual behavior?

Based on our discussion above, we conclude that listeners use f0 and VTL, but the jury is still out on the interaction of the two. It seems that to really get a handle on this issue we need to run an experiment with more voices in the lower left and upper right corners, to see how the surface behaves in that area of the stimulus space. Below we print a table of the fixed effects for our reduced model:

```{r T11-1}
knitr::kable(fixef(model_gender_vtl_f0_reduced), caption = "Fixed effect posterior means, error, and credible intervals for our reduced model.")
```

Based on \@ref(tab:T11-1) it seems that f0 and VTL had about the same effect on the perception of femaleness. Of course, comparison is based on the scaling we carried out on each dependent variable. However, since each variable was scaled so that a unit of 1 equaled about half the difference between adult males and females, the direct comparison of the magnitude of their associated parameters seems fair. Apparent speaker age appears to affect the use of both acoustic cues. In both cases, the effects of f0 and VTL changes are stronger for children compared to adults. In fact, the interaction between f0 and apparent age (`f0:A1`) has the effect of reducing the effect of f0 to nearly zero (i.e. $f0 + (-A1) = 2.2 - 1.6 = 0.6$). We noted in chapter 10 that slopes of larger magnitudes generally indicate steeper category boundaries and less uncertainty between categories along that dimension. In this case, the larger magnitudes of the slopes for apparent adults for f0 and VTL reflect the fact that men and women were more discriminable along those dimensions than boys and girls.   We can think about between-listener variation in the use of acoustics in two ways. The first involves the inspection of the superpopulation standard deviation estimates for our listener-dependent effects, presented in table \@ref(tab:T11-2). Rather than only focusing on the estimates, we can also think about whether effects have 2.5% credible intervals (relatively) far from zero, meaning they are unlikely to be very small. Only three of the effects really meet that threshold: Listener-dependent variation in the use of VTL and the effect of apparent age, and speaker-dependent variation in intercepts. 

```{r T11-2}
knitr::kable(bmmb::getsds (model_gender_vtl_f0_reduced), caption = "Superpopulation standard deviation estimates for our 'random' effects.")
```

We can also think about the result of this variation in terms of how this might actually affect gender classification from speech. To do this, we get listener-specific intercepts, f0 slopes, and VTL slopes. We do this separately for apparent children and apparent adults using the code below (explained in detail in section X). 

```{r}
listener_coefficients_adult = 
  bmmb::short_hypothesis (model_gender_vtl_f0_reduced, scope="coef",group="L",
                          c("Intercept+A1=0","vtl+vtl:A1=0","f0+f0:A1=0"))
listener_coefficients_child = 
  bmmb::short_hypothesis (model_gender_vtl_f0_reduced, scope="coef",group="L",
                          c("Intercept-A1=0","vtl-vtl:A1=0","f0-f0:A1=0"))
```

Using these parameters, we can find boundaries for each listener using equation above. We plot these in figure \@ref(fig:F11-16). We see that there is a general consensus between listeners in terms of where an approximate acoustic boundary is between adult males and adult females. However, there is much more variation in the boundary between boys and girls. This reflects the fact that the acoustic characteristics of adult men and women are generally more predictable and stable relative to children 10-12 years old. In addition, the listeners in our experiment (undergraduate University students) likely have substantially more recent experience interacting with adults than with children in that age group.   
  
```{r F11-16, fig.width = 8, fig.height = 5, fig.cap = "The first plot compares all category boundaries between men/women (orange) and boys/girls (blue). Subsequent plots present each listener's individual boundaries, and point colors indicate the listener's individual speaker classifications.", echo = FALSE, cache = FALSE}

################################################################################
### Figure 11-16
################################################################################

# y = (-b*x - a - z) / (dx+c)
# fixef(model_gender_vtl_f0)

tmp = bmmb::exp_data
tmp = tmp[tmp$R=='a',]

tmp$vtl_original = tmp$vtl
tmp$vtl = tmp$vtl - mean (tmp$vtl)

tmp$f0_original = tmp$f0 
tmp$f0 = tmp$f0 - mean(tmp$f0)
tmp$f0 = tmp$f0 / 100

aggd = aggregate (cbind ( height, A=="a", G=="f", vtl,f0, vtl) ~ S + A_v + G_v + C_v, 
                      data = tmp, FUN = mean)
#aggd = aggd[aggd$A_v=='a',]

a = listener_coefficients_adult[1:15,1]
b = listener_coefficients_adult[16:30,1]
c = listener_coefficients_adult[31:45,1]

ac = listener_coefficients_child[1:15,1]
bc = listener_coefficients_child[16:30,1]
cc = listener_coefficients_child[31:45,1]

par (mar = c(.2,.2,.2,.2), oma = c(3,3,.5,.5), mfrow = c(4,4))

plot (aggd$vtl,aggd$f0, cex =1.2, col = bmmb::cols[c(2:5)][factor(aggd$C_v)], 
      pch=16,lwd=2, xlab = "",ylab="f0 (cm)",xaxt = 'n',
        xlim=c(-2.5,2.7),ylim=c(-1.2,1.2))
grid()

for (i in 1:15)
  curve ((-b[i]*x - a[i]) / (c[i]), from = -3, to = 3, 
         add = TRUE,lwd=2,col=bmmb::cols[8],xaxt='n')

for (i in 1:15)
  curve ((-bc[i]*x - ac[i]) / (cc[i]), from = -3, to = 3, 
         add = TRUE,lwd=2,col=bmmb::cols[7],xaxt='n')

for (i in 1:15){
  xaxt = "n"
  yaxt = "n"
  if (i %in% 12:15) xaxt = "s"
  if (i %in% c(4,8,12)) yaxt = "s"
  tmpp = tmp[tmp$L==i,]
  plot (tmpp$vtl,tmpp$f0, cex =1.2, col = bmmb::cols[2:5][factor(tmpp$C)],
        pch=16,lwd=2, xlab = "",ylab="f0 (cm)",xaxt=xaxt,yaxt=yaxt,
        xlim=c(-2.5,2.7),ylim=c(-1.2,1.2))
  grid()
  curve ((-b[i]*x - a[i]) / (c[i]), from = -5, to = 3, add = TRUE,
         lwd=2,col=bmmb::cols[8])
  curve ((-bc[i]*x - ac[i]) / (cc[i]), from = -5, to = 3, add = TRUE,
         lwd=2,col=bmmb::cols[7])
  text (-1.5,-.75,i,cex=1.5)
}
```












