\newpage
```{r, include = FALSE}
knitr::opts_chunk$set(
  dpi = 300, dev = "jpeg", collapse=TRUE
)
```

# Multinomial and Ordinal regression

In chapter 10 we introduced models that can predict dichotomous categorical variables using logistic regression. Here, we extend many of the concepts introduced in that chapter to the modelling of dependent variables with any number of categories. First, we discuss multinomial regression models that can be used for categorical variables without an inherent ordering. For example, we could use a model like this to predict the perception of vowel sounds from speech acoustics, to predict the lexical category of a word (verb, noun, adjective, ...), or to predict a speaker's native language. Actually, these models can *also* be used for ordered data, they just do not inherently represent the ordering in the model. After this, we introduce ordinal models appropriate for the prediction of categorical variables with some inherent ordering (e.g., first, second and third).  

## Chapter pre-cap

--

### Bold words

Throughout each chapter you will see words in bold. These are important concepts that appear in bold where they are introduced and described in the text. The bold words in this chapter, in alphabetical order, are: 

--

## Multinomial logistic regression

**Multinomial logistic regression** allows you to model data generated by a **multinomial distribution** with some unknown parameters. The multinomial distribution is the generalization of the binomial distribution (see section X) to any number of positive integer outcome categories. For example, the multinomial distribution will allow use to model the categorization of speakers into boys, girls, men, and women simultaneously rather than modeling this as two binary categorizations (male vs. female and adult vs. child). The multinomial distribution has three parameters:
  
  1) $n$: The number of trials, a positive integer.
  2) $J$: The number of possible outcomes, a positive integer.
  3) $p_1, \dots, p_J$: A vector of probabilities of observing each of the $j$ outcomes where $\sum p_j = 1$.
  
Multinomial data arises in situations such as the following. You have a variable that can take on some number of possible values. For example, you ask people to tell you if the speaker seems to be a boy, a girl, a man, or a woman. This results in a variable, apparent speaker category, that can take on one of four discrete values. You observe a certain number of trials ($n$) under some set of conditions. You then count how many times listeners identified the speaker as belonging to one of the four categories. If you divide these counts by the total number of trials ($n$) you will get the probability of observing each outcome ($p_J$). We can think of our data as being generated by a multinomial distribution with some specific parameters as seen below. Our data is a vector of counts, $y_1, \dots, y_J$, representing the expected number of observations of each category for $n$ total outcomes. 


$$
\begin{equation}
y_1, \dots, y_J \sim \mathrm{multinomial}(p_1, \dots, p_J, n)
(\#eq:12-1)
\end{equation}
$$


Below we draw 10 instances of a four-category multinomial variable with probabilities of 0.4, 0.1, 0.2, and 0.3 for the first, second, third and fourth categories respectively. Each of the variables below has $n=1$ so a single category is equal to 1 and the others must all be zero. 
  
```{r}
rmultinom (10, 1, c(.4,.1,.2,.3))
```

We sample ten more multinomial variables, this time each with $n=100$. We can see that we get a distribution of values across the four outcomes for each variable that resembles the values of $p$ we defined for each outcome. Note that the categories are numbered and could represent anything. This sort of variable only represents the relative frequency of outcomes with respect to each other and does not specify relationships between outcomes.

```{r}
set.seed (1)
multinomial_variable = rmultinom (10, 100, c(.4,.1,.2,.3))
multinomial_variable

rowMeans(multinomial_variable)/100
```

There are many ways to think about multinomial logistic regression. We're going to present one that is consistent with the way we presented logistic regression in chapter 10 and the way we have been presenting regression models in general in this book. For a more complete treatment of the topic please see cite. Before beginning the explanation we can 'spoil' the conclusion:  The number of trials ($n$) and the number of possible outcomes ($J$) are aspects of your data and experimental design, and are known to you before you fit any model. Thus, multinomial logistic regression effectively consists of estimating $p_j$, or values analogous to it, for each category as a function of your dependent variables. 

Multinomial regression is a surprisingly 'simple' extension of the concepts underlying logistic regression (presented in chapter 10). When we discussed logistic regression in chapter 10, we introduced the antilogit function (also known as the *logistic* link function). In section X, we discussed the fact that this function converts log odds to probabilities by arbitrarily setting the 'number' of failures to 1 and modeling the number of outcomes (i.e. $e^z$). So, we see in equation below that the probability that $y=1$ (i.e. a 'success') is equal to the ratio of the 'number' of successes over the sum of the total number of outcomes.  

$$
\begin{equation}
\begin{split}
P(Y=1) = \frac{\mathrm{success}}{\mathrm{failure}+\mathrm{success}} = \frac{e^{z}}{1+e^{z}}
\end{split}
(\#eq:12-2)
\end{equation}
$$

The equation above works for when we have exactly two categories. However, it can be modified so that it can be applied to multiple categories. First, we assume that rather than exactly two possible outcomes, there are $J$, some integer larger than one. If we stick to our interpretation of the value of $e^{z}$ as an expected count for that category, then $e^{z_j}$ is the expected count for category $j$. To find the probability of observing category $j$ we find the ratio of the 'count' of $j$ over the sum of all possible outcomes (i.e., the sum of counts for all categories).

$$
\begin{equation}
\begin{split}
P(Y=j) = \frac{e^{z_j}}{\sum_{j=1}^{J} e^{z_j}}
\end{split}
(\#eq:12-3)
\end{equation}
$$

The function above is called the **softmax** function, and it is basically a generalization of the antilogit (logistic) function to more than two categories. When we did dichotomous logistic regression, we modeled only the 'count' of one variable, the one set to 'success'. The 'counts' for the category set to 'failure' was not modeled and was set to 1 (by setting $z=0$) for all cases. When we model multinomial data we have to follow the same convention and set one category as the 'reference'. This means the the equation above can be modified to pull one category out of the summation and set its count to 1 for all situations, as in the equation below. Notice that the count on the summation in the denominator of the fraction now begins at two.

$$
\begin{equation}
\begin{split}
P(Y=j) = \frac{e^{z_j}}{1 + \sum_{j=2}^{J} e^{z_j}}
\end{split}
(\#eq:12-4)
\end{equation}
$$

The equation above results in a set of probabilities which can serve as the multinomial parameters, $p_1, \dots , p_j$, for categories $1, \dots, J$. These probabilities are modeled by estimating $z_j$ as resulting from the linear combination of our predictor variables based on some unknown parameters ($\beta_j$). Each outcome has a different prediction equation for $z_j$ so that a multinomial regression has $J$ prediction equations, one for each outcome. Importantly, each prediction equation combines the same $x_k$ predictors, albeit in a category-specific way (based on the $\beta_j$ parameters for that category).  

$$
\begin{equation}
z_j = \beta_j + \beta_{j1} \times x_1 + \beta_{j2} \times x_2 + \dots + \beta_{kj} \times x_k
(\#eq:12-5)
\end{equation}
$$

The prediction equation for the 'reference' category (`brm` uses the first category) is fixed to have a value of 0. One way to accomplish this is to fix all coefficients for this outcome to equal 0 as in equation below. 

$$
\begin{equation}
\begin{split}
z_1 = 0 \\
0 = \alpha_j + \beta_{j1} \times x_1 + \beta_{j2} \times x_2 + \dots + \beta_{kj} \times x_k \\
z_1 = 0 + 0 \times x_1 + 0 \times x_2 + \dots + 0 \times x_k \\
\end{split}
(\#eq:12-6)
\end{equation}
$$

When we carried out logistic regression, the variable $z$ was refereed to as a logit. Sometimes the $z_j$ values involved in multinomial regression are called **multinomial logits** to highlight their similarity to the dichotomous logit. Sometimes these values are referred to as the **score** for each category. The score is somewhat vaguely defined, in part because there are many ways to think about what the score is and means. One way to think of the score is that it is a *latent variable* associated with each category, that relates to the probability of observing that category given the values of the dependent variables.

**Latent variables** are variables that are inferred mathematically using some statistical model, but are not measured directly. For example, in our logistic regression model in chapter 10 we predicted the perception of femaleness. We did this by predicting variation in the logit of the probability of observing a female response as a function of speaker vocal-tract length. The logit of this probability can be thought of as a latent variable representing something like 'femininity' in the mind of the listener. Based on the 'feeling' of voice femininity that the listener has they produce the surface variable that we do measure: The classification of a speaker as female/male. In this view the realization of the response variable (a female classification) is the result of a secret, *latent* variable that is not directly observed by us, but which we assume underlies the process. 

We have four latent variables in our multinomial model predicting apparent category: The score for each category. We can think of these as the 'feeling' the listener has regarding the 'boyness', 'girlness', 'manness', and 'womanness' of the voice. What is the 'boyness' of a voice? The unquantifiable internal knowledge you have that a voice is that of a boy, as opposed to some other sort of speaker. These latent variables are not directly measured in our experiment but we think they underlie the categorization of speakers into categories. When a listener hears a voice and their 'boyness' score is greater than the other scores, the listener is most likely to indicate that the voice is a boy. When the score between one category and the others is very unequal, this decision is easy and classification into one category will dominate. When the scores for two or more categories are about equal, i.e. the 'boyness' and 'womanness' of a voice are similar, the listener will feel ambiguous about the decision and classification into either category may be equally likely.

At this point we've laid out the basics of multinomial regression and can present a summary of the information we just presented. In multinomial logistic regression we model the probability of observing each of the $J$ categorical outcomes. We fix the value of the score (or multinomial logit) of the reference category to 1, and estimate the scores of the other categories using a prediction equation specific for the category. The logit predicted for each category in a specific situation can then be converted to a probability using the softmax function presented in equation above. 

### Data and research questions

We load our packages and data below. We also add a new variable, $y$, representing our multinomial outcome. This variable represents observations of a vector of length four whose first, second, third, and fourth elements represent observed outcomes of 'boy', 'girl', 'man', and 'woman', respectively. After this we add a variable called `size` that always equals 1 because each row in our data frame represents observation of a single outcome. Finally, we process our quantitative predictors in the same way as in the previous chapters.

```{r, warning=FALSE, message=FALSE}
library (brms)
library (bmmb)
data (exp_data)

# new dependent variable
exp_data$y = cbind(b = as.numeric(exp_data$C=='b'),
                   g = as.numeric(exp_data$C=='g'),
                   m = as.numeric(exp_data$C=='m'),
                   w = as.numeric(exp_data$C=='w'))

# variable representing the size (n) of each observation. They are all 1.
exp_data$size = 1

# preparation of quantitative predictors as in previous chapters
exp_data$vtl_original = exp_data$vtl
exp_data$vtl = exp_data$vtl - mean (exp_data$vtl)

exp_data$f0_original = exp_data$f0 
exp_data$f0 = exp_data$f0 - mean(exp_data$f0)
exp_data$f0 = exp_data$f0 / 100
```

Below, we print out the first six instances of our dependent variable and compare this to the first six values of the `C` (apparent category) variable in our data frame. We can see that the dependent variable indicates which category was selected for a given trial using a 1 in the appropriate column and a 0 in the others. 

```{r}
# first 6 elements of dependent variable
head (exp_data$y)

# first six elements of apparent speaker category factor
head (exp_data$C)
```

We will try to use our data to answer the following research question: 

Q1) Can we use speaker f0 and VTL to predict their apparent speaker category?

Keep in mind we're trying to predict *apparent* and not *veridical* speaker category. Our consideration of the accuracy or utility of this model will depend on how well it represents listener classifications of speakers, now matter how wrong or right these may be. Thus, a model with perfect classification of speakers into veridical categories is not the goal: If listeners make predictable mistakes we want to model to make the same 'mistakes'.

### Description of our model

Our model formula is largely similar to those we have seen before, with one minor change. Beside your dependent variable, you need to include a variable that indicates the integer number of trials for each set of observations. For us this will always be 1, but in many situations this can be a wider range of values. We want to predict our counts of categorizations with respect to value of speaker VTL and f0, and so the model formula we are going to use is seen below. 

`y|trials(size) ~ vtl+f0 + (vtl+f0|S) + (1|L)`

Since we're predicting category membership with two quantitative predictors, we know that the surfaces our model defines are planes. In the models with fit to this point, we had a single dependent variable and a single plane for a single condition. So, our model formulas previously were something like:

`y ~ vtl+f0 + (vtl+f0|S) + (1|L)`

However, in a multinomial regression we have one plane for each response category, so our formula above could really be thought of as:

`y_1 ~ vtl+f0 + (vtl+f0|S) + (1|L)`
`y_2 ~ vtl+f0 + (vtl+f0|S) + (1|L)`
`y_3 ~ vtl+f0 + (vtl+f0|S) + (1|L)`
`y_4 ~ vtl+f0 + (vtl+f0|S) + (1|L)`

This means that our multinomial model will involve four times as many coefficients as an equivalent Gaussian model, and $J$ times as many for $J$ outcome categories. Of course, we noted above that the coefficients of the reference category are set to zero and not estimated. This means that the formula above results in the estimation of three planes, resulting in three sets of analogous parameters. Our full model specification is given below:

$$
\begin{equation}
\begin{split}
y_{1[i]},y_{2[i]},y_{3[i]},y_{4[i]} \sim \mathrm{multinomial}(p_{1[i]},p_{2[i]},p_{3[i]},p_{4[i]}, n_{[i]}) \\ \\
\mathrm{for} \; j = 1, \dots, 4\\ \\ 
p_{j[i]} = \frac{e^{z_j}}{\sum_{j=1}^{J} e^{z_j}} \\ 
\\
z_{j[i]} = \mathrm{a}_j + b_{j[i]} \times \mathrm{vtl}_{[i]} + c_{j[i]} \times \mathrm{f0}_{[i]}  \\ 
a_{j[i]} = \mathrm{Intercept}_j + L_{j[L_{[i]}]} + S_{j[S_{[i]}]} \\ 
b_{j[i]} =  VTL_j + VTL_j \colon L_{j[L_{[i]}]} \\
c_{j[i]} =  f0_j + f0_j \colon L_{j[L_{[i]}]} \\ 
\\
\mathrm{for} \; j = 2, \dots, 4\\ \\ 

\textrm{Priors:} \\
S_{j[\bullet]} \sim \mathrm{Normal}(0,\sigma_{S_j}) 
\\ 
\begin{bmatrix} L_{j[\bullet]} \\ VTL_j \colon L_{j[\bullet]} \\ f0_j \colon L_{j[\bullet]} \end{bmatrix}	
\sim \mathrm{MVNormal} \left(\, \begin{bmatrix} 0\\ 0 \\ 0 \\ \end{bmatrix}, \Sigma_j \right) \\ \\
Intercept_j \sim t(3, 0, 3) \\
VTL_j, f0_j \sim t(3, 0, 3) \\
\sigma_{L_j}, \sigma_{VTL_j \colon L_j}, \sigma_{f0_j \colon L_j} \sim t(3, 0, 3) \\ R_j \sim \mathrm{LKJCorr} (2)

\end{split}
(\#eq:12-7)
\end{equation}
$$

We're going to take some time to unpack this definition, top to bottom, because it is at the same time very familiar and very different. First, note that our data-generating distribution is assumed to be the multinomial distribution. This function has a $p_j$ parameter indicating the probability of observing each of the $J$ categories, and an $n$ parameter specifying the total number of trials for that observation. The next line indicates that the next few lines applies individually for all four categories. For each category, the probability of observing that outcome ($p_j$) is found by combining the score for each category ($z_j$) using the softmax link function. For each category, the score is equal to a trial-dependent combination of an intercept, an effect fot VTL, and an effect for f0. The intercept varies according to an overall model intercept and speaker and listener-dependent variations from this. The VTL and f0 effect vary according to listener-dependent effects. 

After that we move on to the model priors. Unlike for the above lines, we do not specify priors for any parameters related to the reference category. This is because all of these parameters are set to 0 for this category so that the score for this category is always 0 and the 'expected count' (as discussed above) is always equal to 1. Again we may note that the specification of priors is very similar to the models we have discussed to this point, save for the proliferation of $j$ subscripts. 

### Fitting and interpreting our models

There is one major difference in how we need to specify priors for multinomial models: We need to specify priors individually for each response category with modeled parameters. This is done by passing the name of the categorical variable to the `dpar` parameter. Above, we named our response variables according to the letters we have been using throughout this text. We can see this below.

```{r}
colnames (exp_data$y)
```

The name passed to `dpar` will be `muCategory` where `Category` corresponds to the category name. This means we need to specify priors for `mug`, `mum`, and `muw`, but not `mub`. We specify our priors below:

```{r}
multinomial_prior = 
  c(brms::set_prior("student_t(3, 0, 3)", class = "Intercept",dpar="mug"),
    brms::set_prior("student_t(3, 0, 3)", class = "b",dpar="mug"),
    brms::set_prior("student_t(3, 0, 3)", class = "sd",dpar="mug"),
    brms::set_prior("student_t(3, 0, 3)", class = "Intercept",dpar="mum"),
    brms::set_prior("student_t(3, 0, 3)", class = "b",dpar="mum"),
    brms::set_prior("student_t(3, 0, 3)", class = "sd",dpar="mum"),
    brms::set_prior("student_t(3, 0, 3)", class = "Intercept",dpar="muw"),
    brms::set_prior("student_t(3, 0, 3)", class = "b",dpar="muw"),
    brms::set_prior("student_t(3, 0, 3)", class = "sd",dpar="muw"),
    brms::set_prior("lkj_corr_cholesky (2)", class = "cor"))
```

And here is the code to fit our model, using the `multinomial` family for the first time: 

```{r, eval = FALSE}
model_multinomial = 
  brms::brm (y|trials(size) ~ vtl+f0 + (vtl+f0|L) + (1|S), data=exp_data, 
             family="multinomial", chains=4, cores=4, warmup=1000, iter = 5000, 
             thin = 4, prior = multinomial_prior)
```
```{r, eval = FALSE}
model_multinomial = bmmb::get_model ("12_model_multinomial.RDS")
```
```{r, include = FALSE}
#  saveRDS (model_multinomial, "../../models/12_model_multinomial.RDS")
load("../models/12_multinomial_predictions.Rda")
model_multinomial = readRDS ("../models/12_model_multinomial.RDS")
```

Below we see the model fixed effects, the intercept, VTL slope, and the f0 slope for each category with estimated parameters. Each group of parameters defines a plane whose value along the $z$ dimension can be predicted based on the values of f0 and VTL. We have four planes an four values of $z_j$ for any given location in the two dimensional space defined by f0 and VTL. For each point, we can select as the most probable category the one whose value of $z_j$ is highest at the point in the space. Another way to look at this is that we select the highest plane at any given location in the space. 

```{r}
fixef (model_multinomial)
```

Since the dependent variable is the score for each category, the parameters above are difficult to interpret in isolation. Also, keep in mind that scores need to be interpreted relative to the baseline category value of 0 (for boys), or two each other, rather than absolutely. For example, the negative coefficient for VTL for 'girl' (`mug_vtl`) indicates the a longer VTL made a girl response less likely. We can also see that increasing f0 made a 'woman' response less likely, and a 'male' response more likely.

We might wonder how well our model can predict listener judgements. We can do this by first predicting our data using our model:

```{r, eval = FALSE}
multi_pred_re = predict (model_multinomial)
```

The result of this is a three dimensional matrix. The first two dimensions represent the by now familiar summary matrices generated by `brms`. The first column is the posterior probability of category membership for each observation, the second is the standard error for each prediction, and the third and fourth represent the 2.5% and 97.5% credible intervals.

```{r}
head(multi_pred_re[,,1])
```

The third dimension indexes the response category. Above we saw the predictions for the first category (boy) and below we see them for the second category (girl):

```{r}
head(multi_pred_re[,,2])
```

We can also just select the second dimension from each matrix, resulting in a two-dimensional matrix. This matrix contains the posterior probability of being classified into each category across columns, for each observation across rows. 

```{r}
head(multi_pred_re[,1,])
```

Since these are probabilities, the sum of each row equals one, because only these four outcomes exist. For example, the first row above tells us that, according to our model, the first observation has a 0.29 probability of being identified as a boy, 0.64 probability of being identified as a boy, 0.001 probability of being identified as a man, and a 0.07 probability of being identified as a woman. 

```{r}
head(rowSums (multi_pred_re[,1,]))
```

We can use the code below to find the 'winning' category for each observation, that is, the category with the highest posterior probability in each row. We use the resulting column numbers to get category labels. 

```{r}
# find highest posterior prbability from each category
predicted = apply (multi_pred_re[,1,],1,which.max)
head (predicted)

# use modal category to get a category label
predicted_category = c("b","g","m","w")[predicted]
head (predicted_category)

```

Below, we cross-tabulate predicted and observed classifications. Each row shows speaker classifications into different categories, and model predictions vary across columns. This is a *confusion matrix*, introduced in chapter 5. Correct classifications fall on the main diagonal and all other values indicate mistakes. For example, we see that there were 258 correct classifications of boys as boys, and 88 incorrect classifications of boys as girls. A majority of observations fall along the main diagonal indicating that the model was relatively good at predicting listener behavior.

```{r}
xtabs (~ exp_data$C + predicted_category)
```

Below we find the probability of observing a correct classification overall, and individually for each category. We see that the model we able to predict listener judgments with a high degree of accuracy overall, but that some categories (man) were much easier to predict than others (boy).

```{r}
# overall correct
mean (predicted_category == exp_data$C)

# correct predictions by category
tab = xtabs (~ exp_data$C + predicted_category)
diag(tab) / rowSums(tab)
```

### Multinomial models and territorial maps

We discussed territorial maps for two categories along two dimensions in chapter 11 where we predicted the perception of femaleness based on speaker f0 and VTL. As we discussed then, when categories are defined by planes, the boundary between categories on the space is defined by the line representing the intersection of these planes. When we did (dichotomous) logistic regression in chapter 11, we found the intersection of one plane with a horizontal plane at $z=0$. In this chapter we still have a plane such that $z=0$ for all x and y (the reference category plane), but we also have three other planes with possible non-zero slopes. The boundary between each pair of categories forms a boundary made by a line. Since we have 6 unique pairings of our four response categories, we will have six boundary lines. 

We know that the boundary between two categories is where their respective planes intersect, i.e., the place where these planes have the same $z$ axis value. To find this, first we define the values of two planes, $z_1$ and $z_2$ based on their respective coefficients as in \@ref(eq:12-8).

$$
\begin{equation}
\begin{split}
z_1 = \mathrm{a} + \mathrm{b} \times x +  \mathrm{c} \times y \\
z_2 = \mathrm{d} + \mathrm{e} \times x +  \mathrm{f} \times y
\end{split}
(\#eq:12-8)
\end{equation}
$$

We set $z_1$ equal to $z_2$, which is equivalent to setting to right hand side of each equation to equal as in \@ref(eq:12-9).

$$
\begin{equation}
\begin{split}
z_1 = z_2 \\ 
\mathrm{a} + \mathrm{b} \times x +  \mathrm{c} \times y = \mathrm{d} + \mathrm{e} \times x +  \mathrm{f} \times y
\end{split}
(\#eq:12-9)
\end{equation}
$$

In order to get all these terms into the format for the equation of a line ($y = a + b \times x$), we need to isolate y on the left hand side as seen in \@ref(eq:12-10). 

$$
\begin{equation}
y = \frac {-\mathrm{a} + \mathrm{d}}{\mathrm{c} - \mathrm{f}} + \frac{-\mathrm{b} + \mathrm{e}}{\mathrm{c} - \mathrm{f}} \times x
(\#eq:12-10)
\end{equation}
$$

As mentioned above, we get 6 such line equations, one for the boundary between each of the four planes. Figure \@ref(fig:F12-2) presents each of these six boundaries compared to the modal classification for each speaker. 

```{r F12-2, fig.height = 4, fig.width=8, fig.cap = "boys (b), girls (g), men (m), and women (w).", echo = FALSE}

################################################################################
### Figure 12.2
###############################################################################

params = fixef (model_multinomial)
params = fixef (model_multinomial, summary = FALSE)
params = cbind (colMeans (params[,1:3]), 
                colMeans (params[,c(4,6,8)]),
                colMeans (params[,c(5,7,9)]))

params = rbind (c(0,0,0), params[1:3,])

tab = table (exp_data$S, exp_data$C)
mod_cat = apply (tab, 1,which.max)

par (mfrow = c(2,3), mar = c(0.2,0.2,0.2,0.2), oma = c(4.5,4.5,0.5,0.5))

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2,
     xaxt='n')
abline (find_intersection (params[1,], params[2,]),lwd=2, col = bmmb::cols[7]) # b vs g

text (1.5,1, "boy-girl", cex=1.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2,
     yaxt='n',xaxt='n')
abline (find_intersection (params[1,], params[3,]),lwd=2, col = bmmb::cols[8]) # b vs m

text (1.5,1, "boy-man", cex=1.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2,
     yaxt='n',xaxt='n')
abline (find_intersection (params[1,], params[4,]),lwd=2, col = bmmb::cols[9]) # b vs w

text (1.5,1, "boy-woman", cex=1.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2)
abline (find_intersection (params[2,], params[3,]),lwd=2, col = bmmb::cols[10]) # g vs m

text (1.5,1, "girl-man", cex=1.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2,
     yaxt='n')
abline (find_intersection (params[2,], params[4,]),lwd=2, col = bmmb::cols[13]) # g vs w

text (1.5,1, "girl-woman", cex=1.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2,
     yaxt='n')
abline (find_intersection (params[3,], params[4,]),lwd=2, col = bmmb::cols[14]) # m vs w

text (1.5,1, "man-woman", cex=1.5)

mtext (side=1, "Centered vocal tract length (cm)", outer = TRUE, line=3)
mtext (side=2, "Centered f0 / 100 (Hz)", outer = TRUE, line=3)

```

All six boundary lines are presented in the left plot of figure \@ref(fig:F12-3). One problem with considering the figure in this way is that many of the boundaries are not very relevant. For example, the boundary between girl and man will hardly matter for classification because these categories are divided by 'woman' and 'boy' classifications. The right plot of figure \@ref(fig:F12-3) presents only those boundaries that are *relevant*. This can be stated more formally as: The figure contains only those boundaries that represents scores equal to or greater than the maximal score, for that location, from among the response categories. For example, in the left plot we see that the boy-woman boundary bisects the are where man is a modal response. This line segment does not feature in the right plot because it has a lower value than the man plane in this area. In other words, who cares if its a boy or a woman because people are more likely to say man anyways. 

```{r F12-3, fig.height = 3, fig.width=8, fig.cap = "boys (b), girls (g), men (m), and women (w).", echo = FALSE}


################################################################################
### Figure 12.3
################################################################################


params = fixef (model_multinomial)
params = fixef (model_multinomial, summary = FALSE)
params = cbind (colMeans (params[,1:3]), 
                colMeans (params[,c(4,6,8)]),
                colMeans (params[,c(5,7,9)]))

params = rbind (c(0,0,0), params[1:3,])

tab = table (exp_data$S, exp_data$C)
mod_cat = apply (tab, 1,which.max)

par (mfrow = c(1,2), mar = c(.0,.0,.21,.2),oma=c(4,4,.1,.1))

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat])
abline (find_intersection (params[1,], params[2,]),lwd=3, col = bmmb::cols[7])
abline (find_intersection (params[1,], params[3,]),lwd=3, col = bmmb::cols[8])
abline (find_intersection (params[1,], params[4,]),lwd=3, col = bmmb::cols[9])
abline (find_intersection (params[2,], params[3,]),lwd=3, col = bmmb::cols[10])
abline (find_intersection (params[2,], params[4,]),lwd=3, col = bmmb::cols[13])
abline (find_intersection (params[3,], params[4,]),lwd=3, col = bmmb::cols[14])

points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)
#points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 1, col = 1,
#     lwd=2, cex=2)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],ylab="",yaxt="n")

maps = make_map (t(params))

plot_map (maps, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)

points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)
#points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 1, col = 1,
#     lwd=2, cex=2)

mtext (side=1, "Centered vocal tract length (cm)", outer = TRUE, line=2.5)
mtext (side=2, "Centered f0 / 100 (Hz)", outer = TRUE, line=2.5)

```

We noticed something very strange when we made the territorial map in figure \@ref(fig:F12-3): The boy territory contains a large number of woman responses. In addition, the boy-woman boundary seems strangely high. If that is really the boundary between boys and women in the VYL by f0 space, then why is the model classifying all those women correctly? The answer to this question may lie in figure \@ref(fig:F12-4). 

In the left plot of figure \@ref(fig:F12-3), point colors represent modal listener judgments for each speaker. In the middle plot we see model predictions including speaker and listener random effects. When these are included the model predictions look very much like the listener judgments and the classifications don't make much sense relative to the territorial map. In the right plot of the same figure we see model predictions when random effects are *not* included. In this case we see that model predictions do *not* look like the listener judgments, but the classifications *do* make sense relative to the territorial map. So, it seems that the random effects may be causing this strange behavior in our model.

```{r F12-4, fig.height = 3, fig.width=8, fig.cap = "boys (b), girls (g), men (m), and women (w).", echo = FALSE}

################################################################################
### Figure 12.4
################################################################################


params = fixef (model_multinomial)
params = fixef (model_multinomial, summary = FALSE)
params = cbind (colMeans (params[,1:3]), 
                colMeans (params[,c(4,6,8)]),
                colMeans (params[,c(5,7,9)]))

params = rbind (c(0,0,0), params[1:3,])

tab = table (exp_data$S, exp_data$C)
mod_cat = apply (tab, 1,which.max)

cats = apply(multi_pred[,1,],1,which.max)
table (exp_data$C, cats)
tab2 = table (exp_data$S, cats)
mod_cat2 = apply (tab2, 1,which.max)

cats = apply(multi_pred_re[,1,],1,which.max)
table (exp_data$C, cats)
tab2 = table (exp_data$S, cats)
mod_cat3 = apply (tab2, 1,which.max)


par (mfrow = c(1,3), mar = c(.0,.0,.21,.2),oma=c(4,4,2,.1))

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],ylab="")
#maps = make_map (t(params))
mtext (side=3, text = "Listener Judgments", line = 0.5)

plot_map (maps, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat2],ylab="",yaxt="n")
plot_map (maps, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat3], cex = 2)
mtext (side=3, text = "Model Predictions (with RE)", line = 0.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat3],ylab="",yaxt="n")
plot_map (maps, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat2], cex = 2)
mtext (side=3, text = "Model Predictions (no RE)", line = 0.5)

mtext (side=1, "Centered vocal tract length (cm)", outer = TRUE, line=2.5)
mtext (side=2, "Centered f0 / 100 (Hz)", outer = TRUE, line=2.5)

```

Figure \@ref(fig:F12-5) presents the speaker random intercepts. Since there are three modeled categories, there are three random intercepts for each speaker. We can see that, in general, the speaker intercepts have small values that vary around zero, and have credible intervals that mostly include zero. However, many female speakers have intercepts that have large non-zero values for the female category, and whose credible intervals omit zero and very small values.

```{r F12-5, fig.height = 4, fig.width=8, fig.cap = "boys (b), girls (g), men (m), and women (w).", echo = FALSE}

################################################################################
### Figure 12.5
################################################################################

sranef = ranef(model_multinomial)$S

tab = table (exp_data$S, exp_data$C_v)
real_cat = apply (tab, 1,which.max)

par (mfrow = c(4,1), mar =c(.1,4,.1,.5), oma = c(.5,0,.5,0))
brmplot((sranef[,,1]+sranef[,,2]+sranef[,,3])/3, labels = '', 
        col = bmmb::cols[real_cat+1], ylim = c(-8,8))
text (1,7,"Boy category speaker intercepts", pos=4,cex=1.4)

brmplot(sranef[,,1], labels = '', col = bmmb::cols[real_cat+1], ylim = c(-8,8))
text (1,7,"Girl category speaker intercepts", pos=4,cex=1.4)

brmplot(sranef[,,2], labels = '', col = bmmb::cols[real_cat+1], ylim = c(-8,8))
text (1,7,"Man category speaker intercepts", pos=4,cex=1.4)

brmplot(sranef[,,3], labels = '', col = bmmb::cols[real_cat+1], ylim = c(-8,8))
text (1,7,"Woman category speaker intercepts", pos=4,cex=1.4)

```

Here is what we believe is happening. Think of the female response plane with a specific intercept, VTL slope and f0 slope. If female speaker categorizations were very predictable based on the value of this plane at a given location, all the female speaker effects would be zero or near zero. This is because if the score based on the plane explains classification, there is nothing left for the speaker intercept to explain. We can see this sort of behavior for adult male speakers: Adult male speakers are mostly easy to identify because of their unusually low voice f0.

In contrast, consider a situation where individual female speakers fall way off the plane, in a seemingly random but consistent manner. For example, imagine a female speaker whose score is way higher than the plane says it should be, but that every listener seems to behave this way for this speaker. This would mean that this is a consistent classification for this voice, that cannot be explained by the score according to the plane. In other words, the classification cannot be predicted based on the linear combination of voice VTL and f0. In such a situation, this consistent classification would be explained by the speaker intercept. Effectively, this tells your model "use the general female plane, but move it up/down this much specifically for this person". Why are we moving it up/down for this person? Our model can't tell us, however, it can tell us that the up/down adjustment is consistent for the speaker across listeners and improves model performance.

We can think about what these speaker effects might reflect. The information regarding gender and age in voices is subtle and complicated, and likely reflects subtle stylistic and prosodic cues. Basically, sounding 'feminine' and 'masculine' is much more complicated than just f0 or VTL. This is analogous to the fact that women tend to be shorter than men, but it would be ridiculous to suggest that masculinity/femininity are entirely predictable based on the height of a person. Size is perhaps an aspect of perceived femininity/masculinity but the whole of it is substantially more complicated. 

We again consider our model prediction accuracy, but this time consider predictions without any random effects.

```{r}
predicted_no_re = apply (multi_pred[,1,],1,which.max)
predicted_category_no_re = c("b","g","m","w")[predicted]
```

The picture without random effects is much more grim. Correct prediction is not *too* bad (relative to chance at 25%), however, some of the individual categories are predicted very poorly. As expected, accurate prediction of woman responses is particularly bad with only 22% of female responses being accurately predicted as such. 

```{r}
# overall correct
mean (predicted_category_no_re == exp_data$C)

# correct predictions by category
tab = xtabs (~ exp_data$C + predicted_category_no_re)
diag(tab) / rowSums(tab)
```

### Refitting the model without speaker random effects

The results of our previous model suggest that the inclusion of speaker random effects may lead to some unintended consequences. Model prediction is good as long as we include the speaker random effects. However, these do not let us understand the prediction of new speakers. Further, the territorial map we can generate using the figure is a bit unreliable because of its reliance on the speaker random effects included in the model. We will try fitting the model without speaker effects to see if we get a territorial map that is a better match for the listener judgments. We use the same priors we used before, and fit the same model save for the absence of speaker effects from our fromula: 

```{r, eval = FALSE}
model_multinomial_noS = 
  brms::brm (y|trials(size) ~ vtl+f0 + (vtl+f0|L), data=exp_data, 
             family=multinomial(), chains=4, cores=4, warmup=1000, iter = 5000, 
             thin = 4, prior = multinomial_prior)
```
```{r, eval = FALSE}
model_multinomial_noS = bmmb::get_model ("../models/12_model_multinomial_noS.RDS")
```
```{r}
#  saveRDS (model_multinomial_noS, "../../models/12_model_multinomial_noS.RDS")
model_multinomial_noS = readRDS ("../models/12_model_multinomial_noS.RDS")
```

```{r, eval = FALSE}
multi_pred_noS = predict (model_multinomial_noS, re_formula = NA)
multi_pred_re_noS = predict (model_multinomial_noS)
```

We just straight to plotting the territorial map represented by this model, again comparing listener judgments to model predictions with and without random effects (\@ref(fig:F12-6)). We can wee that the territorial maps in the figure seem to be a better match to the data.

```{r F12-6, fig.height = 3, fig.width=8, fig.cap = "boys (b), girls (g), men (m), and women (w).", echo = FALSE}

################################################################################
### Figure 12.6
################################################################################


params = fixef (model_multinomial_noS)
params = fixef (model_multinomial_noS, summary = FALSE)
params = cbind (colMeans (params[,1:3]), 
                colMeans (params[,c(4,6,8)]),
                colMeans (params[,c(5,7,9)]))

params = rbind (c(0,0,0), params[1:3,])

tab = table (exp_data$S, exp_data$C)
mod_cat = apply (tab, 1,which.max)

cats = apply(multi_pred_noS[,1,],1,which.max)
table (exp_data$C, cats)
tab2 = table (exp_data$S, cats)
mod_cat2 = apply (tab2, 1,which.max)

cats = apply(multi_pred_re_noS[,1,],1,which.max)
table (exp_data$C, cats)
tab2 = table (exp_data$S, cats)
mod_cat3 = apply (tab2, 1,which.max)


par (mfrow = c(1,3), mar = c(.0,.0,.21,.2),oma=c(4,4,2,.1))

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],ylab="")

maps_noS = make_map (t(params))

mtext (side=3, text = "Listener Judgments", line = 0.5)

plot_map (maps_noS, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat2],ylab="",yaxt="n")
plot_map (maps_noS, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat3], cex = 2)
mtext (side=3, text = "Model Predictions (with RE)", line = 0.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat3],ylab="",yaxt="n")
plot_map (maps_noS, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat2], cex = 2)
mtext (side=3, text = "Model Predictions (no RE)", line = 0.5)

mtext (side=1, "Centered vocal tract length (cm)", outer = TRUE, line=2.5)
mtext (side=2, "Centered f0 / 100 (Hz)", outer = TRUE, line=2.5)

```

Figure \@ref(fig:F12-7) compares the territorial maps represented by our models with (left) and without (right) speaker information. In addition to being a better fit to the data, we think the new territorial maps make more 'sense'. This is because the map with speakers suggests that the difference between women and boys was almost entirely due to f0, with women being associated with the higher f0. This is despite boys being associated with shorter VTLs than adult females *and* a higher f0. The new map has basically no effect for f0 between these categories and makes it a primarily VTL difference, which is backed up by the distributions of these characteristics between these speaker types. 

```{r F12-7, fig.height = 3, fig.width=8, fig.cap = "(left) Territorial maps indicating which sections of the stimulus space are associated with: Boys (turquoise), girls (yellow), men (green), and women (red). Points represent individual speakers, colors represent modal classifications using the same colors as the territories.", echo = FALSE}

################################################################################
### Figure 12.7
################################################################################


params = fixef (model_multinomial_noS)
params = fixef (model_multinomial_noS, summary = FALSE)
params = cbind (colMeans (params[,1:3]), 
                colMeans (params[,c(4,6,8)]),
                colMeans (params[,c(5,7,9)]))

params = rbind (c(0,0,0), params[1:3,])

tab = table (exp_data$S, exp_data$C)
mod_cat = apply (tab, 1,which.max)

cats = apply(multi_pred_noS[,1,],1,which.max)
tab2 = table (exp_data$S, cats)
mod_cat2 = apply (tab2, 1,which.max)

cats = apply(multi_pred_re_noS[,1,],1,which.max)
tab2 = table (exp_data$S, cats)
mod_cat3 = apply (tab2, 1,which.max)


par (mfrow = c(1,2), mar = c(.0,.0,.21,.2),oma=c(4,4,2,.1))

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],ylab="")

#maps_noS = make_map (t(params))

mtext (side=3, text = "model_multinomial", line = 0.5)

plot_map (maps, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat2],ylab="",yaxt="n")
plot_map (maps_noS, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)
mtext (side=3, text = "model_multinomial_noS", line = 0.5)

mtext (side=1, "Centered vocal tract length (cm)", outer = TRUE, line=2.5)
mtext (side=2, "Centered f0 / 100 (Hz)", outer = TRUE, line=2.5)

```

One concern with omitting the speaker effects is that our model now thinks all observations for any one speaker are independent. Based on what we saw in figure (intercepts) we know that this is defnitely not the case. Instead, individual speakers were identified as one or another category consistently, indicating that these judgments were related across listeners. Tis can potentially have the effect of artificially decreasing our confidence intervals, as we see in chapter 6 (heck out details, it was for A1). Figure \@ref(fig:F12-8) compares the fixed effects between our two models, suggesting that the omission of the speaker effects has not had a large effect on our parameters. The two largest differences are for the woman category: The intercept went from slightly negative to slightly positive, nd the effect for f0 went from zero to positive. 

```{r F12-8, fig.height = 3, fig.width=8, fig.cap = "-- ", echo = FALSE}
################################################################################
### Figure 12.8
###############################################################################

par (mar = c(4,8,1,1))
brmplot (fixef(model_multinomial)[c(1,4,5,2,6,7,3,8,9),], las = 2,
         horizontal = FALSE,col = 0, xlim = c(-5,6))
abline (h = seq(1,10),lty=3,col="grey")
brmplot (fixef(model_multinomial)[c(1,4,5,2,6,7,3,8,9),], add = TRUE,
         nudge = -0.2, labels = "", horizontal = FALSE, pch=16,
         col = rep(bmmb::cols[3:5],each=3))
brmplot (fixef(model_multinomial_noS)[c(1,4,5,2,6,7,3,8,9),], add = TRUE,
         nudge = 0.2, labels = "", horizontal = FALSE, pch=17,
         col = rep(bmmb::cols[3:5],each=3))

legend (2.5,9,legend =c("With Speaker","No Speaker"),bty='n',
        pch=16:17,pt.cex=1.3)
```

We again find the maximum a posteriori speaker classification and get a label for each trial. 

```{r}
predicted_noS = apply (multi_pred_re_noS[,1,],1,which.max)
predicted_category_noS = c("b","g","m","w")[predicted_noS]
```

And calculate correct classifications overall and by category. Performance is not as good as the model with speaker effect when random effects are included (82%) but not as bad as for the same model when random effects are not included (59%). In addition, we see very good classification of all categories except for 'boy'. 

```{r}
# overall correct
mean (predicted_category_noS == exp_data$C)

# correct predictions by category
tab = xtabs (~ exp_data$C + predicted_category_noS)
diag(tab) / rowSums(tab)
```

Importantly, we see that classification barely changes when random effects are not included, except for boy classifications which drop even below chance. 

```{r}
predicted_noS_no_re = apply (multi_pred_noS[,1,],1,which.max)
predicted_category_noS_no_re = c("b","g","m","w")[predicted_noS_no_re]

# overall correct
mean (predicted_category_noS_no_re == exp_data$C)

# correct predictions by category
tab = xtabs (~ exp_data$C + predicted_category_noS_no_re)
diag(tab) / rowSums(tab)
```

### Answering our research questions

We can use our models to answer the question we posed above:

Q1) Can we use speaker f0 and VTL to predict their apparent speaker category?

Yes, we can use speaker f0 and VTL to predict apparent speaker with relative accuracy. If we consider a baseline correctness by chance along of 25%, then our classification of 72% from two predictors (with no random effects) isn't bad at all. However, the importance of the speaker random effects for female speakers strongly suggests that there is 'something else' being used to identify women as women, apart from VTL and f0. So, our first model tells us that we should probably try to understand what that 'something else' is. The speaker random effects are not particularly useful for understanding the categorization of new speakers. However, understanding what causes the variation in these random effects is. Our model tells us that even though we know there is something else to it, we can still pretty much predict categorization from just these two predictors. So, the first model may be better to really try to understand what listeners are doing when they classify while the second model may be better to understand classification from just f0 and VTL. 

## Ordinal (logistic) regression

Ordinal logistic regression involves the prediction of ordered categories. Although in some senses ordinal regression is 'simpler' than multinomial regression, we decided to present it after multinomial regression. This is because multinomial regression is mostly just a multivariate generalization of logistic regression, which was discussed in detail in chapter 10. In contrast, ordinal regression, although related to (dichotomous) logistic regression, is in many ways conceptually its own thing. We will present one way of thinking about logistic regression however, as usual, there are other ways to think of it.  

A simple example of an ordinal variable is first, second, and third place in a race. These values are categorical and not numerical. For example fourth place is not 'double' anything with respect to second place (i.e., $2 \times second \neq fourth$). However, there is clearly an inherent ordering in the categories such that first < second < third < fourth < and so on. A common experimental example of ordered categorical data arises from survey data that asks listeners to respond to questions using a small number of discrete, categorical choices. For example, respondents might be asked to evaluate whether they 1) strongly agree, 2) somewhat agree, 3) are neutral, 4) somewhat disagree, or 5) strongly disagree with some proposition. This is often referred to as a **Likert scale** and the data resulting from this is often refereed to as **Likert scale data**. 

Likert scale data was originally meant to have response scales ranging from agreement to disagreement. However, the concept of Likert scale data can be generalized to a very broad range of possible questions. For example, rather than height in centimeters, we might have asked listeners "use this 10 point scale to indicate how tall this person sounds". This could be made more traditional by asking it in the form "this person sounds very tall" and asking people to agree or disagree on a 10 point scale. Rather than ask for binary gender judgments, we might have asked "Use this 7 point scale to judge the perceived femininity/masculinity of the speaker" (or the more traditional "this person sounds very feminine" and asking people to agree or disagree on a 7 point scale).

Although Likert scale data is sometimes treated as quantitative, there are some characteristics of this data that make an ordinal analysis a better fit. First, it is not necessarily the case that the 'distance' between adjacent responses is equal across both categories. We can say with absolute certainty that the difference between 150 and 151 cm is equal to the difference between 151 and 152 cm. However, is the difference between strongly agree and somewhat agree the same as the distance between somewhat agree and neutral? Not necessarily. Further, the small number of outcome categories may result in subjects reserving extreme categories for extraordinary cases. What if a subject somewhat strongly agrees? There is no such option, and this subject may instead indicate somewhat agree lest something they *really* strongly agree with comes along. 

Here's what we said in chapter 1 about when to treat a variable as quantitative:

* Is the variable on a ratio or interval scale? This is a prerequisite for a quantitative value to be used as a dependent variable. An interval scale means that distances are meaningful, and a ratio scale means that 0 is meaningful.  

* Is the underlying value continuous? Many variables are discrete in practice due to limitations in measurement. However, if the underlying value is continuous (e.g., height, time) then this can motivate treating the measurement as a quantitative dependent variable since fractional values 'make sense'. For example, even if you measure time only down to the nearest millisecond, a value of 0.5 milliseconds is possible and interpretable. In contrast, a value of 0.5 people is not.

* Are there a large number (>50) of possible values the measured variable can take? For example a die can only take on 6 quantitative values, which is not enough.

* Are most/all of the observed values far from their bounds? Human height does not really get much smaller than about 50 cm and longer than about 220 cm, so it is technically bounded. However, in most cases our observations are expected to not be clustered at the boundaries. 

If survey participants were given numerical categories and were told that this represented some continuous value 'agreement', then we could perhaps argue that that 5-point Likert scale data abides by the first two considerations above. However, our data runs afoul of the bottom two considerations: There are only a small number of discrete outcomes, with nothing 'in between', and many of the observed values are likely to be near the boundaries and are likely to be constrained by these. 

We don't actually have any ordinal variables in our experiment, but we still wanted to provide an example of an ordinal analysis. To do this, we're going to make a fake ordinal variable that we think is actually relatively defensible. Below we see a boxplot of apparent height judgments organized by apparent speaker category, with boys and girls collapsed into one (child) category. Note that apparent children are judged to be shortest, apparent women are judged to be a little taller than that, and apparent men are judged to be a little taller than women. Based on this, we could think of our apparent speaker categories as reflecting classifications of speakers into small (boys, girls), medium (women), and large (men). Based on the boxplot below, we might imagine that if we *had* asked listeners to identify speakers small, medium, or large, listeners would have labelled most apparent children as small, most apparent women as medium, and most apparent men as large.

```{r F12-9, fig.height = 3, fig.width=8, fig.cap = " -- ", echo = FALSE}

################################################################################
### Figure 12.9
################################################################################

library (bmmb)
data (exp_data)

SG = 0
SG[exp_data$C=='m'] = 3
SG[exp_data$C=='w'] = 2
SG[exp_data$C=='g'] = 1
SG[exp_data$C=='b'] = 1


x = seq (100,200,.1)
y = seq (100,200,.1)

par (mfrow = c(1,2), mar = c(.1,.1,.1,.1), oma = c(4,4,.5,.5))

boxplot (height ~ SG, data = exp_data,col=bmmb::cols[c(1,11,10)],ylim = c(100,200),
         xlab = "Apparent Speaker Category",names=c("Child","Woman","Man"))

tmp = aggregate (height ~ SG, data = exp_data, FUN = mean)
abline (h = mean (tmp[1:2,2]), lwd = 2, col = bmmb::cols[15])
abline (h = mean (tmp[2:3,2]), lwd = 2, col = bmmb::cols[15])
boxplot (height ~ SG, data = exp_data,col=bmmb::cols[c(1,11,10)],
         add = TRUE,xlab = "",xaxt='n')
mtext (side=1,text="Size Group", line = 2.5)
mtext (side=2,text="Apparent Height (cm)", line = 2.75)

plot (x,y, yaxt='n',type = 'l', xlim = c(120,190),ylim = c(100,200),xaxt='n')
rect (100,90,200,mean(tmp[1:2,2]), col = bmmb::cols[1],border=bmmb::cols[1])
rect (100,mean(tmp[1:2,2]),200,mean(tmp[2:3,2]), col = bmmb::cols[11],border=bmmb::cols[11])
rect (100,mean(tmp[2:3,2]),200,400, col = bmmb::cols[10],border=bmmb::cols[10])
lines (x,y, lwd=4, col = bmmb::cols[2])

points (c(140,160,180),c(140,160,180),pch=16,col=bmmb::cols[2],cex=2)
abline (h = mean (tmp[1:2,2]), lwd = 6, col = bmmb::cols[15])
abline (h = mean (tmp[2:3,2]), lwd = 6, col = bmmb::cols[15])

text (118,c(140,163,195), c("Small", "Medium", "Large"),cex=1.1,pos=4)
axis (side=1, at = seq(110,190,length.out=6), labels = 11:16)
mtext (side=1,text="Vocal tract length (cm)", line = 2.75)
```

The right plot in figure \@ref(fig:F12-9) presents the y axis divided into three sections. The boundaries between sections are halfway between the means of apparent children and adult females (155.7 cm), and apparent adult females and adult males (170 cm) apparent speakers. We can think of these sections as reflecting expected categorization of speakers into small, medium, or large based on their apparent height.

We can see how this might work using the code below. First, we convert our observed speaker classifications into a new variable that we will treat as ordinal. This variable is *size group* (`SG`), and it has the values 1 (small), 2 (medium), and 3 (large). 

```{r}
SG = 0
SG[exp_data$C=='b' | exp_data$C=='g'] = 1
SG[exp_data$C=='w'] = 2
SG[exp_data$C=='m'] = 3
```

Then, we create a new variable that will hold our size group predictions, `SG_hat`. After this, we set this variable to 1 if apparent height is less than the boundary between small and medium (155.7 cm), to 2 if apparent height is greater than the boundary between small and medium (155.7), but less than the boundary between medium and large (170 cm), and to 3 if it is greater than the boundary between medium and large (170 cm).

```{r}
SG_hat = exp_data$height * 0
SG_hat[exp_data$height <= 155.7] = 1
SG_hat[exp_data$height >= 155.7 & exp_data$height <= 170] = 2
SG_hat[exp_data$height >= 170] = 3
```

We can see that this relatively primitive 'model' is able to correctly predict size group responses in 75% of cases. 

```{r}
mean (SG == SG_hat)
```

Imagine that the line in the right plot in figure \@ref(fig:F12-9) reflects the relationship between speaker VTL and apparent height. We know from earlier chapters that a longer speaker VTL is associated with taller apparent speakers. Let's assume for the sake of simplicity that this relationship is causal and that there is a direct connection between speaker VTL and apparent height. This means that when we hear a voice, we can be thought of as sliding along the line in the plot based on the VTL of the speaker. Then, based on the apparent height value at a given x axis location, we can arrive at a size group classification based on the method above. 

Note that in the scenario above we were not collecting or observing apparent speaker height but rather predicting size group using VTL. Instead, by assuming that apparent height was driving this process but not trying to measure it directly we treated it as a latent variable. We acted like this variable was apparent size, however, the latent variable could have had any name and used any other units. For example, in our situation we can think of this variable as 'size' or 'bigness', buts its name is not important, and neither is us having a rock-solid conceptual grasp of what it is exactly. Instead, all we need to understand is that we think there is some latent variable, something like 'bigness', that allows listeners to classify speakers into small, medium, and large groups based on their voices. 

The right side of figure \@ref(fig:F12-10) is labelled "bigness" to correspond to our hypothetical latent variable. This variable is just apparent height divided by 50, but the point is that the values of this axis are entirely arbitrary. Notice that the change in axis units has absolutely no effect of the way our conceptual model works. If the latent variable units are 50 times smaller than some other variable, that just means the line relating x to y is 50 times smaller and the boundaries between categories are equal to the other categories divided by 50. The same logic applies to the relationship between our latent dependent variable and our predictors. 

```{r F12-10, fig.height = 3, fig.width=8, fig.cap = " -- ", echo = FALSE}

################################################################################
### Figure 12.10
################################################################################

tmp = aggregate (height ~ SG, data = exp_data, FUN = mean)

x = seq (-35,35,.1)
y = dlogis(x,0,5)

x_2 = seq (100,230,.1)
y_2 = x_2


par (mfrow = c(1,1), mar = c(4,4,.1,4), oma = c(.5,.5,.51,.51))
#layout (mat = t(c(1,2)), widths = c(.6,.4))

plot (x,y, yaxt='s',type = 'l', xlim = c(120,190),ylim = c(105,215),
      xlab = "Apparent Height (cm)",xaxt='n',ylab="Apparent Height (cm)")
rect (100,90,200,mean(tmp[1:2,2]), col = bmmb::cols[1],border=bmmb::cols[1])
rect (100,mean(tmp[1:2,2]),200,mean(tmp[2:3,2]), col = bmmb::cols[11],border=bmmb::cols[11])
rect (100,mean(tmp[2:3,2]),200,400, col = bmmb::cols[10],border=bmmb::cols[10])
lines (x_2,y_2, lwd=4, col = bmmb::cols[2])


axis (side=4, at = seq(120,200,20), labels = seq(120,200,20)/5)

spot = 160
lines (-y*150+spot, x+spot, ylim = c(120,190), xlim = c(-.35,0), xaxs='i',type='l',lwd=2)
lines (rep(spot,length(x)),x+spot,type="l",lwd=2)
points (spot,spot,pch=16,col=bmmb::cols[2],cex=2)

spot = 140
lines (-y*150+spot, x+spot, ylim = c(120,190), xlim = c(-.35,0), xaxs='i',type='l',lwd=2)
lines (rep(spot,length(x)),x+spot,type="l",lwd=2)
points (spot,spot,pch=16,col=bmmb::cols[2],cex=2)

spot = 180
lines (-y*150+spot, x+spot, ylim = c(120,190), xlim = c(-.35,0), xaxs='i',type='l',lwd=2)
lines (rep(spot,length(x)),x+spot,type="l",lwd=2)
points (spot,spot,pch=16,col=bmmb::cols[2],cex=2)

text (118,c(140,163,195), c("Small", "Medium", "Large"),cex=1.1, pos=4)

abline (h = mean (tmp[1:2,2]), lwd = 5, col = bmmb::cols[15])
abline (h = mean (tmp[2:3,2]), lwd = 5, col = bmmb::cols[15])

axis (side=1, at = seq(110,190,length.out=6), labels = 11:16)
lines (x,y, lwd=4, col = bmmb::cols[2])

mtext (side=4, "Bigness", line=2.2)
```

Our model so far would do a reasonable job of predicting classification but contains no random component. In figure \@ref(fig:F9-1) we showed that bivariate linear regression with Gaussian errors can be thought of as a Gaussian distribution sliding along a line based on the value of the dependent variable. The y axis value of the line at an x axis location tells you the expected value of y for that value of x. However, we will hardly (if ever) observed the expected value exactly. Instead, we assume that we have Gaussian error centered around our expected values so that the values we observe actually probabilistically vary around the expected value. 

We show a similar situation in figure \@ref(fig:F12-10), with a probability distribution sliding along a line. However, in the case of ordinal regression the values that this distribution generates are not the observed values of the ordinal dependent variable, but rather values of the *latent* variable (e.g. 'bigness'). The observed ordinal variable is then based on the value of the latent variable with respect to the boundaries in the space. In this chapter we will use a *logistic* distribution as the error distribution (more detail on this in the next section), hence the name, ordinal *logistic* regression. We will do this because it is commonly used and has some useful characteristics, but a basically equivalent model can be constructed assuming a Gaussian distribution for the latent variable. 

Ordinal regression estimates the location of boundaries between categories along the latent variable, and tries to predict the expected value of the latent variable based on a combination of the dependent variables. For example, in figure \@ref(fig:F12-10) the boundaries are at 31 and 34 bigness, and you have an expected bigness of around 32 for a vocal-tract length of 14.1. We can think of it this way: Given a VTL of 14.1 we know how big people will sound in general, but these things are fuzzy and necessarily noisy. So there is actually a distribution of expected perceived/apparent 'bigness' given our predictors. Sometimes, this distribution might 'generate' a bigness value of 28, resulting in a response of small, while for another observation the value of the latent variable may be 36 and the speaker will be identified as large. 

### Cumulative density functions

In order to understand ordinal regression, we need to talk about cumulative distribution functions first. We haven't explicitly talked about cumulative distribution functions yet, though we did see one in chapter 10 when it was referred to as the *logistic* function (more on this in a moment). To this point we've been focused on what are called *probability density functions* (PDF), functions that assign a density to different values a variable can take. Examples of PDFs are given in the top row of figure \@ref(fig:F12-11). **Cumulative distribution functions** (CDF) tell you the probability that a variable will be *less than or equal to* some value. Since a PDF has an area under the curve equal to 1 (representing the total probability of the variable), then the CDF tells you how much of the area under the curve of the PDF is to the left of any value.

For example, in the left column of figure \@ref(fig:F12-11) we see a standard normal distribution with a mean of 0 and a standard deviation of one. We know that the normal distribution is symmetrical about its mean so that half the area under the curve of this density must be below 0. If we look at the bottom row of the first column, we can see the CDF corresponding to the PDF in the top row. If we look at the value of this function at x=0, we see that it is exactly equal to 0.5. In other words, the cumulative function tells us that the standard normal has exactly half its mass at values less than x=0, i.e. the probability of observing a value of x that is less than or equal to 0 is exactly 0.5.

```{r F12-11, fig.height = 3.5, fig.width=8, fig.cap = " -- ", echo = FALSE}

################################################################################
### Figure 12.11
################################################################################

par (mfcol = c(2,3), mar = c(.1,.2,.11,.2), oma = c(2.5,4,3,.5))

x = seq(-5,5,.01)
plot (x, dnorm (x), type = 'l', xaxt='n', xaxs='i',lwd=4,col=bmmb::cols[5],yaxt='n')
mtext (side=2,"Density", line=2.5)
mtext (side=3,"Standard Normal", line=1)
abline (v = 0,lty=3,col="grey",lwd=3)
plot (x, pnorm (x), type = 'l', xaxs='i',lwd=4,col=bmmb::cols[5])
mtext (side=2,"Cumulative Probability", line=2.5)
segments (-6,.5,0,.5,lty=3,col="grey",lwd=3)
segments (0,-5,0,.5,lty=3,col="grey",lwd=3)
text (0.1,.2,"x=0", cex = 1.5,pos=4)
text (-3,.6,"y=0.5", cex = 1.5,pos=4)

x = seq(-10,10,.01)
plot (x, dlogis (x), type = 'l', xaxt='n', yaxt='n', xaxs='i',lwd=5,col=bmmb::cols[2])
mtext (side=3,"Logistic", line=1)
abline (v = 2,lty=3,col="grey",lwd=3)
plot (x, plogis (x), type = 'l', yaxt='n', xaxs='i',lwd=5,col=bmmb::cols[2])
segments (-16,.88,2,.88,lty=3,col="grey",lwd=3)
segments (2,-5,2,.88,lty=3,col="grey",lwd=3)
text (2.1,.2,"x=2", cex = 1.5,pos=4)
text (-7,.8,"y=0.88", cex = 1.5,pos=4)

x = seq(-10,10,.01)
plot (x, dlogis (x), type = 'l', xaxt='n', yaxt='n', xaxs='i',lwd=5,col=bmmb::cols[1])
mtext (side=3,"Logistic", line=1)
abline (v = c(2,-1),lty=3,col="grey",lwd=3)
plot (x, plogis (x), type = 'l', yaxt='n', xaxs='i',lwd=5,col=bmmb::cols[1])
segments (-16,.88,2,.88,lty=3,col="grey",lwd=3)
segments (-16,.27,-1,.27,lty=3,col="grey",lwd=3)
segments (2,-5,2,.88,lty=3,col="grey",lwd=3)
segments (-1,-5,-1,.27,lty=3,col="grey",lwd=3)
text (2.1,.2,"x=2", cex = 1.5,pos=4)
text (-7,.8,"y=0.88", cex = 1.5,pos=4)

text (-5.11,.1,"x= -1", cex = 1.5,pos=4)
text (-7,.35,"y=0.27", cex = 1.5,pos=4)
```

We can use the `pnorm` function (discussed in chapter 2) to get the value of the normal CDF for any value of x. Below we calculate this for x=0, x= -2, and x=2. See that in each case, the output of the function corresponds to the y axis value of the CDF at that x axis location (bottom left, figure \@ref(fig:F12-11)).

```{r}
# cumulative density at x = 0
pnorm (0,0,1)

# cumulative density at x = -2,2
pnorm (c(-2,2),0,1)
```

The CDF is the **integral** of the PDF, and the PDF is the **derivative** of the CDF. We've already explained the *integral* part of this: As you move left to right, the value of the CDF equals the cumulative (i.e. added up total) area under the curve (i.e. probability) in the PDF to that point. To say that the PDF is the derivative of the CDF means that the value of the PDF reflects the *rate of change* (i.e. the slope) in the CDF for different values of x. Imagine you were on a car driving along the standard normal CDF in figure \@ref(fig:F12-11), left to right. As you drive along around -4 the 'terrain' is flat and the value of the density is near 0. As you near -2 the slope of the CDF begins to increase, as does the value of the PDF. The value of the PDF is largest at x=0, telling us that the slope of the CDF is greatest at that point. As we drive past x=0 we see a gradual decrease in the slope until we more or less reach 'flat ground' again at just past x=2. This is reflected by the gradual decrease in the value of the PDF between x=0 and x=2. 

In the middle column of figure \@ref(fig:F12-11) we see a logistic distribution. The **logistic distribution** is a two-parameter distribution very similar to the normal distribution but with 'fatter/heavier' tails (like the t distribution). The logistic distribution has a location parameter (\mu, equal to the mean) that determines its location along the number line, and a scale parameter ($s$, equal to the standard deviation times $\sqrt{3}/\pi$) that is positively related to the 'width' of the density function. In the bottom row of the middle column, we see the CDF pf the logistic density. It turns out that logistic function we used as the link function for logistic regression in chapter 10 is simply the CDF of a logistic distribution with a mean of 0 and a scale 0f 1.

In the middle column of figure \@ref(fig:F12-11) we see that we can use the same approach we used for our normal distribution to calculate values of the CDF of our logistic distribution. Below, we use the `plogis` function to calculate the probability of observing a value greater than or equal to 2 form that distribution. 

```{r}
plogis (2,0,1)
```

In the right column of figure \@ref(fig:F12-11) we've placed two vertical lines at x= -1 and x=2. We use the code below to calculate the area under the curve to the left of each line. 

```{r}
# area left of first line
plogis (-1,0,1)

# area left of second line
plogis (2,0,1)
```

At this point, the connection between CDFs and ordinal regressions may be clear: We can use a set of boundaries and the CDF of a probability distribution to calculate the probability of observing values of the latent variable, within certain intervals. Figure \@ref(fig:F12-12) presents an example of how this might work. 

In figure \@ref(fig:F12-12), the boundaries and distributions from figure \@ref(fig:F12-11) have been rotated clockwise 90 degrees so that our latent variable (the arbitrarily named 'bigness') varies along the x axis. The distributions presented in the figure have means of 28, 32, 36, and scales of 1. The probabilities in each subsection of each plot represent the predicted probability of observing size group responses of 1, 2, and 3 for each distribution. These probabilities were calculated based on the area under the curve of the distributions falling between different intervals of the latent variable space. 

```{r F12-12, fig.height = 3.5, fig.width=8, fig.cap = " -- ", echo = FALSE}

################################################################################
### Figure 12.12
################################################################################

x = seq (20,44,.01)
y = dlogis(x,30,1)

x_2 = seq (-4,4.4,.05)
y_2 = x_2

par (mfrow = c(3,1), mar = c(.5,1,.5,1), oma = c(4,.5,.51,.51))

plot (x+3.2,y*2, yaxt='s',type = 'n', xlim = c(22,42),ylim = c(0.02,.8),
      xlab = "",xaxt='n',ylab="",yaxt = 'n')
rect (1,0,31,1, col = bmmb::cols[1],border=bmmb::cols[1])
rect (31,0,34,1, col = bmmb::cols[11],border=bmmb::cols[11])
rect (34,0,50,1, col = bmmb::cols[10],border=bmmb::cols[10])
lines (x-2,y*2.5, xaxs='i',type='l',lwd=2)
abline (v = c(31,34),lwd=5,col=bmmb::cols[15])

text (25, .45, "P(SG=1)=0.95", cex=1.1)
text (32.5, .3, "P(SG=2)=0.04", cex=1.1)
text (40, .3, "P(SG=3)=0.01", cex=1.1)

plot (x+3.2,y*2, yaxt='s',type = 'n', xlim = c(22,42),ylim = c(0.02,.8),
      xlab = "Bigness",xaxt='n',ylab="",yaxt = 'n')
rect (1,0,31,1, col = bmmb::cols[1],border=bmmb::cols[1])
rect (31,0,34,1, col = bmmb::cols[11],border=bmmb::cols[11])
rect (34,0,50,1, col = bmmb::cols[10],border=bmmb::cols[10])
lines (x+2,y*2.5, type = 'l', lwd=2)
abline (v = c(31,34),lwd=5,col=bmmb::cols[15])

text (25, .3, "P(SG=1)=0.26", cex=1.1)
text (32.5, .2, "P(SG=2)=0.61", cex=1.1)
text (40, .3, "P(SG=3)=0.12", cex=1.1)


plot (x+3.2,y*2, yaxt='s',type = 'n', xlim = c(22,42),ylim = c(0.02,.8),
      xlab = "Bigness",xaxt='n',ylab="",yaxt = 'n')
rect (1,0,31,1, col = bmmb::cols[1],border=bmmb::cols[1])
rect (31,0,34,1, col = bmmb::cols[11],border=bmmb::cols[11])
rect (34,0,50,1, col = bmmb::cols[10],border=bmmb::cols[10])
axis (side=1, at = seq(24,40,4),cex=1.2)
lines (x+6,y*2.5, type = 'l', lwd=2)
abline (v = c(31,34),lwd=5,col=bmmb::cols[15])

text (25, .3, "P(SG=1)=0.01", cex=1.1)
text (32.5, .35, "P(SG=2)=0.11", cex=1.1)
text (40, .3, "P(SG=3)=0.88", cex=1.1)

mtext (side=1,"Bigness", line=2.75)
```

For example, below we calculate the probability of observing each size group based on the distribution in the middle plot of figure \@ref(fig:F12-12), a latent variable distribution with a mean of 32 and a scale of 1. First, we find the probability of observing a bigness value less than 31 (the first boundary). This tells us the probability of observing a response of size group 1 for this expected value of bigness (P(SG=1)=0.26). Then, we again find the probability of a bigness value less than 31 (the first boundary), and subtract this from the probability of a bigness value less than 34 (the second boundary). This operation gives us the probability of observing a bigness value between the first and second boundaries, i.e. the probability of observing a medium size group response (P(SG=2) = 0.88 - 0.26). Finally, to find the probability of a large size group response we find the probability of a bigness value less than 34 and subtract this from 1. Since there are no more boundaries above the largest response category, the entire probability above the highest threshold must correspond to the final category. 

```{r}
# probability of observing category 1
plogis (31,32,1)

# probability of observing category 2
plogis (34,32,1) - plogis (31,32,1)

# probability of observing category 3
1 - plogis (34,28,1)
```

This conceptualization of our model leads to both **hard** and **soft** classification. An ordinal regression model will predict, for every classification, an expected value of the dependent variable based on the values of the predictors. This value can then be used to classify the predictions into a predicted category, 1, 23, or 3 based on the value of the variable relative to the thresholds. That would be a *hard* classification that reports only the winning category. In contrast, the expected value can be used in the method shown just above to report response probabilities for each category. For example, it may be useful for the example shown in figure \@ref(fig:F12-12) that the most probable classification is of a 'medium' speaker. However, it may be just as useful to indicate that the probability of this response was only 0.61, making the observation of a small response (P=0.26) not unlikely.

### Data and research questions

We load our packages and data below. We also add a new variable, `SG` (size group), which will act as our dependent variable. This variable represents children with a 1, adult women with a 2, and adult males with a 3. We don't need to do anything special to make this variable 'ordinal', but we are using three consecutive integers to represent the categories to make things simpler. After this, we process our quantitative predictors in the same way as in the previous chapters.

```{r, warning=FALSE, message=FALSE}
library (brms)
library (bmmb)
data (exp_data)

# new dependent variable: Size Group
exp_data$SG = 0
exp_data$SG[exp_data$C=='m'] = 3
exp_data$SG[exp_data$C=='w'] = 2
exp_data$SG[exp_data$C=='g'] = 1
exp_data$SG[exp_data$C=='b'] = 1

# preparation of quantitative predictors as in previous chapters
exp_data$vtl_original = exp_data$vtl
exp_data$vtl = exp_data$vtl - mean (exp_data$vtl)

exp_data$f0_original = exp_data$f0 
exp_data$f0 = exp_data$f0 - mean(exp_data$f0)
exp_data$f0 = exp_data$f0 / 100
```

We're going to keep our research questions relatively simple this time: 

Q1) Can we predict which size group people will tend to respond for a speaker's voice given their f0 and VTL?

### Description of the model

To fit a model predicting apparent size group from speaker f0 and VTL, we can use the formula below:

`SG ~ vtl+f0 + (vtl+f0|L) + (1|S)`

There is nothing new about this model formula, it is very much like ones we've used several times in earlier chapters. The formula says "predict size group using a plane based on voice f0 and VTL, allow for listener-specific planes, and speaker-specific adjustments to the height of the plane". However, the relationship it represents between our predictors and our dependent variables is substantially different to what we've seen before. Let's consider the relationship between the independent variables and the mean of our logistic distribution, presented in equation below:


$$
\begin{equation}
\begin{split}
\mu_{[i]} = VTL \times vtl_{[i]} + F0 \times f0_{[i]}
\end{split}
(\#eq:12-11)
\end{equation}
$$

The result of this regression equation is an expected value for our latent variable. We model this latent variable as being distributed according to a logistic distribution with a mean of $\mu$ and a scale parameter equal to 1, as in equation below. 

$$
\begin{equation}
\begin{split}
z_{[i]} \sim \mathrm{Logistic} (\mu_{[i]}, 1)
\end{split}
(\#eq:12-12)
\end{equation}
$$
Our observed (dependent) ordinal category is then selected based on the value of the latent variable ($z_{[i]}$) for that trial, relative to the model thresholds. We see this in equation below. 

$$
\begin{equation}
\begin{split}
SG_{[i]} = 
\begin{cases}
1 \; \mathrm{if} \; z_{[i]} < \theta_1 \\ 
2 \; \mathrm{if} \; \theta_{[1]} < z_{[i]} < \theta_{[2]} \\ 
3 \; \mathrm{if} \; \theta_{[2]} < z_{[i]} \\ 
\end{cases}       
\end{split}
(\#eq:12-13)
\end{equation}
$$

Here is a full description of our model:

$$
\begin{equation}
\begin{split}
SG_{[i]} = 
\begin{cases}
1 \; \mathrm{if} \; z_{[i]} < \theta_{[1]} \\ 
2 \; \mathrm{if} \; \theta_{[3]} < z_{[i]} < \theta_{[2]} \\ 
3 \; \mathrm{if} \; \theta_{[2]} < z_{[i]} \\ 
\end{cases}
\\\\
z_{[i]} \sim \mathrm{Logistic} (\mu_{[i]}, s)\\
\\
\mu_{[i]} = a_{[i]} + b_{[i]} \times \mathrm{vtl}_{[i]} + c_{[i]} \times \mathrm{f0}_{[i]}  \\ 
a_{[i]} =  L_{[L_{[i]}]} \\
b_{[i]} =  VTL + VTL \colon L_{[L_{[i]}]} \\
c_{[i]} =  F0 + F0 \colon L_{[L_{[i]}]} \\ 
\\
\textrm{Priors:} \\
S_{[\bullet]} \sim \mathrm{Normal}(0,\sigma_{S_j}) 
\\ 
\begin{bmatrix} L_{[\bullet]} \\ VTL \colon L_{[\bullet]} \\ F0 \colon L_{[\bullet]} \end{bmatrix}	
\sim \mathrm{MVNormal} \left(\, \begin{bmatrix} 0\\ 0 \\ 0 \\ \end{bmatrix}, \Sigma \right) \\ \\
\theta_{[1]}, \theta_{[2]} \sim t(3, 0, 3) \\
VTL, F0 \sim t(3, 0, 3) \\
\sigma_{L}, \sigma_{VTL \colon L}, \sigma_{f0 \colon L} \sim t(3, 0, 3) \\ R \sim \mathrm{LKJCorr} (2)
\end{split}
(\#eq:12-14)
\end{equation}
$$

Notice that the model prediction equation (reference equation) does not contain an intercept term in its prediction of the expected value of the latent variable. This is because the important thing for our model is the distance between the intercept and the thresholds, and not the value of the latent variable itself. For example, imagine an 'intercept-only' model (chapter 4) that had intercept = 0 and thresholds of 2 and 5. The behavior of this model would be exactly analogous to a model with an intercept of 10 and thresholds of 12 and 15.  There are an infinite number of models that maintain these distances, one for each possible value of the intercept, making finding the 'best' one an impossible task. To resolve this issue, the overall intercept in these models is usually set to zero and not modeled, and instead only the J-1 thresholds are modeled. 

Although ordinal models do not usually model the overall intercept, they *can* model listener-dependent (and speaker) intercepts, and our model in equation does. Using cluster-dependent intercepts can be thought of as sliding the thresholds up and down the number line by different amounts for each level of a grouping factor, or as moving the predicted values for the cluster by a given amount. This sort of adjustment *can* have a meaningful effect on predictions, unlike changes in the overall model intercept outlined above. 

Here's a verbal description of our model:

> We are modelling an ordinal variable, size group ($SG$), with possible outcomes of small (1), medium (2), and large (3). The value expected for any given trial is based on the value of a latent variable ($z$) in relation to two thresholds ($\theta_{[1]},\theta_{[2]}$), which were estimated from the data. Our latent variable is modeled as coming from a logistic distribution with a scale of 1 and a mean that varies from trial to trial. The mean of these distributions varies based on the combination of 'main' (e.g., $VTL$) and listener-dependent (e.g. $VTL \colon L$) effects for vocal tract length and f0, and a listener-dependent intercept. 

> The speaker intercept ($S$) terms were drawn from a normal distribution with a mean of zero and a standard deviation estimated from the data. The listener random effects were drawn from a multivariate normal distribution with means of 0 of zero and a covariance matrix estimated from the data. All other effects (e.g., the Intercept, VTL, etc.) were treated as 'fixed' and drawn from prior distributions appropriate for their expected range of values. 


### Fitting and interpreting the model

To fit an ordinal logistic model, you set `family=cumulative` when fitting your model. The logistic distribution is the default distribution for these sorts of models, but other distributions such as the normal distribution can be used. 

```{r, eval = FALSE}
# Fit the model yourself
set.seed (1)
options (contrasts = c('contr.sum','contr.sum'))
model_ordinal = brms::brm (SG ~ vtl+f0 + (vtl+f0|L) + (1|S), data=exp_data, family="cumulative", 
           chains=4, cores=4, warmup=1000, iter = 5000, thin = 4,
           prior = c(set_prior("student_t(3, 0, 3)", class = "Intercept"),
                     set_prior("student_t(3, 0, 3)", class = "b"),
                     set_prior("student_t(3, 0, 3)", class = "sd"),
                     brms::set_prior("lkj_corr_cholesky (2)", class = "cor")))
```

```{r, eval = FALSE}
model_ordinal = bmmb::get_model ("12_model_ordinal.RDS")
```
```{r, include = FALSE}
#  saveRDS (model_ordinal, "../models/12_model_ordinal.RDS")
model_ordinal = readRDS ("../models/12_model_ordinal.RDS")
```

We can inspect the short summary to see the information it contains:

```{r}
bmmb::short_summary(model_ordinal)
```

Note that we get listener-dependent intercepts, VTL, and f0 effects. Note that these intercepts correspond to the $L$ terms in the model equation above, and do not refer to thresholds/cutoffs. In the population-level effects, we see the two estimated thresholds `Intercept[1]` and `Intercept[1]` representing $\theta_{[1]}$ and $\theta_{[1]}$ above. We also see our 'main' effects for VTL and f0 in this section. Our results indicate that VTL is positively related to a larger size group response, while f0 is negatively related to this (no surprises there). 

Below we make 'fixed effect' predictions using our model. These predictions omit the random effects structure to let us see how well our fixed effects can predict our data. We inspect the predictions for our first six observations, and we can see that these consist of three columns representing the probability that the observation belongs to each category. 

```{r}
# make predictions
predictions = fitted (model_ordinal, re_formula = NA)

# see first six
head (predictions[,1,])
```

Below we find the maximum value across each row, representing the categorical prediction made by our model for each observation.  

```{r}
SG_hat = apply (predictions[,1,],1,which.max)
```

We can see that our model does a pretty good job of predicting our data:
      
```{r}
mean (exp_data$SG == SG_hat)
```
      
Below we make predictions using our posterior mean fixed effects. We do this just to show that it does, in fact, align with the model we outlined above. First, we get the posterior mean model fixed effects and use this to come up with an expected value for our latent variable for each observation. Then, we assign each observation to a response category based on where the expected value lies relative to the thresholds.

```{r}
# get fixed effects
fixed_effects = brms::fixef(model_ordinal)

threshold_1 = fixed_effects[1,1]
threshold_2 = fixed_effects[2,1]
vtl_slope = fixed_effects[3,1]
f0_slope = fixed_effects[4,1]

# get expected values
mu = exp_data$vtl * vtl_slope + exp_data$f0  * f0_slope

# assign to category based on location relative to threshold.
SG_hat_manual = 0
SG_hat_manual[mu < threshold_1] = 1
SG_hat_manual[(threshold_1 < mu) & (mu < threshold_2)] = 2
SG_hat_manual[threshold_2 < mu] = 3
```

We can see that this approach results in basically the same predictions as using our linear predictions (with the differences attributable to using the posterior means).  

```{r, eval = FALSE}
mean (SG_hat == SG_hat_manual)
```

We can also use the expected values and thresholds to calculate the predicted probabilities that the observation will belong to each category. Again, because of the different approaches used, we expect small differences to the predictions made using the `fitted` function above. 

```{r}
predictions_manual = 
  cbind (round (plogis (threshold_1, mu),5),
         round ((plogis (threshold_2, mu)-plogis (threshold_1, mu)),5),
         round (1-plogis (threshold_2, mu), 5))

head (predictions_manual)
```

- explain disc
- inverse of scale, not modeled here but we could have


### Answering our research questions

We can try to answer our research question:

Q1) Can we predict which size group people will tend to respond for a speaker's voice given their f0 and VTL?

Yes we can, and with reasonable accuracy based only on the fixed effects. Here's something else worth noting: There is very little between-listener variation in our parameters. 

```{r F12-13, fig.height = 3, fig.width=8, fig.cap = " -- ", echo = FALSE}

par (mfrow = c(1,2), mar = c(2,3,.1,.1), oma = c(.7,1,1,1))
layout (mat = t(c(1,2)), widths = c(.6,.4))
brmplot (fixef(model_ordinal), ylim = c(-3,4))
brmplot (get_sds(model_ordinal), ylim = c(0,7))
```








