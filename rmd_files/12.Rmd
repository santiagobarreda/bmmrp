\newpage
```{r}
knitr::opts_chunk$set(
  dpi = 300, dev = "jpeg", collapse=TRUE
)
```

# Multinomial and Ordinal regression

In chapter 10 we introduced models that can predict dichotomous categorical variables using logistic regression. Here, we extend many of the concepts introduced in that chapter to the modelling of dependent variables with any number of categories. First, we discuss multinomial regression models that can be used for categorical variables without an inherent ordering. For example, we could use a model like this to predict the perception of vowel sounds from speech acoustics, to predict the lexical category of a word (verb, noun, adjective, ...), or to predict a speaker's native language. Actually, these models can *also* be used for ordered data, they just do not inherently represent the ordering in the model. After this, we introduce ordinal models appropriate for the prediction of categorical variables with some inherent ordering (e.g., first, second and third).  

## Chapter pre-cap

--

### Bold words

Throughout each chapter you will see words in bold. These are important concepts that appear in bold where they are introduced and described in the text. The bold words in this chapter, in alphabetical order, are: 

--

## Multinomial logistic regression

**Multinomial logistic regression** allows you to model data generated by a **multinomial distribution** with some unknown parameters. The multinomial distribution is the generalization of the binomial distribution (see section X) to any number of positive integer outcome categories. For example, the multinomial distribution will allow use to model the categorization of speakers into boys, girls, men, and women simultaneously rather than modeling this as two binary categorizations (male vs. female and adult vs. child). The multinomial distribution has three parameters:
  
  1) $n$: The number of trials, a positive integer.
  2) $J$: The number of possible outcomes, a positive integer.
  3) $p_1, \dots, p_J$: A vector of probabilities of observing each of the $j$ outcomes where $\sum p_j = 1$.
  
Multinomial data arises in situations such as the following. You have a variable that can take on some number of possible values. For example, you ask people to tell you if the speaker seems to be a boy, a girl, a man, or a woman. This results in a variable, apparent speaker category, that can take on one of four discrete values. You observe a certain number of trials ($n$) under some set of conditions. You then count how many times listeners identified the speaker as belonging to one of the four categories. If you divide these counts by the total number of trials ($n$) you will get the probability of observing each outcome ($p_J$). We can think of our data as being generated by a multinomial distribution with some specific parameters as seen below. Our data is a vector of counts, $y_1, \dots, y_J$, representing the expected number of observations of each category for $n$ total outcomes. 


$$
\begin{equation}
y_1, \dots, y_J \sim \mathrm{multinomial}(p_1, \dots, p_J, n)
(\#eq:12-1)
\end{equation}
$$


Below we draw 10 instances of a four-category multinomial variable with probabilities of 0.4, 0.1, 0.2, and 0.3 for the first, second, third and fourth categories respectively. Each of the variables below has $n=1$ so a single category is equal to 1 and the others must all be zero. 
  
```{r}
rmultinom (10, 1, c(.4,.1,.2,.3))
```

We sample ten more multinomial variables, this time each with $n=100$. We can see that we get a distribution of values across the four outcomes for each variable that resembles the values of $p$ we defined for each outcome. Note that the categories are numbered and could represent anything. This sort of variable only represents the relative frequency of outcomes with respect to each other and does not specify relationships between outcomes.

```{r}
set.seed (1)
multinomial_variable = rmultinom (10, 100, c(.4,.1,.2,.3))
multinomial_variable

rowMeans(multinomial_variable)/100
```

There are many ways to think about multinomial logistic regression. We're going to present one that is consistent with the way we presented logistic regression in chapter 10 and the way we have been presenting regression models in general in this book. For a more complete treatment of the topic please see cite. Before beginning the explanation we can 'spoil' the conclusion:  The number of trials ($n$) and the number of possible outcomes ($J$) are aspects of your data and experimental design, and are known to you before you fit any model. Thus, multinomial logistic regression effectively consists of estimating $p_j$, or values analogous to it, for each category as a function of your dependent variables. 

Multinomial regression is a surprisingly 'simple' extension of the concepts underlying logistic regression (presented in chapter 10). When we discussed logistic regression in chapter 10, we introduced the antilogit function (also known as the *logistic* link function). In section X, we discussed the fact that this function converts log odds to probabilities by arbitrarily setting the 'number' of failures to 1 and modeling the number of outcomes (i.e. $e^z$). So, we see in equation below that the probability that $y=1$ (i.e. a 'success') is equal to the ratio of the 'number' of successes over the sum of the total number of outcomes.  

$$
\begin{equation}
\begin{split}
P(Y=1) = \frac{\mathrm{success}}{\mathrm{failure}+\mathrm{success}} = \frac{e^{z}}{1+e^{z}}
\end{split}
(\#eq:12-2)
\end{equation}
$$

The equation above works for when we have exactly two categories. However, it can be modified so that it can be applied to multiple categories. First, we assume that rather than exactly two possible outcomes, there are $J$, some integer larger than one. If we stick to our interpretation of the value of $e^{z}$ as an expected count for that category, then $e^{z_j}$ is the expected count for category $j$. To find the probability of observing category $j$ we find the ratio of the 'count' of $j$ over the sum of all possible outcomes (i.e., the sum of counts for all categories).

$$
\begin{equation}
\begin{split}
P(Y=j) = \frac{e^{z_j}}{\sum_{j=1}^{J} e^{z_j}}
\end{split}
(\#eq:12-3)
\end{equation}
$$

The function above is called the **softmax** function, and it is basically a generalization of the antilogit (logistic) function to more than two categories. When we did dichotomous logistic regression, we modeled only the 'count' of one variable, the one set to 'success'. The 'counts' for the category set to 'failure' was not modeled and was set to 1 (by setting $z=0$) for all cases. When we model multinomial data we have to follow the same convention and set one category as the 'reference'. This means the the equation above can be modified to pull one category out of the summation and set its count to 1 for all situations, as in the equation below. Notice that the count on the summation in the denominator of the fraction now begins at two.

$$
\begin{equation}
\begin{split}
P(Y=j) = \frac{e^{z_j}}{1 + \sum_{j=2}^{J} e^{z_j}}
\end{split}
(\#eq:12-4)
\end{equation}
$$

The equation above results in a set of probabilities which can serve as the multinomial parameters, $p_1, \dots , p_j$, for categories $1, \dots, J$. These probabilities are modeled by estimating $z_j$ as resulting from the linear combination of our predictor variables based on some unknown parameters ($\beta_j$). Each outcome has a different prediction equation for $z_j$ so that a multinomial regression has $J$ prediction equations, one for each outcome. Importantly, each prediction equation combines the same $x_k$ predictors, albeit in a category-specific way (based on the $\beta_j$ parameters for that category).  

$$
\begin{equation}
z_j = \beta_j + \beta_{j1} \times x_1 + \beta_{j2} \times x_2 + \dots + \beta_{kj} \times x_k
(\#eq:12-5)
\end{equation}
$$

The prediction equation for the 'reference' category (`brm` uses the first category) is fixed to have a value of 0. One way to accomplish this is to fix all coefficients for this outcome to equal 0 as in equation below. 

$$
\begin{equation}
z_1 = 0 \\
0 = \alpha_j + \beta_{j1} \times x_1 + \beta_{j2} \times x_2 + \dots + \beta_{kj} \times x_k \\
z_1 = 0 + 0 \times x_1 + 0 \times x_2 + \dots + 0 \times x_k \\
(\#eq:12-6)
\end{equation}
$$

When we carried out logistic regression, the variable $z$ was refereed to as a logit. Sometimes the $z_j$ values involved in multinomial regression are called **multinomial logits** to highlight their similarity to the dichotomous logit. Sometimes these values are referred to as the **score** for each category. The score is somewhat vaguely defined, in part because there are many ways to think about what the score is and means. One way to think of the score is that it is a *latent variable* associated with each category, that relates to the probability of observing that category given the values of the dependent variables.

**Latent variables** are variables that are inferred mathematically using some statistical model, but are not measured directly. For example, in our logistic regression model in chapter 10 we predicted the perception of femaleness. We did this by predicting variation in the logit of the probability of observing a female response as a function of speaker vocal-tract length. The logit of this probability can be thought of as a latent variable representing something like 'femininity' in the mind of the listener. Based on the 'feeling' of voice femininity that the listener has they produce the surface variable that we do measure: The classification of a speaker as female/male. In this view the realization of the response variable (a female classification) is the result of a secret, *latent* variable that is not directly observed by us, but which we assume underlies the process. 

We have four latent variables in our multinomial model predicting apparent category: The score for each category. We can think of these as the 'feeling' the listener has regarding the 'boyness', 'girlness', 'manness', and 'womanness' of the voice. What is the 'boyness' of a voice? The unquantifiable internal knowledge you have that a voice is that of a boy, as opposed to some other sort of speaker. These latent variables are not directly measured in our experiment but we think they underlie the categorization of speakers into categories. When a listener hears a voice and their 'boyness' score is greater than the other scores, the listener is most likely to indicate that the voice is a boy. When the score between one category and the others is very unequal, this decision is easy and classification into one category will dominate. When the scores for two or more categories are about equal, i.e. the 'boyness' and 'womanness' of a voice are similar, the listener will feel ambiguous about the decision and classification into either category may be equally likely.

At this point we've laid out the basics of multinomial regression and can present a summary of the information we just presented. In multinomial logistic regression we model the probability of observing each of the $J$ categorical outcomes. We fix the value of the score (or multinomial logit) of the reference category to 1, and estimate the scores of the other categories using a prediction equation specific for the category. The logit predicted for each category in a specific situation can then be converted to a probability using the softmax function presented in equation above. 

### Data and research questions

We load our packages and data below. We also add a new variable, $y$, representing our multinomial outcome. This variable represents observations of a vector of length four whose first, second, third, and fourth elements represent observed outcomes of 'boy', 'girl', 'man', and 'woman', respectively. After this we add a variable called `size` that always equals 1 because each row in our data frame represents observation of a single outcome. Finally, we process our quantitative predictors in the same way as in the previous chapters.

```{r, warning=FALSE, message=FALSE}
library (brms)
library (bmmb)
data (exp_data)

# new dependent variable
exp_data$y = cbind(b = as.numeric(exp_data$C=='b'),
                   g = as.numeric(exp_data$C=='g'),
                   m = as.numeric(exp_data$C=='m'),
                   w = as.numeric(exp_data$C=='w'))

# variable representing the size (n) of each observation. They are all 1.
exp_data$size = 1

# preparation of quantitative predictors as in previous chapters
exp_data$vtl_original = exp_data$vtl
exp_data$vtl = exp_data$vtl - mean (exp_data$vtl)

exp_data$f0_original = exp_data$f0 
exp_data$f0 = exp_data$f0 - mean(exp_data$f0)
exp_data$f0 = exp_data$f0 / 100
```

Below, we print out the first six instances of our dependent variable and compare this to the first six values of the `C` (apparent category) variable in our data frame. We can see that the dependent variable indicates which category was selected for a given trial using a 1 in the appropriate column and a 0 in the others. 

```{r}
# first 6 elements of dependent variable
head (exp_data$y)

# first six elements of apparent speaker category factor
head (exp_data$C)
```

We will try to use our data to answer the following research question: 

Q1) Can we use speaker f0 and VTL to predict their apparent speaker category?

Keep in mind we're trying to predict *apparent* and not *veridical* speaker category. Our consideration of the accuracy or utility of this model will depend on how well it represents listener classifications of speakers, now matter how wrong or right these may be. Thus, a model with perfect classification of speakers into veridical categories is not the goal: If listeners make predictable mistakes we want to model to make the same 'mistakes'.

### Description of our model

Our model formula is largely similar to those we have seen before, with one minor change. Beside your dependent variable, you need to include a variable that indicates the integer number of trials for each set of observations. For us this will always be 1, but in many situations this can be a wider range of values. We want to predict our counts of categorizations with respect to value of speaker VTL and f0, and so the model formula we are going to use is seen below. 

`y|trials(size) ~ vtl+f0 + (vtl+f0|S) + (1|L)`

Since we're predicting category membership with two quantitative predictors, we know that the surfaces our model defines are planes. In the models with fit to this point, we had a single dependent variable and a single plane for a single condition. So, our model formulas previously were something like:

`y ~ vtl+f0 + (vtl+f0|S) + (1|L)`

However, in a multinomial regression we have one plane for each response category, so our formula above could really be thought of as:

`y_1 ~ vtl+f0 + (vtl+f0|S) + (1|L)`
`y_2 ~ vtl+f0 + (vtl+f0|S) + (1|L)`
`y_3 ~ vtl+f0 + (vtl+f0|S) + (1|L)`
`y_4 ~ vtl+f0 + (vtl+f0|S) + (1|L)`

This means that our multinomial model will involve four times as many coefficients as an equivalent Gaussian model, and $J$ times as many for $J$ outcome categories. Of course, we noted above that the coefficients of the reference category are set to zero and not estimated. This means that the formula above results in the estimation of three planes, resulting in three sets of analogous parameters. Our full model specification is given below:

$$
\begin{equation}
\begin{split}
y_{1[i]},y_{2[i]},y_{3[i]},y_{4[i]} \sim \mathrm{multinomial}(p_{1[i]},p_{2[i]},p_{3[i]},p_{4[i]}, n_{[i]}) \\ \\
\mathrm{for} \; j = 1, \dots, 4\\ \\ 
p_{j[i]} = \frac{e^{z_j}}{\sum_{j=1}^{J} e^{z_j}} \\ 
\\
z_{j[i]} = \mathrm{a}_j + b_{j[i]} \times \mathrm{vtl}_{[i]} + c_{j[i]} \times \mathrm{f0}_{[i]}  \\ 
a_{j[i]} = \mathrm{Intercept}_j + L_{j[L_{[i]}]} + S_{j[S_{[i]}]} \\ 
b_{j[i]} =  VTL_j + VTL_j \colon L_{j[L_{[i]}]} \\
c_{j[i]} =  f0_j + f0_j \colon L_{j[L_{[i]}]} \\ 
\\
\mathrm{for} \; j = 2, \dots, 4\\ \\ 

\textrm{Priors:} \\
S_{j[\bullet]} \sim \mathrm{Normal}(0,\sigma_{S_j}) 
\\ 
\begin{bmatrix} L_{j[\bullet]} \\ VTL_j \colon L_{j[\bullet]} \\ f0_j \colon L_{j[\bullet]} \end{bmatrix}	
\sim \mathrm{MVNormal} \left(\, \begin{bmatrix} 0\\ 0 \\ 0 \\ \end{bmatrix}, \Sigma_j \right) \\ \\
Intercept_j \sim t(3, 0, 3) \\
VTL_j, f0_j \sim t(3, 0, 3) \\
\sigma_{L_j}, \sigma_{VTL_j \colon L_j}, \sigma_{f0_j \colon L_j} \sim t(3, 0, 3) \\ R_j \sim \mathrm{LKJCorr} (2)

\end{split}
(\#eq:12-7)
\end{equation}
$$

We're going to take some time to unpack this definition, top to bottom, because it is at the same time very familiar and very different. First, note that our data-generating distribution is assumed to be the multinomial distribution. This function has a $p_j$ parameter indicating the probability of observing each of the $J$ categories, and an $n$ parameter specifying the total number of trials for that observation. The next line indicates that the next few lines applies individually for all four categories. For each category, the probability of observing that outcome ($p_j$) is found by combining the score for each category ($z_j$) using the softmax link function. For each category, the score is equal to a trial-dependent combination of an intercept, an effect fot VTL, and an effect for f0. The intercept varies according to an overall model intercept and speaker and listener-dependent variations from this. The VTL and f0 effect vary according to listener-dependent effects. 

After that we move on to the model priors. Unlike for the above lines, we do not specify priors for any parameters related to the reference category. This is because all of these parameters are set to 0 for this category so that the score for this category is always 0 and the 'expected count' (as discussed above) is always equal to 1. Again we may note that the specification of priors is very similar to the models we have discussed to this point, save for the proliferation of $j$ subscripts. 

### Fitting and interpreting our models

There is one major difference in how we need to specify priors for multinomial models: We need to specify priors individually for each response category with modeled parameters. This is done by passing the name of the categorical variable to the `dpar` parameter. Above, we named our response variables according to the letters we have been using throughout this text. We can see this below.

```{r}
colnames (exp_data$y)
```

The name passed to `dpar` will be `muCategory` where `Category` corresponds to the category name. This means we need to specify priors for `mug`, `mum`, and `muw`, but not `mub`. We specify our priors below:

```{r}
multinomial_prior = 
  c(brms::set_prior("student_t(3, 0, 3)", class = "Intercept",dpar="mug"),
    brms::set_prior("student_t(3, 0, 3)", class = "b",dpar="mug"),
    brms::set_prior("student_t(3, 0, 3)", class = "sd",dpar="mug"),
    brms::set_prior("student_t(3, 0, 3)", class = "Intercept",dpar="mum"),
    brms::set_prior("student_t(3, 0, 3)", class = "b",dpar="mum"),
    brms::set_prior("student_t(3, 0, 3)", class = "sd",dpar="mum"),
    brms::set_prior("student_t(3, 0, 3)", class = "Intercept",dpar="muw"),
    brms::set_prior("student_t(3, 0, 3)", class = "b",dpar="muw"),
    brms::set_prior("student_t(3, 0, 3)", class = "sd",dpar="muw"),
    brms::set_prior("lkj_corr_cholesky (2)", class = "cor"))
```

And here is the code to fit our model, using the `multinomial` family for the first time: 

```{r, eval = FALSE}
model_multinomial = 
  brms::brm (y|trials(size) ~ vtl+f0 + (vtl+f0|L) + (1|S), data=exp_data, 
             family="multinomial", chains=4, cores=4, warmup=1000, iter = 5000, 
             thin = 4, prior = multinomial_prior)
```
```{r, eval = FALSE}
model_multinomial = bmmb::get_model ("12_model_multinomial.RDS")
```
```{r, include = FALSE}
#  saveRDS (model_multinomial, "../../models/12_model_multinomial.RDS")
load("../models/12_multinomial_predictions.Rda")
model_multinomial = readRDS ("../models/12_model_multinomial.RDS")
```

Figure \@ref(fig:F12-1) presents the model fixed effects, the intercept, VTL slope, and the f0 slope for each category with estimated parameters. Each group of parameters defines a plane whose value along the $z$ dimension can be predicted based on the values of f0 and VTL. We have four planes an four values of $z_j$ for any given location in the two dimensional space defined by f0 and VTL. For each point, we can select as the most probable category the one whose value of $z_j$ is highest at the point in the space. Another way to look at this is that we select the highest plane at any given location in the space. 

```{r F12-1, fig.height = 3, fig.width=8, fig.cap = " -- ", echo = FALSE}

################################################################################
### Figure 12.1
###############################################################################

par(mar=c(4,7,.51,.51))
brmplot (fixef (model_multinomial)[c(1,4,5,2,6,7,3,8,9),], 
         horizontal=FALSE, col = rep(bmmb::cols[3:5],each=3))
mtext (side=1,line=3,"Coefficient")
```

Since the dependent variable is the score for each category, the parameters above are difficult to interpret in isolation. Also, keep in mind that scores need to be interpreted relative to the baseline category value of 0 (for boys), or two each other, rather than absolutely. For example, the negative coefficient for VTL for 'girl' (`mug_vtl`) indicates the a longer VTL made a girl response less likely. We can also see that increasing f0 made a 'woman' response less likely, and a 'male' response more likely.

We might wonder how well our model can predict listener judgements. We can do this by first predicting our data using our model:

```{r, eval = FALSE}
multi_pred_re = predict (model_multinomial)
```

The result of this is a three dimensional matrix. The first two dimensions represent the by now familiar summary matrices generated by `brms`. The first column is the posterior probability of category membership for each observation, the second is the standard error for each prediction, and the third and fourth represent the 2.5% and 97.5% credible intervals.

```{r}
head(multi_pred_re[,,1])
```

The third dimension indexes the response category. Above we saw the predictions for the first category (boy) and below we see them for the second category (girl):

```{r}
head(multi_pred_re[,,2])
```

We can also just select the second dimension from each matrix, resulting in a two-dimensional matrix. This matrix contains the posterior probability of being classified into each category across columns, for each observation across rows. 

```{r}
head(multi_pred_re[,1,])
```

Since these are probabilities, the sum of each row equals one, because only these four outcomes exist. For example, the first row above tells us that, according to our model, the first observation has a 0.29 probability of being identified as a boy, 0.64 probability of being identified as a boy, 0.001 probability of being identified as a man, and a 0.07 probability of being identified as a woman. 

```{r}
head(rowSums (multi_pred_re[,1,]))
```
We can use the code below to find the 'winning' category for each observation, that is, the category with the highest posterior probability in each row. We use the resulting column numbers to get category labels. 

```{r}
# find highest posterior prbability from each category
predicted = apply (multi_pred_re[,1,],1,which.max)
head (predicted)

# use modal category to get a category label
predicted_category = c("b","g","m","w")[predicted]
head (predicted_category)

```

Below, we cross-tabulate predicted and observed classifications. Each row shows speaker classifications into different categories, and model predictions vary across columns. This is a *confusion matrix*, introduced in chapter 5. Correct classifications fall on the main diagonal and all other values indicate mistakes. For example, we see that there were 258 correct classifications of boys as boys, and 88 incorrect classifications of boys as girls. A majority of observations fall along the main diagonal indicating that the model was relatively good at predicting listener behavior.

```{r}
xtabs (~ exp_data$C + predicted_category)
```

Below we find the probability of observing a correct classification overall, and individually for each category. We see that the model we able to predict listener judgments with a high degree of accuracy overall, but that some categories (man) were much easier to predict than others (boy).

```{r}
# overall correct
mean (predicted_category == exp_data$C)

# correct predictions by category
tab = xtabs (~ exp_data$C + predicted_category)
diag(tab) / rowSums(tab)
```

### Multinomial models and territorial maps

We discussed territorial maps for two categories along two dimensions in chapter 11 where we predicted the perception of femaleness based on speaker f0 and VTL. As we discussed then, when categories are defined by planes, the boundary between categories on the space is defined by the line representing the intersection of these planes. When we did (dichotomous) logistic regression in chapter 11, we found the intersection of one plane with a horizontal plane at $z=0$. In this chapter we still have a plane such that $z=0$ for all x and y (the reference category plane), but we also have three other planes with possible non-zero slopes. The boundary between each pair of categories forms a boundary made by a line. Since we have 6 unique pairings of our four response categories, we will have six boundary lines. 

We know that the boundary between two categories is where their respective planes intersect, i.e., the place where these planes have the same $z$ axis value. To find this, first we define the values of two planes, $z_1$ and $z_2$ based on their respective coefficients as in \@ref(eq:12-8).

$$
\begin{equation}
\begin{split}
z_1 = \mathrm{a} + \mathrm{b} \times x +  \mathrm{c} \times y \\
z_2 = \mathrm{d} + \mathrm{e} \times x +  \mathrm{f} \times y
\end{split}
(\#eq:12-8)
\end{equation}
$$

We set $z_1$ equal to $z_2$, which is equivalent to setting to right hand side of each equation to equal as in \@ref(eq:12-9).

$$
\begin{equation}
\begin{split}
z_1 = z_2 \\ 
\mathrm{a} + \mathrm{b} \times x +  \mathrm{c} \times y = \mathrm{d} + \mathrm{e} \times x +  \mathrm{f} \times y
\end{split}
(\#eq:12-9)
\end{equation}
$$

In order to get all these terms into the format for the equation of a line ($y = a + b \times x$), we need to isolate y on the left hand side as seen in \@ref(eq:12-10). 

$$
\begin{equation}
y = \frac {-\mathrm{a} + \mathrm{d}}{\mathrm{c} - \mathrm{f}} + \frac{-\mathrm{b} + \mathrm{e}}{\mathrm{c} - \mathrm{f}} \times x
(\#eq:12-10)
\end{equation}
$$

As mentioned above, we get 6 such line equations, one for the boundary between each of the four planes. Figure \@ref(fig:F12-2) presents each of these six boundaries compared to the modal classification for each speaker. 

```{r F12-2, fig.height = 4, fig.width=8, fig.cap = "boys (b), girls (g), men (m), and women (w).", echo = FALSE}

################################################################################
### Figure 12.2
###############################################################################

params = fixef (model_multinomial)
params = fixef (model_multinomial, summary = FALSE)
params = cbind (colMeans (params[,1:3]), 
                colMeans (params[,c(4,6,8)]),
                colMeans (params[,c(5,7,9)]))

params = rbind (c(0,0,0), params[1:3,])

tab = table (exp_data$S, exp_data$C)
mod_cat = apply (tab, 1,which.max)

par (mfrow = c(2,3), mar = c(0.2,0.2,0.2,0.2), oma = c(4.5,4.5,0.5,0.5))

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2,
     xaxt='n')
abline (find_intersection (params[1,], params[2,]),lwd=2, col = bmmb::cols[7]) # b vs g

text (1.5,1, "boy-girl", cex=1.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2,
     yaxt='n',xaxt='n')
abline (find_intersection (params[1,], params[3,]),lwd=2, col = bmmb::cols[8]) # b vs m

text (1.5,1, "boy-man", cex=1.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2,
     yaxt='n',xaxt='n')
abline (find_intersection (params[1,], params[4,]),lwd=2, col = bmmb::cols[9]) # b vs w

text (1.5,1, "boy-woman", cex=1.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2)
abline (find_intersection (params[2,], params[3,]),lwd=2, col = bmmb::cols[10]) # g vs m

text (1.5,1, "girl-man", cex=1.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2,
     yaxt='n')
abline (find_intersection (params[2,], params[4,]),lwd=2, col = bmmb::cols[13]) # g vs w

text (1.5,1, "girl-woman", cex=1.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2,
     yaxt='n')
abline (find_intersection (params[3,], params[4,]),lwd=2, col = bmmb::cols[14]) # m vs w

text (1.5,1, "man-woman", cex=1.5)

mtext (side=1, "Centered vocal tract length (cm)", outer = TRUE, line=3)
mtext (side=2, "Centered f0 / 100 (Hz)", outer = TRUE, line=3)

```

All six boundary lines are presented in the left plot of figure \@ref(fig:F12-3). One problem with considering the figure in this way is that many of the boundaries are not very relevant. For example, the boundary between girl and man will hardly matter for classification because these categories are divided by 'woman' and 'boy' classifications. The right plot of figure \@ref(fig:F12-3) presents only those boundaries that are *relevant*. This can be stated more formally as: The figure contains only those boundaries that represents scores equal to or greater than the maximal score, for that location, from among the response categories. For example, in the left plot we see that the boy-woman boundary bisects the are where man is a modal response. This line segment does not feature in the right plot because it has a lower value than the man plane in this area. In other words, who cares if its a boy or a woman because people are more likely to say man anyways. 

```{r F12-3, fig.height = 3, fig.width=8, fig.cap = "boys (b), girls (g), men (m), and women (w).", echo = FALSE}


################################################################################
### Figure 12.3
################################################################################


params = fixef (model_multinomial)
params = fixef (model_multinomial, summary = FALSE)
params = cbind (colMeans (params[,1:3]), 
                colMeans (params[,c(4,6,8)]),
                colMeans (params[,c(5,7,9)]))

params = rbind (c(0,0,0), params[1:3,])

tab = table (exp_data$S, exp_data$C)
mod_cat = apply (tab, 1,which.max)

par (mfrow = c(1,2), mar = c(.0,.0,.21,.2),oma=c(4,4,.1,.1))

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat])
abline (find_intersection (params[1,], params[2,]),lwd=3, col = bmmb::cols[7])
abline (find_intersection (params[1,], params[3,]),lwd=3, col = bmmb::cols[8])
abline (find_intersection (params[1,], params[4,]),lwd=3, col = bmmb::cols[9])
abline (find_intersection (params[2,], params[3,]),lwd=3, col = bmmb::cols[10])
abline (find_intersection (params[2,], params[4,]),lwd=3, col = bmmb::cols[13])
abline (find_intersection (params[3,], params[4,]),lwd=3, col = bmmb::cols[14])

points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)
#points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 1, col = 1,
#     lwd=2, cex=2)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],ylab="",yaxt="n")

#maps = make_map (t(params))

plot_map (maps, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)

points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)
#points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 1, col = 1,
#     lwd=2, cex=2)

mtext (side=1, "Centered vocal tract length (cm)", outer = TRUE, line=2.5)
mtext (side=2, "Centered f0 / 100 (Hz)", outer = TRUE, line=2.5)

```

We noticed something very strange when we made the territorial map in figure \@ref(fig:F12-3): The boy territory contains a large number of woman responses. In addition, the boy-woman boundary seems strangely high. If that is really the boundary between boys and women in the VYL by f0 space, then why is the model classifying all those women correctly? The answer to this question may lie in figure \@ref(fig:F12-4). 

In the left plot of figure \@ref(fig:F12-3), point colors represent modal listener judgments for each speaker. In the middle plot we see model predictions including speaker and listener random effects. When these are included the model predictions look very much like the listener judgments and the classifications don't make much sense relative to the territorial map. In the right plot of the same figure we see model predictions when random effects are *not* included. In this case we see that model predictions do *not* look like the listener judgments, but the classifications *do* make sense relative to the territorial map. So, it seems that the random effects may be causing this strange behavior in our model.

```{r F12-4, fig.height = 3, fig.width=8, fig.cap = "boys (b), girls (g), men (m), and women (w).", echo = FALSE}

################################################################################
### Figure 12.4
################################################################################


params = fixef (model_multinomial)
params = fixef (model_multinomial, summary = FALSE)
params = cbind (colMeans (params[,1:3]), 
                colMeans (params[,c(4,6,8)]),
                colMeans (params[,c(5,7,9)]))

params = rbind (c(0,0,0), params[1:3,])

tab = table (exp_data$S, exp_data$C)
mod_cat = apply (tab, 1,which.max)

cats = apply(multi_pred[,1,],1,which.max)
table (exp_data$C, cats)
tab2 = table (exp_data$S, cats)
mod_cat2 = apply (tab2, 1,which.max)

cats = apply(multi_pred_re[,1,],1,which.max)
table (exp_data$C, cats)
tab2 = table (exp_data$S, cats)
mod_cat3 = apply (tab2, 1,which.max)


par (mfrow = c(1,3), mar = c(.0,.0,.21,.2),oma=c(4,4,2,.1))

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],ylab="")
#maps = make_map (t(params))
mtext (side=3, text = "Listener Judgments", line = 0.5)

plot_map (maps, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat2],ylab="",yaxt="n")
plot_map (maps, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat3], cex = 2)
mtext (side=3, text = "Model Predictions (with RE)", line = 0.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat3],ylab="",yaxt="n")
plot_map (maps, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat2], cex = 2)
mtext (side=3, text = "Model Predictions (no RE)", line = 0.5)



mtext (side=1, "Centered vocal tract length (cm)", outer = TRUE, line=2.5)
mtext (side=2, "Centered f0 / 100 (Hz)", outer = TRUE, line=2.5)

```

Figure \@ref(fig:F12-5) presents the speaker random intercepts. Since there are three modeled categories, there are three random intercepts for each speaker. We can see that, in general, the speaker intercepts have small values that vary around zero, and have credible intervals that mostly include zero. However, many female speakers have intercepts that have large non-zero values for the female category, and whose credible intervals omit zero and very small values.

```{r F12-5, fig.height = 4, fig.width=8, fig.cap = "boys (b), girls (g), men (m), and women (w).", echo = FALSE}

################################################################################
### Figure 12.5
################################################################################

sranef = ranef(model_multinomial)$S

tab = table (exp_data$S, exp_data$C_v)
real_cat = apply (tab, 1,which.max)

par (mfrow = c(4,1), mar =c(.1,4,.1,.5), oma = c(.5,0,.5,0))
brmplot((sranef[,,1]+sranef[,,2]+sranef[,,3])/3, labels = '', 
        col = bmmb::cols[real_cat+1], ylim = c(-8,8))
text (1,7,"Boy category speaker intercepts", pos=4,cex=1.4)

brmplot(sranef[,,1], labels = '', col = bmmb::cols[real_cat+1], ylim = c(-8,8))
text (1,7,"Girl category speaker intercepts", pos=4,cex=1.4)

brmplot(sranef[,,2], labels = '', col = bmmb::cols[real_cat+1], ylim = c(-8,8))
text (1,7,"Man category speaker intercepts", pos=4,cex=1.4)

brmplot(sranef[,,3], labels = '', col = bmmb::cols[real_cat+1], ylim = c(-8,8))
text (1,7,"Woman category speaker intercepts", pos=4,cex=1.4)

```

Here is what we believe is happening. Think of the female response plane with a specific intercept, VTL slope and f0 slope. If female speaker categorizations were very predictable based on the value of this plane at a given location, all the female speaker effects would be zero or near zero. This is because if the score based on the plane explains classification, there is nothing left for the speaker intercept to explain. We can see this sort of behavior for adult male speakers: Adult male speakers are mostly easy to identify because of their unusually low voice f0.

In contrast, consider a situation where individual female speakers fall way off the plane, in a seemingly random but consistent manner. For example, imagine a female speaker whose score is way higher than the plane says it should be, but that every listener seems to behave this way for this speaker. This would mean that this is a consistent classification for this voice, that cannot be explained by the score according to the plane. In other words, the classification cannot be predicted based on the linear combination of voice VTL and f0. In such a situation, this consistent classification would be explained by the speaker intercept. Effectively, this tells your model "use the general female plane, but move it up/down this much specifically for this person". Why are we moving it up/down for this person? Our model can't tell us, however, it can tell us that the up/down adjustment is consistent for the speaker across listeners and improves model performance.

We can think about what these speaker effects might reflect. The information regarding gender and age in voices is subtle and complicated, and likely reflects subtle stylistic and prosodic cues. Basically, sounding 'feminine' and 'masculine' is much more complicated than just f0 or VTL. This is analogous to the fact that women tend to be shorter than men, but it would be ridiculous to suggest that masculinity/femininity are entirely predictable based on the height of a person. Size is perhaps an aspect of perceived femininity/masculinity but the whole of it is substantially more complicated. 

We again consider our model prediction accuracy, but this time consider predictions without any random effects.

```{r}
predicted_no_re = apply (multi_pred[,1,],1,which.max)
predicted_category_no_re = c("b","g","m","w")[predicted]
```

The picture without random effects is much more grim. Correct prediction is not *too* bad (relative to chance at 25%), however, some of the individual categories are predicted very poorly. As expected, accurate prediction of woman responses is particularly bad with only 22% of female responses being accurately predicted as such. 

```{r}
# overall correct
mean (predicted_category_no_re == exp_data$C)

# correct predictions by category
tab = xtabs (~ exp_data$C + predicted_category_no_re)
diag(tab) / rowSums(tab)
```

### Refitting the model without speaker random effects

The results of our previous model suggest that the inclusion of speaker random effects may lead to some unintended consequences. Model prediction is good as long as we include the speaker random effects. However, these do not let us understand the prediction of new speakers. Further, the territorial map we can generate using the figure is a bit unreliable because of its reliance on the speaker random effects included in the model. We will try fitting the model without speaker effects to see if we get a territorial map that is a better match for the listener judgments. We use the same priors we used before, and fit the same model save for the absence of speaker effects from our fromula: 

```{r, eval = FALSE}
model_multinomial_noS = 
  brms::brm (y|trials(size) ~ vtl+f0 + (vtl+f0|L), data=exp_data, 
             family=multinomial(), chains=4, cores=4, warmup=1000, iter = 5000, 
             thin = 4, prior = multinomial_prior)
```
```{r, eval = FALSE}
model_multinomial_noS = bmmb::get_model ("../models/12_model_multinomial_noS.RDS")
```
```{r}
#  saveRDS (model_multinomial_noS, "../../models/12_model_multinomial_noS.RDS")
model_multinomial_noS = readRDS ("../models/12_model_multinomial_noS.RDS")
```

```{r, cache = TRUE}
multi_pred_noS = predict (model_multinomial_noS, re_formula = NA)
multi_pred_re_noS = predict (model_multinomial_noS)
```

We just straight to plotting the territorial map represented by this model, again comparing listener judgments to model predictions with and without random effects (\@ref(fig:F12-6)). We can wee that the territorial maps in the figure seem to be a better match to the data.

```{r F12-6, fig.height = 3, fig.width=8, fig.cap = "boys (b), girls (g), men (m), and women (w).", echo = FALSE}

################################################################################
### Figure 12.6
################################################################################


params = fixef (model_multinomial_noS)
params = fixef (model_multinomial_noS, summary = FALSE)
params = cbind (colMeans (params[,1:3]), 
                colMeans (params[,c(4,6,8)]),
                colMeans (params[,c(5,7,9)]))

params = rbind (c(0,0,0), params[1:3,])

tab = table (exp_data$S, exp_data$C)
mod_cat = apply (tab, 1,which.max)

cats = apply(multi_pred_noS[,1,],1,which.max)
table (exp_data$C, cats)
tab2 = table (exp_data$S, cats)
mod_cat2 = apply (tab2, 1,which.max)

cats = apply(multi_pred_re_noS[,1,],1,which.max)
table (exp_data$C, cats)
tab2 = table (exp_data$S, cats)
mod_cat3 = apply (tab2, 1,which.max)


par (mfrow = c(1,3), mar = c(.0,.0,.21,.2),oma=c(4,4,2,.1))

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],ylab="")

maps_noS = make_map (t(params))

mtext (side=3, text = "Listener Judgments", line = 0.5)

plot_map (maps_noS, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat2],ylab="",yaxt="n")
plot_map (maps_noS, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat3], cex = 2)
mtext (side=3, text = "Model Predictions (with RE)", line = 0.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat3],ylab="",yaxt="n")
plot_map (maps_noS, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat2], cex = 2)
mtext (side=3, text = "Model Predictions (no RE)", line = 0.5)

mtext (side=1, "Centered vocal tract length (cm)", outer = TRUE, line=2.5)
mtext (side=2, "Centered f0 / 100 (Hz)", outer = TRUE, line=2.5)

```

Figure \@ref(fig:12-7) compares the territorial maps represented by our models with (left) and without (right) speaker information. In addition to being a better fit to the data, we think the new territorial maps make more 'sense'. This is because the map with speakers suggests that the difference between women and boys was almost entirely due to f0, with women being associated with the higher f0. This is despite boys being associated with shorter VTLs than adult females *and* a higher f0. The new map has basically no effect for f0 between these categories and makes it a primarily VTL difference, which is backed up by the distributions of these characteristics between these speaker types. 

```{r F12-7, fig.height = 3, fig.width=8, fig.cap = "(left) Territorial maps indicating which sections of the stimulus space are associated with: Boys (turquoise), girls (yellow), men (green), and women (red). Points represent individual speakers, colors represent modal classifications using the same colors as the territories.", echo = FALSE}

################################################################################
### Figure 12.7
################################################################################


params = fixef (model_multinomial_noS)
params = fixef (model_multinomial_noS, summary = FALSE)
params = cbind (colMeans (params[,1:3]), 
                colMeans (params[,c(4,6,8)]),
                colMeans (params[,c(5,7,9)]))

params = rbind (c(0,0,0), params[1:3,])

tab = table (exp_data$S, exp_data$C)
mod_cat = apply (tab, 1,which.max)

cats = apply(multi_pred_noS[,1,],1,which.max)
tab2 = table (exp_data$S, cats)
mod_cat2 = apply (tab2, 1,which.max)

cats = apply(multi_pred_re_noS[,1,],1,which.max)
tab2 = table (exp_data$S, cats)
mod_cat3 = apply (tab2, 1,which.max)


par (mfrow = c(1,2), mar = c(.0,.0,.21,.2),oma=c(4,4,2,.1))

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],ylab="")

#maps_noS = make_map (t(params))

mtext (side=3, text = "model_multinomial", line = 0.5)

plot_map (maps, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat2],ylab="",yaxt="n")
plot_map (maps_noS, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)
mtext (side=3, text = "model_multinomial_noS", line = 0.5)

mtext (side=1, "Centered vocal tract length (cm)", outer = TRUE, line=2.5)
mtext (side=2, "Centered f0 / 100 (Hz)", outer = TRUE, line=2.5)

```

One concern with omitting the speaker effects is that our model now thinks all observations for any one speaker are independent. Based on what we saw in figure (intercepts) we know that this is defnitely not the case. Instead, individual speakers were identified as one or another category consistently, indicating that these judgments were related across listeners. Tis can potentially have the effect of artificially decreasing our confidence intervals, as we see in chapter 6 (heck out details, it was for A1). Figure \@ref(fig:12-8) compares the fixed effects between our two models, suggesting that the omission of the speaker effects has not had a large effect on our parameters. The two largest differences are for the woman category: The intercept went from slightly negative to slightly positive, nd the effect for f0 went from zero to positive. 

```{r F12-8, fig.height = 3, fig.width=8, fig.cap = "-- ", echo = FALSE}
################################################################################
### Figure 12.8
###############################################################################

par (mar = c(4,8,1,1))
brmplot (fixef(model_multinomial)[c(1,4,5,2,6,7,3,8,9),], las = 2,
         horizontal = FALSE,col = 0, xlim = c(-5,6))
abline (h = seq(1,10),lty=3,col="grey")
brmplot (fixef(model_multinomial)[c(1,4,5,2,6,7,3,8,9),], add = TRUE,
         nudge = -0.2, labels = "", horizontal = FALSE, pch=16,
         col = rep(bmmb::cols[3:5],each=3))
brmplot (fixef(model_multinomial_noS)[c(1,4,5,2,6,7,3,8,9),], add = TRUE,
         nudge = 0.2, labels = "", horizontal = FALSE, pch=17,
         col = rep(bmmb::cols[3:5],each=3))

legend (2.5,9,legend =c("With Speaker","No Speaker"),bty='n',
        pch=16:17,pt.cex=1.3)
```

We again find the maximum a posteriori speaker classification and get a label for each trial. 
```{r}
predicted_noS = apply (multi_pred_re_noS[,1,],1,which.max)
predicted_category_noS = c("b","g","m","w")[predicted_noS]
```

And calculate correct classifications overall and by category. Performance is not as good as the model with speaker effect when random effects are included (82%) but not as bad as for the same model when random effects are not included (59%). In addition, we see very good classification of all categories except for 'boy'. 

```{r}
# overall correct
mean (predicted_category_noS == exp_data$C)

# correct predictions by category
tab = xtabs (~ exp_data$C + predicted_category_noS)
diag(tab) / rowSums(tab)
```

Importantly, we see that classification barely changes when random effects are not included, except for boy classifications which drop even below chance. 

```{r}
predicted_noS_no_re = apply (multi_pred_noS[,1,],1,which.max)
predicted_category_noS_no_re = c("b","g","m","w")[predicted_noS_no_re]

# overall correct
mean (predicted_category_noS_no_re == exp_data$C)

# correct predictions by category
tab = xtabs (~ exp_data$C + predicted_category_noS_no_re)
diag(tab) / rowSums(tab)
```

### Answering our research questions

We can use our models to answer the question we posed above:

Q1) Can we use speaker f0 and VTL to predict their apparent speaker category?

Yes, we can use speaker f0 and VTL to predict apparent speaker with relative accuracy. If we consider a baseline correctness by chance along of 25%, then our classification of 72% from two predictors (with no random effects) isn't bad at all. However, the importance of the speaker random effects for female speakers strongly suggests that there is 'something else' being used to identify women as women, apart from VTL and f0. So, our first model tells us that we should probably try to understand what that 'something else' is. The speaker random effects are not particularly useful for understanding the categorization of new speakers. However, understanding what causes the variation in these random effects is. Our model tells us that even though we know there is something else to it, we can still pretty much predict categorization from just these two predictors. So, the first model may be better to really try to understand what listeners are doing when they classify while the second model may be better to understand classification from just f0 and VTL. 

## Ordinal (logistic) regression

Ordinal logistic regression involves the prediction of ordered categories. Although in some senses ordinal regression is 'simpler' than multinomial regression, we decided to present it after multinomial regression. This is because multinomial regression is just a generalization of logistic regression, which was discussed in detail in chapter 10. In contrast, ordinal regression, although related to (dichotomous) logistic regression, is in many ways conceptually its own thing. We will present one way of thinking about logistic regression however, as usual, there are many others. 

A simple example of an ordinal variable is first, second, and third place in a race. These values are categorical and not numerical. For example fourth place is not 'double' anything with respect to second place (i.e., $2 \times second \neq fourth$). However, there is clearly an inherent ordering in the categories such that first < second < third < fourth < and so on. A common experimental example of ordered categorical data arises from survey data that asks listeners to respond to questions using a small number of discrete, categorical choices (e.g., a scale from one to five). The reason this is not a truly quantitative variable is because there are a limited number of discrete choices with nothing 'in between', and it is not necessarily the case that, for example, the second choice implied double the quantity of the second. These limitations mat result in subjects, for example, reserving categories 1 and 5 for 'extreme' cases in a way that would not arise for truly quantitative data. 

We don't actually have any ordinal variables in our experiment, but we still wanted to provide an example of an ordinal analysis. To do this, we're going to make a fake ordinal variable that we think is actually relatively plausible. Below we see a boxplot of apparent height judgments organized by apparent speaker category, with boys and girls collapsed into one category. Note that apparent children are judged to be shortest, apparent women are judged to be a little taller than that, and apparent men are judged to be a little taller than women. Based on this, we could think of our speaker classifications as classifications of speakers into small (boys, girls), medium (women), and large (men) speakers. For example, based on the boxplot below we might imagine that if we *had* asked listeners to label speakers small medium and large, they would have labelled most apparent children as small, most apparent women as medium, and most apparent men are large. In any case, we are only presenting this as an example and are only interested in establishing that the conversion of speaker category into an ordinal small < medium < large variable is not completely unfounded.

The right plot in figure \@ref(F12-9) presents the y axis divided into three sections. The boundaries are halfway between the means of our small and medium, and medium and large speakers respectively. We know from earlier chapters that a longer speaker VTL is associated with taller apparent speakers. Imagine that we slide along the line in the plot based on the VTL of the speaker. Based on the apparent height value at a given x axis location, we arrive at a classification of the speaker as small medium or large. 

```{r F12-9, fig.height = 3, fig.width=8, fig.cap = " -- ", echo = FALSE}

################################################################################
### Figure 12.9
################################################################################

library (bmmb)
data (exp_data)

SG = 0
SG[exp_data$C=='m'] = 3
SG[exp_data$C=='w'] = 2
SG[exp_data$C=='g'] = 1
SG[exp_data$C=='b'] = 1


x = seq (100,200,.1)
y = seq (100,200,.1)

par (mfrow = c(1,2), mar = c(.1,.1,.1,.1), oma = c(4,4,.5,.5))

boxplot (height ~ SG, data = exp_data,col=bmmb::cols[c(1,11,10)],ylim = c(100,200),
         xlab = "Size Group")

tmp = aggregate (height ~ SG, data = exp_data, FUN = mean)
abline (h = mean (tmp[1:2,2]), lwd = 6, col = bmmb::cols[15])
abline (h = mean (tmp[2:3,2]), lwd = 6, col = bmmb::cols[15])
boxplot (height ~ SG, data = exp_data,col=bmmb::cols[c(1,11,10)],
         add = TRUE)
mtext (side=1,text="Size Group", line = 2.5)
mtext (side=2,text="Apparent Height (cm)", line = 2.75)

plot (x,y, yaxt='n',type = 'l', xlim = c(120,190),ylim = c(100,200),xaxt='n')
rect (100,90,200,mean(tmp[1:2,2]), col = bmmb::cols[1],border=bmmb::cols[1])
rect (100,mean(tmp[1:2,2]),200,mean(tmp[2:3,2]), col = bmmb::cols[11],border=bmmb::cols[11])
rect (100,mean(tmp[2:3,2]),200,400, col = bmmb::cols[10],border=bmmb::cols[10])
lines (x,y, lwd=4, col = bmmb::cols[2])

points (c(140,160,180),c(140,160,180),pch=16,col=bmmb::cols[2],cex=2)
abline (h = mean (tmp[1:2,2]), lwd = 6, col = bmmb::cols[15])
abline (h = mean (tmp[2:3,2]), lwd = 6, col = bmmb::cols[15])

text (118,c(140,163,195), c("Small", "Medium", "Large"),cex=1.1,pos=4)
axis (side=1, at = seq(110,190,length.out=6), labels = 11:16)
mtext (side=1,text="Vocal tract length (cm)", line = 2.75)
```

We can see how this might work in the code below. First, we create a new variable that will hold our size group predictions, `SG_hat`. Then, we see this variable to 1 if apparent height is less than 155.7 cm, to 2 if apparent height is between 155.7 and 170 cm, and 3 if it is greater than 170 cm.

```{r}
SG_hat = exp_data$height * 0
SG_hat[exp_data$height <= 155.7] = 1
SG_hat[exp_data$height >= 155.7 & exp_data$height <= 170] = 2
SG_hat[exp_data$height >= 170] = 3
```

We can see that even this relatively primitive 'model' is able to correctly predict size group responses in 75% of cases. 

```{r}
mean (exp_data$SG == SG_hat)

xtabs (~ exp_data$SG + SG_hat)
```

We can make this situation more general if we abstract the y axis to be a latent variable that is not necessarily apparent height. We can think of this as 'size' or 'bigness', buts its name is not important, and neither is us having a rock-solid conceptual grasp of what it is exactly. Instead, all we need to conceptualize is that we think there is some latent variable, something like 'bigness', that allows listeners to classify speakers into small, medium, and large groups based on their voices. The right side of figure \@ref(F12-10) is labelled "Bigness" to correspond to this latent variable. Actually, this variable is just apparent height divided by 50, but the point is that the values of this axis are entirely arbitrary. Notice that the change in axis units has absolutely no effect of the way our conceptual model works. If the latent variable units are 50 times smaller than some other variable, that just means the line relating x to y is 50 times smaller and the boundaries between categories are equal to the other categories divided by 50. The same logic applies to the relationship between our latent dependent variable and our predictors. 

```{r F12-10, fig.height = 3, fig.width=8, fig.cap = " -- ", echo = FALSE}

################################################################################
### Figure 12.10
################################################################################

tmp = aggregate (height ~ SG, data = exp_data, FUN = mean)

x = seq (-35,35,.1)
y = dlogis(x,0,5)

x_2 = seq (100,230,.1)
y_2 = x_2


par (mfrow = c(1,1), mar = c(4,4,.1,4), oma = c(.5,.5,.51,.51))
#layout (mat = t(c(1,2)), widths = c(.6,.4))

plot (x,y, yaxt='s',type = 'l', xlim = c(120,190),ylim = c(105,215),
      xlab = "Apparent Height (cm)",xaxt='n',ylab="Apparent Height (cm)")
rect (100,90,200,mean(tmp[1:2,2]), col = bmmb::cols[1],border=bmmb::cols[1])
rect (100,mean(tmp[1:2,2]),200,mean(tmp[2:3,2]), col = bmmb::cols[11],border=bmmb::cols[11])
rect (100,mean(tmp[2:3,2]),200,400, col = bmmb::cols[10],border=bmmb::cols[10])
lines (x_2,y_2, lwd=4, col = bmmb::cols[2])


axis (side=4, at = seq(120,200,20), labels = seq(120,200,20)/5)

spot = 160
lines (-y*150+spot, x+spot, ylim = c(120,190), xlim = c(-.35,0), xaxs='i',type='l',lwd=2)
lines (rep(spot,length(x)),x+spot,type="l",lwd=2)
points (spot,spot,pch=16,col=bmmb::cols[2],cex=2)

spot = 140
lines (-y*150+spot, x+spot, ylim = c(120,190), xlim = c(-.35,0), xaxs='i',type='l',lwd=2)
lines (rep(spot,length(x)),x+spot,type="l",lwd=2)
points (spot,spot,pch=16,col=bmmb::cols[2],cex=2)

spot = 180
lines (-y*150+spot, x+spot, ylim = c(120,190), xlim = c(-.35,0), xaxs='i',type='l',lwd=2)
lines (rep(spot,length(x)),x+spot,type="l",lwd=2)
points (spot,spot,pch=16,col=bmmb::cols[2],cex=2)

text (118,c(140,163,195), c("Small", "Medium", "Large"),cex=1.1, pos=4)

abline (h = mean (tmp[1:2,2]), lwd = 5, col = bmmb::cols[15])
abline (h = mean (tmp[2:3,2]), lwd = 5, col = bmmb::cols[15])

axis (side=1, at = seq(110,190,length.out=6), labels = 11:16)
lines (x,y, lwd=4, col = bmmb::cols[2])

mtext (side=4, "Bigness", line=2.2)
```

We need to add one final detail to get to an almost explanation of ordinal regression. In figure \@ref(fig:F9-1) we showed that bivariate linear regression with Gaussian errors can be thought of as a Gaussian distribution sliding along a line based on the value of the dependent variable. The y axis value of the line at an x axis location tells you the expected value of y for that value of x. However, we will hardly (if ever) observed the expected value exactly. Instead, we assume that we have Gaussian error centered around our expected values so that the values we observe actually probabilistically vary around the expected value. 

We show a similar situation in figure \@ref(F12-10), with a probability distribution sliding along a line. However, the values that this distribution generates cannot be the observed values of an ordinal variable. This is because our observed values are strictly the ordinal categories small (the first category), medium (the second category), and large (the third category), and a continuous probability distribution will generate continuous values. This means that our probability distribution, centered at our expected value, needs to generate values broadly consistent with three integer values 1, 2 and 3. Ordinal regression solves this problem by using the area under the curve of the error distribution in the latent variable to predict the probability of observing different probability distributions. 

Ordinal regression estimates the location of boundaries between categories along the latent variable, and the expected value of the latent variable for a combination of predictor variables. For example, figure \@ref(fig:F9-1) shows a situation where the boundaries are at around 3.1 and 3.4 bigness, and you have an expected bigness of around 3.2 for a vocal-tract length of 14.1. We then center a **logistic** distribution at this location (hence the name, ordinal *logistic* regression), to represent the error in our model. We can think of it this way: Given a VTL of 14.1 we know how big people will sound in general, but these things are fuzzy and necessarily noisy. So there is actually a distribution of expected perceived/apparent 'bigness' given our predictors. In order to understand how this information is used in ordinal regression, we need to talk about cumulative distribution functions first. 

We can see that a substantial amount of the first distribution is in the 'small' zone of the y axis. Since the total area under the curve of the distribution is 1, the area in the 'small' section can be thought of as the probability of observing a small response. The same logic applies to the area within the 'medium' and large sections. We can also see that when there is a VTL of 15.4 and a bigness of 3.6 the probability distribution slides up along the y axis, changing the amount of probability density falling within each section of the dependent variable. 

### Cumulative density

We haven't explicitly talked about cumulative distribution functions yet, though we did see one in chapter 10 when it was referred to as the *logistic* function (more on this in a moment). To this point we've been focused on what are called probability density functions (PDF), functions that assign a density to given values of variables. Examples of density functions are given in the top row of figure \@ref(fig:F12-11). **Cumulative distribution functions** (CDF) tell you the probability that a variable will be less than or equal to some value. If we recall that a probability density function has an area under the curve equal to 1 (representing the total probability of the variable), then the cumulative distribution function tells you how much of the area under the curve of the density function is to the left of any value.

For example, in the left column we see a standard normal distribution with a mean of 0 and a standard deviation of one. In the top row we see its probability density function showing that the most probable values are near the mean of the variable and values become less probable as we go further from the mean. We know that the normal distribution is symmetrical about its mean so that half the area under the curve of this density must be below 0. If we look at the bottom row of the first column, we can see the cumulative function corresponding to the density in the top row. If we look at the value of this function at x=0, we see that it is exactly equal to 0.5. In other words, the cumulative function tells us that the standard normal has exactly half its mass at values less than x=0. 

```{r F12-11, fig.height = 4, fig.width=8, fig.cap = " -- ", echo = FALSE}

################################################################################
### Figure 12.11
################################################################################

par (mfcol = c(2,3), mar = c(.1,.2,.11,.2), oma = c(2.5,4,3,.5))

x = seq(-5,5,.01)
plot (x, dnorm (x), type = 'l', xaxt='n', xaxs='i',lwd=4,col=bmmb::cols[5],yaxt='n')
mtext (side=2,"Density", line=2.5)
mtext (side=3,"Standard Normal", line=1)
abline (v = 0,lty=3,col="grey",lwd=3)
plot (x, pnorm (x), type = 'l', xaxs='i',lwd=4,col=bmmb::cols[5])
mtext (side=2,"Cumulative Probability", line=2.5)
segments (-6,.5,0,.5,lty=3,col="grey",lwd=3)
segments (0,-5,0,.5,lty=3,col="grey",lwd=3)
text (0.1,.2,"x=0", cex = 1.5,pos=4)
text (-3,.6,"y=0.5", cex = 1.5,pos=4)

x = seq(-10,10,.01)
plot (x, dlogis (x), type = 'l', xaxt='n', yaxt='n', xaxs='i',lwd=5,col=bmmb::cols[2])
mtext (side=3,"Logistic", line=1)
abline (v = 2,lty=3,col="grey",lwd=3)
plot (x, plogis (x), type = 'l', yaxt='n', xaxs='i',lwd=5,col=bmmb::cols[2])
segments (-16,.88,2,.88,lty=3,col="grey",lwd=3)
segments (2,-5,2,.88,lty=3,col="grey",lwd=3)
text (2.1,.2,"x=2", cex = 1.5,pos=4)
text (-7,.8,"y=0.88", cex = 1.5,pos=4)

x = seq(-10,10,.01)
plot (x, dlogis (x), type = 'l', xaxt='n', yaxt='n', xaxs='i',lwd=5,col=bmmb::cols[1])
mtext (side=3,"Logistic", line=1)
abline (v = c(2,-1),lty=3,col="grey",lwd=3)
plot (x, plogis (x), type = 'l', yaxt='n', xaxs='i',lwd=5,col=bmmb::cols[1])
segments (-16,.88,2,.88,lty=3,col="grey",lwd=3)
segments (-16,.27,-1,.27,lty=3,col="grey",lwd=3)
segments (2,-5,2,.88,lty=3,col="grey",lwd=3)
segments (-1,-5,-1,.27,lty=3,col="grey",lwd=3)
text (2.1,.2,"x=2", cex = 1.5,pos=4)
text (-7,.8,"y=0.88", cex = 1.5,pos=4)

text (-5.11,.1,"x= -1", cex = 1.5,pos=4)
text (-7,.35,"y=0.27", cex = 1.5,pos=4)
```

We can use the `pnorm` function (discussed in chapter 2) to get the value of the normal CDF for any value of x. Below we calculate this for x=0, x= -2, and x=2. See that in each case, the output of the function corresponds to the y axis value of the CDF at that x axis location.

```{r}
# cumulative density at x = 0
pnorm (0,0,1)

# cumulative density at x = -2,2
pnorm (c(-2,2),0,1)
```

The CDF is the **integral** of the PDF, and the PDF is the **derivative** of the CDF. We've already explained the *integral* part of this: As you move left to right, the value of the CDF equals the cumulative (i.e. added up total) area under the curve in the PDF to that point. To say that the PDF is the derivative of the CDF means that the value of the PDF reflects the *rate of change* (i.e. the slope) in the CDF for different values of x. Imagine you were on a car driving up the standard normal CDF in figure \@ref(fig:F12-11). As you drive along around -4 the 'terrain' is flat and the value of the density is near 0. As you near -2 the slope of the CDF increases, as does the value of the PDF. The value of the PDF is largest at x=0, telling us that the slope of the CDF is greatest at that point. As we drive past x=0 we see a gradual decrease in the slope until we more or less reach 'flat ground' again at just past x=2. This is reflected by the gradual decrease in the value of the PDF between x=0 and x=2. 

In the middle column we see a logistic distribution. The **logistic distribution** is a two-parameter distribution very similar to the normal distribution but with 'fatter/heavier tails' (like the t distribution). The logistic distribution has a location parameter (\mu, equal to the mean) that determines its location along the number line, and a scale parameter ($s$, equal to the standard deviation times $\sqrt{3}/\pi$) that is positively related to the 'width' of the density function. These parameters are very similar to those of the Gaussian and t distributions, and serve the same functions. However, they have different definitions and are involved in different ways in their respective density function. In the bottom row of the middle column, we see the CDF pf the logistic density. It turns out that logistic function we used as the link function for logistic regression in chapter 10 is simply the CDF of a logistic distribution with a mean of 0 and a scale 0f 1. 

In the middle column we see that we can use the same approach we used for our normal distribution to calculate values of the CDF of our logistic distribution. Below, we use the `plogis` function to calculate the probability of observing a value greater than or equal to 2 form that distribution. 

```{r}
plogis (2,0,1)
```

In the right column of figure \@ref(fig:F12-11) we've placed two vertical lines at x= -1 and x=2. We use the code below to calculate the area under the curve to the left of each line. 


```{r}
# area left of first line
plogis (-1,0,1)

# area left of second line
plogis (2,0,1)
```

At this point, the connection between CDFs and ordinal regressions may be clear: We can use a set of boundaries and the CDF of a probability to calculate the probability of observing values within certain intervals. Figure \@ref(fig:F12-12) presents the same space, boundaries, and distributions as in figure \@ref(fig:F12-11), but rotated clockwise 90 degrees so that our latent variable (the arbitrarily named 'bigness') varies along the x axis. The distributions presented in the figure have means of 28, 32, 36, and scales of 1. The probabilities in each subsection of each plot represent the predicted probability of observing size group responses of 1, 2, and 3 respectively. These probabilities were calculated using the values of the CDF of the distributions at the different boundaries.

```{r F12-12, fig.height = 3.5, fig.width=8, fig.cap = " -- ", echo = FALSE}

################################################################################
### Figure 12.12
################################################################################

x = seq (20,44,.01)
y = dlogis(x,30,1)

x_2 = seq (-4,4.4,.05)
y_2 = x_2

par (mfrow = c(3,1), mar = c(.5,1,.5,1), oma = c(4,.5,.51,.51))

plot (x+3.2,y*2, yaxt='s',type = 'n', xlim = c(22,42),ylim = c(0.02,.8),
      xlab = "",xaxt='n',ylab="",yaxt = 'n')
rect (1,0,31,1, col = bmmb::cols[1],border=bmmb::cols[1])
rect (31,0,34,1, col = bmmb::cols[11],border=bmmb::cols[11])
rect (34,0,50,1, col = bmmb::cols[10],border=bmmb::cols[10])
lines (x-2,y*2.5, xaxs='i',type='l',lwd=2)
abline (v = c(31,34),lwd=5,col=bmmb::cols[15])

text (25, .45, "P(SG=1)=0.95", cex=1.1)
text (32.5, .3, "P(SG=2)=0.04", cex=1.1)
text (40, .3, "P(SG=3)=0.01", cex=1.1)

plot (x+3.2,y*2, yaxt='s',type = 'n', xlim = c(22,42),ylim = c(0.02,.8),
      xlab = "Bigness",xaxt='n',ylab="",yaxt = 'n')
rect (1,0,31,1, col = bmmb::cols[1],border=bmmb::cols[1])
rect (31,0,34,1, col = bmmb::cols[11],border=bmmb::cols[11])
rect (34,0,50,1, col = bmmb::cols[10],border=bmmb::cols[10])
lines (x+2,y*2.5, type = 'l', lwd=2)
abline (v = c(31,34),lwd=5,col=bmmb::cols[15])

text (25, .3, "P(SG=1)=0.26", cex=1.1)
text (32.5, .2, "P(SG=2)=0.61", cex=1.1)
text (40, .3, "P(SG=3)=0.12", cex=1.1)


plot (x+3.2,y*2, yaxt='s',type = 'n', xlim = c(22,42),ylim = c(0.02,.8),
      xlab = "Bigness",xaxt='n',ylab="",yaxt = 'n')
rect (1,0,31,1, col = bmmb::cols[1],border=bmmb::cols[1])
rect (31,0,34,1, col = bmmb::cols[11],border=bmmb::cols[11])
rect (34,0,50,1, col = bmmb::cols[10],border=bmmb::cols[10])
axis (side=1, at = seq(24,40,4),cex=1.2)
lines (x+6,y*2.5, type = 'l', lwd=2)
abline (v = c(31,34),lwd=5,col=bmmb::cols[15])

text (25, .3, "P(SG=1)=0.01", cex=1.1)
text (32.5, .35, "P(SG=2)=0.11", cex=1.1)
text (40, .3, "P(SG=3)=0.88", cex=1.1)

mtext (side=1,"Bigness", line=2.75)
```

For example, below we calculate the probability of observing each size group based on the distribution in the middle plot with a mean of 32 and a scale of 1. First, we find the probability of observing a bigness value less than 31 (the first boundary). This tells us the probability of observing a response of size group 1 for this expected value of bigness (P(SG=1)=0.26). Then, we again find the probability of a bigness value less than 31 (the first boundary), and subtract this from the probability of a bigness value less than 34 (the second boundary). This section operation gives us the probability of observing a bigness value between the first and second boundaries, i.e. the probability of observing a medium size group response (P(SG=2) = 0.88 - 0.26). Finally, to find the probability of a large size group response we find the probability of a bigness value less than 34, and subtract this from 1. Since there are no values above the largest response category, the entire probability above the highest threshold must correspond to the final category. 

```{r}
# probability of observing category 1
plogis (31,32,1)

# probability of observing category 2
plogis (34,32,1) - plogis (31,32,1)

# probability of observing category 3
1 - plogis (34,28,1)
```

### Data and research questions

We load our packages and data below. We also add a new variable, `SG` (size group), which will act as our dependent variable. This variable represents children with a 1, adult women with a 2, and adult males with a 3. We don't need to do anything special to make this variable 'ordinal', but we are using three consecutive integers to represent the categories to make things simpler. After this, we process our quantitative predictors in the same way as in the previous chapters.

```{r, warning=FALSE, message=FALSE}
library (brms)
library (bmmb)
data (exp_data)

# new dependent variable: Size Group
exp_data$SG = 0
exp_data$SG[exp_data$C=='m'] = 3
exp_data$SG[exp_data$C=='w'] = 2
exp_data$SG[exp_data$C=='g'] = 1
exp_data$SG[exp_data$C=='b'] = 1

# preparation of quantitative predictors as in previous chapters
exp_data$vtl_original = exp_data$vtl
exp_data$vtl = exp_data$vtl - mean (exp_data$vtl)

exp_data$f0_original = exp_data$f0 
exp_data$f0 = exp_data$f0 - mean(exp_data$f0)
exp_data$f0 = exp_data$f0 / 100
```

We're going to keep our research questions relatively simple this time: 

Q1) Can we predict which size group people will tend to respond for a speaker's voice given their f0 and VTL?


### Description of the model

To fit a model predicting apparent size group from speaker f0 and VTL, we can use the formula below:

`SG ~ vtl+f0 + (vtl+f0|L) + (1|S)`

There is actually nothing new or unique about this model formula, it is very much like ones we've used several times in earlier chapters. However, the relationship it represents between our predictors and our dependent variables is substantially different to what we have seen before. Let's consider the relationship between the independent variables and the mean of our logistic distribution, presented in equation below:


$$
\begin{equation}
\begin{split}
\mu_{[i]} = VTL \times vtl_{[i]} + F0 \times f0_{[i]}
\end{split}
(\#eq:12-11)
\end{equation}
$$

The result of this regression equation is an expected value for our latent variable. We model this latent variable as being distributed according to a logistic distribution with a mean of $\mu$ and a scale parameter equal to 1, as in equation below. 

$$
\begin{equation}
\begin{split}
z_{[i]} \sim \mathrm{Logistic} (\mu_{[i]}, 1)
\end{split}
(\#eq:12-12)
\end{equation}
$$
Our observed (dependent) ordinal category is then selected based on the value of the latent variable ($z_{[i]}$) for that trial, relative to the model thresholds. We see this in equation below. 

$$
\begin{equation}
\begin{split}
SG_{[i]} = 
\begin{cases}
1 \; \mathrm{if} \; z_{[i]} < \theta_1 \\ 
2 \; \mathrm{if} \; \theta_{[1]} < z_{[i]} < \theta_{[2]} \\ 
3 \; \mathrm{if} \; \theta_{[2]} < z_{[i]} \\ 
\end{cases}       
\end{split}
(\#eq:12-13)
\end{equation}
$$

Notice that the model prediction equation (reference equation) does not contain an intercept term in its prediction of the expected value of the latent variable. This is because the value of the latent variable doesn't really matter on its own, but only relative to the thresholds. Suppose we had an intercept = 0 and thresholds of 2 and 5. The behavior of this model would be exactly analogous to a model with an intercept of 10 and thresholds of 12 and 15. There are an infinite number of such analogous models, one for each possible value of the intercept. For this reason, the overall intercept in these models is usually set to zero and not modeled, and instead only the J-1 thresholds are modeled. 

Although ordinal models do not usually model the overall intercept, they *can* model listener-dependent intercepts. Effectively, this is analogous to sliding the thresholds up and down the numberline by different amounts for each listener. This sort of listener-adjustment *can* have a meaningful effect on predictions, unlike changes in the overall model intercept outlined above.  


$$
\begin{equation}
\begin{split}
SG_{[i]} = 
\begin{cases}
1 \; \mathrm{if} \; z_{[i]} < \theta_{[1]} \\ 
2 \; \mathrm{if} \; \theta_{[3]} < z_{[i]} < \theta_{[2]} \\ 
3 \; \mathrm{if} \; \theta_{[2]} < z_{[i]} \\ 
\end{cases}
\\\\
z_{[i]} \sim \mathrm{Logistic} (\mu_{[i]}, s)\\
\\
\mu_{[i]} = a_{[i]} + b_{[i]} \times \mathrm{vtl}_{[i]} + c_{[i]} \times \mathrm{f0}_{[i]}  \\ 
a_{[i]} =  L_{[L_{[i]}]} \\
b_{[i]} =  VTL + VTL \colon L_{[L_{[i]}]} \\
c_{[i]} =  f0 + f0 \colon L_{[L_{[i]}]} \\ 
\\
\textrm{Priors:} \\
S_{[\bullet]} \sim \mathrm{Normal}(0,\sigma_{S_j}) 
\\ 
\begin{bmatrix} L_{[\bullet]} \\ VTL \colon L_{[\bullet]} \\ f0 \colon L_{[\bullet]} \end{bmatrix}	
\sim \mathrm{MVNormal} \left(\, \begin{bmatrix} 0\\ 0 \\ 0 \\ \end{bmatrix}, \Sigma \right) \\ \\
Intercept \sim t(3, 0, 3) \\
VTL, f0 \sim t(3, 0, 3) \\
\sigma_{L}, \sigma_{VTL \colon L}, \sigma_{f0 \colon L} \sim t(3, 0, 3) \\ R \sim \mathrm{LKJCorr} (2)
\end{split}
(\#eq:12-14)
\end{equation}
$$

Here's a verbal description of our model:

> We are modelling an ordinal variable, size group ($SG$), with possible outcomes of small (1), medium (2), and large (3). The value expected for any given trial is based on the value of a latent variable ($z$) in relation to two thresholds ($\theta_{[1]},\theta_{[2]}$). Our latent variable is modeled as coming from a logistic distribution with a scale of 1 and a mean that varies from trial to trial. The mean of these distributions varies based on the combination of 'main' (e.g., $VTL$) and listener-dependent (e.g. $VTL \colon L$) effects for vocal tract length and f0, and a listener-dependent intercept. 







The mean is modeled as varying based on 



> We're treating our femaleness judgments (1 or 0 for female or male) as coming from a Bernoulli distribution with a probability that varies trial to trial. The *logit of the probability* (z) varies along lines. The lines are specified by intercepts and slopes that vary trom trial to trial, and there is a single continuous predictor (speaker VTL). The intercept of these lines vary based on an overall intercept (the main effect), an overall effect for the perception of an adult speaker ($A1$), listener-specific effects for apparent age ($A1 \colon L$), listener-specific deviations from the mean ($L$), and speaker-specific deviations from the mean (S). The slope of these lines vary based on an overall slope ($VTL$, the main effect), deviations based on apparent age ($VTL \colon A1$), listener-specific deviations from the average slope ($VTL \colon L$), and listener-specific interactions between apparent age and VTL ($A1 \colon VTL \colon A1$)). 
  The speaker intercept ($S$) terms were drawn from a normal distribution with a mean of zero and a standard deviation estimated from the data. The listener random effects were drawn from a multivariate normal distribution with means of 0 of zero and a covariance matrix estimated from the data. All other effects (e.g., the Intercept, VTL, A, etc.) were treated as 'fixed' and drawn from prior distributions appropriate for their expected range of values. 











### Fitting and interpreting the model

- you can also model the sd parameter
- there is also a normal model, but we will not be discussing here
- in practice little to no difference just like probit and logit for logistic
- not used because they are the real distribution but because commonly used, efficient, easy, convenient etc


```{r}
# Fit the model yourself
set.seed (1)
options (contrasts = c('contr.sum','contr.sum'))
model_ordinal = brms::brm (SG ~ vtl+f0 + (vtl+f0|L) + (1|S), data=exp_data, family="cumulative", 
           chains=4, cores=4, warmup=1000, iter = 5000, thin = 4,
           prior = c(set_prior("student_t(3, 0, 3)", class = "Intercept"),
                     set_prior("student_t(3, 0, 3)", class = "b"),
                     set_prior("student_t(3, 0, 3)", class = "sd"),
                     brms::set_prior("lkj_corr_cholesky (2)", class = "cor")))
```

```{r, eval = FALSE}
model_ordinal = bmmb::get_model ("12_model_ordinal.RDS")
```
```{r, include = FALSE}
#  saveRDS (model_ordinal, "../models/12_model_ordinal.RDS")
model_ordinal = readRDS ("../models/12_model_ordinal.RDS")
```







```{r}
preds = predict (model_ordinal, re_formula = NA)
preds2 = predict (model_ordinal)
```

```{r}

fixed = brms::fixef(model_ordinal)

x = model_ordinal$data$vtl * fixed[3,1] + model_ordinal$data$f0  * fixed[4,1]

predds = cbind (round (plogis (fixed[1,1], x),5), 
                round ((plogis (fixed[2,2], x)-plogis (fixed[1,1], x)),5),
                round (1-plogis (fixed[2,2], x), 5))

head (predds)
head (preds)

       
```



```{r}
pred_cat = apply (preds,1,which.max)
pred_cat2 = apply (preds2,1,which.max)

mean (exp_data$SG == pred_cat)
mean (exp_data$SG == pred_cat2)
```




```{r}
tapply (bmmb::exp_data$vtl, bmmb::exp_data$C, mean)
tapply (bmmb::exp_data$f0, bmmb::exp_data$C, mean)

par (mar = c(.2,.2,.2,.2), oma = c(3,3,.5,.5), mfrow = c(4,4))
curve (dlogis (x), from=-7,to=7)
abline (v = fixed[1:2])
```



### Answering our research questions









