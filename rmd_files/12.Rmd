\newpage
```{r}
knitr::opts_chunk$set(
  dpi = 300, dev = "jpeg", collapse=TRUE
)
```

# Multinomial and Ordinal regression

In chapter 10 we introduced models that can predict dichotomous categorical variables using logistic regression. Here, we extend many of the concepts introduced in that chapter to the modelling of dependent variables with any number of categories. First, we discuss multinomial regression models that can be used for categorical variables without an inherent ordering. For example, we could use a model like this to predict the perception of vowel sounds from speech acoustics, to predict the lexical category of a word (verb, noun, adjective, ...), or to predict a speaker's native language. Actually, these models can *also* be used for ordered data, they just do not inherently represent the ordering in the model. After this, we introduce ordinal models appropriate for the prediction of categorical variables with some inherent ordering (e.g., first, second and third).  

## Chapter pre-cap

--

### Bold words

Throughout each chapter you will see words in bold. These are important concepts that appear in bold where they are introduced and described in the text. The bold words in this chapter, in alphabetical order, are: 

--

## Multinomial logistic regression

**Multinomial logistic regression** allows you to model data generated by a **multinomial distribution** with some unknown parameters. The multinomial distribution is the generalization of the binomial distribution (see section X) to any number of positive integer outcome categories. For example, the multinomial distribution will allow use to model the categorization of speakers into boys, girls, men, and women simultaneously rather than modeling this as two binary categorizations (male vs. female and adult vs. child). The multinomial distribution has three parameters:
  
  1) $n$: The number of trials, a positive integer.
  2) $J$: The number of possible outcomes, a positive integer.
  3) $p_1, \dots, p_J$: A vector of probabilities of observing each of the $j$ outcomes where $\sum p_j = 1$.
  
Multinomial data arises in situations such as the following. You have a variable that can take on some number of possible values. For example, you ask people to tell you if the speaker seems to be a boy, a girl, a man, or a woman. This results in a variable, apparent speaker category, that can take on one of four discrete values. You observe a certain number of trials ($n$) under some set of conditions. You then count how many times listeners identified the speaker as belonging to one of the four categories. If you divide these counts by the total number of trials ($n$) you will get the probability of observing each outcome ($p_J$). We can think of our data as being generated by a multinomial distribution with some specific parameters as seen below. Our data is a vector of counts, $y_1, \dots, y_J$, representing the expected number of observations of each category for $n$ total outcomes. 


$$
\begin{equation}
y_1, \dots, y_J \sim \mathrm{multinomial}(p_1, \dots, p_J, n)
(\#eq:12-1)
\end{equation}
$$


Below we draw 10 instances of a four-category multinomial variable with probabilities of 0.4, 0.1, 0.2, and 0.3 for the first, second, third and fourth categories respectively. Each of the variables below has $n=1$ so a single category is equal to 1 and the others must all be zero. 
  
```{r}
rmultinom (10, 1, c(.4,.1,.2,.3))
```

We sample ten more multinomial variables, this time each with $n=100$. We can see that we get a distribution of values across the four outcomes for each variable that resembles the values of $p$ we defined for each outcome. Note that the categories are numbered and could represent anything. This sort of variable only represents the relative frequency of outcomes with respect to each other and does not specify relationships between outcomes.

```{r}
set.seed (1)
multinomial_variable = rmultinom (10, 100, c(.4,.1,.2,.3))
multinomial_variable

rowMeans(multinomial_variable)/100
```

There are many ways to think about multinomial logistic regression. We're going to present one that is consistent with the way we presented logistic regression in chapter 10 and the way we have been presenting regression models in general in this book. For a more complete treatment of the topic please see cite. Before beginning the explanation we can 'spoil' the conclusion:  The number of trials ($n$) and the number of possible outcomes ($J$) are aspects of your data and experimental design, and are known to you before you fit any model. Thus, multinomial logistic regression effectively consists of estimating $p_j$, or values analogous to it, for each category as a function of your dependent variables. 

Multinomial regression is a surprisingly 'simple' extension of the concepts underlying logistic regression (presented in chapter 10). When we discussed logistic regression in chapter 10, we introduced the antilogit function (also known as the *logistic* link function). In section X, we discussed the fact that this function converts log odds to probabilities by arbitrarily setting the 'number' of failures to 1 and modeling the number of outcomes (i.e. $e^z$). So, we see in equation below that the probability that $y=1$ (i.e. a 'success') is equal to the ratio of the 'number' of successes over the sum of the total number of outcomes.  

$$
\begin{equation}
\begin{split}
P(Y=1) = \frac{\mathrm{success}}{\mathrm{failure}+\mathrm{success}} = \frac{e^{z}}{1+e^{z}}
\end{split}
(\#eq:12-2)
\end{equation}
$$

The equation above works for when we have exactly two categories. However, it can be modified so that it can be applied to multiple categories. First, we assume that rather than exactly two possible outcomes, there are $J$, some integer larger than one. If we stick to our interpretation of the value of $e^{z}$ as an expected count for that category, then $e^{z_j}$ is the expected count for category $j$. To find the probability of observing category $j$ we find the ratio of the 'count' of $j$ over the sum of all possible outcomes (i.e., the sum of counts for all categories).

$$
\begin{equation}
\begin{split}
P(Y=j) = \frac{e^{z_j}}{\sum_{j=1}^{J} e^{z_j}}
\end{split}
(\#eq:12-3)
\end{equation}
$$

The function above is called the **softmax** function, and it is basically a generalization of the antilogit (logistic) function to more than two categories. When we did dichotomous logistic regression, we modeled only the 'count' of one variable, the one set to 'success'. The 'counts' for the category set to 'failure' was not modeled and was set to 1 (by setting $z=0$) for all cases. When we model multinomial data we have to follow the same convention and set one category as the 'reference'. This means the the equation above can be modified to pull one category out of the summation and set its count to 1 for all situations, as in the equation below. Notice that the count on the summation in the denominator of the fraction now begins at two.

$$
\begin{equation}
\begin{split}
P(Y=j) = \frac{e^{z_j}}{1 + \sum_{j=2}^{J} e^{z_j}}
\end{split}
(\#eq:12-4)
\end{equation}
$$

The equation above results in a set of probabilities which can serve as the multinomial parameters, $p_1, \dots , p_j$, for categories $1, \dots, J$. These probabilities are modeled by estimating $z_j$ as resulting from the linear combination of our predictor variables based on some unknown parameters ($\beta_j$). Each outcome has a different prediction equation for $z_j$ so that a multinomial regression has $J$ prediction equations, one for each outcome. Importantly, each prediction equation combines the same $x_k$ predictors, albeit in a category-specific way (based on the $\beta_j$ parameters for that category).  

$$
\begin{equation}
z_j = \beta_j + \beta_{j1} \times x_1 + \beta_{j2} \times x_2 + \dots + \beta_{kj} \times x_k
(\#eq:12-5)
\end{equation}
$$

The prediction equation for the 'reference' category (`brm` uses the first category) is fixed to have a value of 0. One way to accomplish this is to fix all coefficients for this outcome to equal 0 as in equation below. 

$$
\begin{equation}
z_1 = 0 \\
0 = \alpha_j + \beta_{j1} \times x_1 + \beta_{j2} \times x_2 + \dots + \beta_{kj} \times x_k \\
z_1 = 0 + 0 \times x_1 + 0 \times x_2 + \dots + 0 \times x_k \\
(\#eq:12-6)
\end{equation}
$$

When we carried out logistic regression, the variable $z$ was refereed to as a logit. Sometimes the $z_j$ values involved in multinomial regression are called **multinomial logits** to highlight their similarity to the dichotomous logit. Sometimes these values are referred to as the **score** for each category. The score is somewhat vaguely defined, in part because there are many ways to think about what the score is and means. One way to think of the score is that it is a *latent variable* associated with each category, that relates to the probability of observing that category given the values of the dependent variables.

**Latent variables** are variables that are inferred mathematically using some statistical model, but are not measured directly. For example, in our logistic regression model in chapter 10 we predicted the perception of femaleness. We did this by predicting variation in the logit of the probability of observing a female response as a function of speaker vocal-tract length. The logit of this probability can be thought of as a latent variable representing something like 'femininity' in the mind of the listener. Based on the 'feeling' of voice femininity that the listener has they produce the surface variable that we do measure: The classification of a speaker as female/male. In this view the realization of the response variable (a female classification) is the result of a secret, *latent* variable that is not directly observed by us, but which we assume underlies the process. 

We have four latent variables in our multinomial model predicting apparent category: The score for each category. We can think of these as the 'feeling' the listener has regarding the 'boyness', 'girlness', 'manness', and 'womanness' of the voice. What is the 'boyness' of a voice? The unquantifiable internal knowledge you have that a voice is that of a boy, as opposed to some other sort of speaker. These latent variables are not directly measured in our experiment but we think they underlie the categorization of speakers into categories. When a listener hears a voice and their 'boyness' score is greater than the other scores, the listener is most likely to indicate that the voice is a boy. When the score between one category and the others is very unequal, this decision is easy and classification into one category will dominate. When the scores for two or more categories are about equal, i.e. the 'boyness' and 'womanness' of a voice are similar, the listener will feel ambiguous about the decision and classification into either category may be equally likely.

At this point we've laid out the basics of multinomial regression and can present a summary of the information we just presented. In multinomial logistic regression we model the probability of observing each of the $J$ categorical outcomes. We fix the value of the score (or multinomial logit) of the reference category to 1, and estimate the scores of the other categories using a prediction equation specific for the category. The logit predicted for each category in a specific situation can then be converted to a probability using the softmax function presented in equation above. 

### Data and research questions

We load our packages and data below. We also add a new variable, $y$, representing our multinomial outcome. This variable represents observations of a vector of length four whose first, second, third, and fourth elements represent observed outcomes of 'boy', 'girl', 'man', and 'woman', respectively. After this we add a variable called `size` that always equals 1 because each row in our data frame represents observation of a single outcome. Finally, we process our quantitative predictors in the same way as in the previous chapters.

```{r, warning=FALSE, message=FALSE}
library (brms)
library (bmmb)
data (exp_data)

# new dependent variable
exp_data$y = cbind(b = as.numeric(exp_data$C=='b'),
                   g = as.numeric(exp_data$C=='g'),
                   m = as.numeric(exp_data$C=='m'),
                   w = as.numeric(exp_data$C=='w'))

# variable representing the size (n) of each observation. They are all 1.
exp_data$size = 1

# preparation of quantitative predictors as in previous chapters
exp_data$vtl_original = exp_data$vtl
exp_data$vtl = exp_data$vtl - mean (exp_data$vtl)

exp_data$f0_original = exp_data$f0 
exp_data$f0 = exp_data$f0 - mean(exp_data$f0)
exp_data$f0 = exp_data$f0 / 100
```

Below, we print out the first six instances of our dependent variable and compare this to the first six values of the `C` (apparent category) variable in our data frame. We can see that the dependent variable indicates which category was selected for a given trial using a 1 in the appropriate column and a 0 in the others. 

```{r}
# first 6 elements of dependent variable
head (exp_data$y)

# first six elements of apparent speaker category factor
head (exp_data$C)
```

We will try to use our data to answer the following research question: 

Q1) Can we use speaker f0 and VTL to predict their apparent speaker category?

Keep in mind we're trying to predict *apparent* and not *veridical* speaker category. Our consideration of the accuracy or utility of this model will depend on how well it represents listener classifications of speakers, now matter how wrong or right these may be. Thus, a model with perfect classification of speakers into veridical categories is not the goal: If listeners make predictable mistakes we want to model to make the same 'mistakes'.

### Description of our model

Our model formula is largely similar to those we have seen before, with one minor change. Beside your dependent variable, you need to include a variable that indicates the integer number of trials for each set of observations. For us this will always be 1, but in many situations this can be a wider range of values. We want to predict our counts of categorizations with respect to value of speaker VTL and f0, and so the model formula we are going to use is seen below. 

`y|trials(size) ~ vtl+f0 + (vtl+f0|S) + (1|L)`

Since we're predicting category membership with two quantitative predictors, we know that the surfaces our model defines are planes. In the models with fit to this point, we had a single dependent variable and a single plane for a single condition. So, our model formulas previously were something like:

`y ~ vtl+f0 + (vtl+f0|S) + (1|L)`

However, in a multinomial regression we have one plane for each response category, so our formula above could really be thought of as:

`y_1 ~ vtl+f0 + (vtl+f0|S) + (1|L)`
`y_2 ~ vtl+f0 + (vtl+f0|S) + (1|L)`
`y_3 ~ vtl+f0 + (vtl+f0|S) + (1|L)`
`y_4 ~ vtl+f0 + (vtl+f0|S) + (1|L)`

This means that our multinomial model will involve four times as many coefficients as an equivalent Gaussian model, and $J$ times as many for $J$ outcome categories. Of course, we noted above that the coefficients of the reference category are set to zero and not estimated. This means that the formula above results in the estimation of three planes, resulting in three sets of analogous parameters. Our full model specification is given below:

$$
\begin{equation}
\begin{split}
y_{1[i]},y_{2[i]},y_{3[i]},y_{4[i]} \sim \mathrm{multinomial}(p_{1[i]},p_{2[i]},p_{3[i]},p_{4[i]}, n_{[i]}) \\ \\
\mathrm{for} \; j = 1, \dots, 4\\ \\ 
p_{j[i]} = \frac{e^{z_j}}{\sum_{j=1}^{J} e^{z_j}} \\ 
\\
z_{j[i]} = \mathrm{a}_j + b_{j[i]} \times \mathrm{vtl}_{[i]} + c_{j[i]} \times \mathrm{f0}_{[i]}  \\ 
a_{j[i]} = \mathrm{Intercept}_j + L_{j[L_{[i]}]} + S_{j[S_{[i]}]} \\ 
b_{j[i]} =  VTL_j + VTL_j \colon L_{j[L_{[i]}]} \\
c_{j[i]} =  f0_j + f0_j \colon L_{j[L_{[i]}]} \\ 
\\
\mathrm{for} \; j = 2, \dots, 4\\ \\ 

\textrm{Priors:} \\
S_{j[\bullet]} \sim \mathrm{Normal}(0,\sigma_{S_j}) 
\\ 
\begin{bmatrix} L_{j[\bullet]} \\ VTL_j \colon L_{j[\bullet]} \\ f0_j \colon L_{j[\bullet]} \end{bmatrix}	
\sim \mathrm{MVNormal} \left(\, \begin{bmatrix} 0\\ 0 \\ 0 \\ \end{bmatrix}, \Sigma_j \right) \\ \\
Intercept_j \sim t(3, 0, 3) \\
VTL_j, f0_j \sim t(3, 0, 3) \\
\sigma_{L_j}, \sigma_{VTL_j \colon L_j}, \sigma_{f0_j \colon L_j} \sim t(3, 0, 3) \\ R_j \sim \mathrm{LKJCorr} (2)

\end{split}
(\#eq:12-7)
\end{equation}
$$

We're going to take some time to unpack this definition, top to bottom, because it is at the same time very familiar and very different. First, note that our data-generating distribution is assumed to be the multinomial distribution. This function has a $p_j$ parameter indicating the probability of observing each of the $J$ categories, and an $n$ parameter specifying the total number of trials for that observation. The next line indicates that the next few lines applies individually for all four categories. For each category, the probability of observing that outcome ($p_j$) is found by combining the score for each category ($z_j$) using the softmax link function. For each category, the score is equal to a trial-dependent combination of an intercept, an effect fot VTL, and an effect for f0. The intercept varies according to an overall model intercept and speaker and listener-dependent variations from this. The VTL and f0 effect vary according to listener-dependent effects. 

After that we move on to the model priors. Unlike for the above lines, we do not specify priors for any parameters related to the reference category. This is because all of these parameters are set to 0 for this category so that the score for this category is always 0 and the 'expected count' (as discussed above) is always equal to 1. Again we may note that the specification of priors is very similar to the models we have discussed to this point, save for the proliferation of $j$ subscripts. 

### Fitting and interpreting our models

There is one major difference in how we need to specify priors for multinomial models: We need to specify priors individually for each response category with modeled parameters. This is done by passing the name of the categorical variable to the `dpar` parameter. Above, we named our response variables according to the letters we have been using throughout this text. We can see this below.

```{r}
colnames (exp_data$y)
```

The name passed to `dpar` will be `muCategory` where `Category` corresponds to the category name. This means we need to specify priors for `mug`, `mum`, and `muw`, but not `mub`. We specify our priors below:

```{r}
multinomial_prior = 
  c(brms::set_prior("student_t(3, 0, 3)", class = "Intercept",dpar="mug"),
    brms::set_prior("student_t(3, 0, 3)", class = "b",dpar="mug"),
    brms::set_prior("student_t(3, 0, 3)", class = "sd",dpar="mug"),
    brms::set_prior("student_t(3, 0, 3)", class = "Intercept",dpar="mum"),
    brms::set_prior("student_t(3, 0, 3)", class = "b",dpar="mum"),
    brms::set_prior("student_t(3, 0, 3)", class = "sd",dpar="mum"),
    brms::set_prior("student_t(3, 0, 3)", class = "Intercept",dpar="muw"),
    brms::set_prior("student_t(3, 0, 3)", class = "b",dpar="muw"),
    brms::set_prior("student_t(3, 0, 3)", class = "sd",dpar="muw"),
    brms::set_prior("lkj_corr_cholesky (2)", class = "cor"))
```

And here is the code to fit our model, using the `multinomial()` family for the first time: 

```{r, eval = FALSE}
model_multinomial = 
  brms::brm (y|trials(size) ~ vtl+f0 + (vtl+f0|L) + (1|S), data=exp_data, 
             family=multinomial(), chains=4, cores=4, warmup=1000, iter = 5000, 
             thin = 4, prior = multinomial_prior)
```
```{r, eval = FALSE}
model_multinomial = bmmb::get_model ("12_model_multinomial.RDS")
```
```{r, include = FALSE}
#  saveRDS (model_multinomial, "../../models/12_model_multinomial.RDS")
load("../models/12_multinomial_predictions.Rda")
model_multinomial = readRDS ("../models/12_model_multinomial.RDS")
```

Figure \@ref(fig:F12-1) presents the model fixed effects, the intercept, VTL slope, and the f0 slope for each category with estimated parameters. Each group of parameters defines a plane whose value along the $z$ dimension can be predicted based on the values of f0 and VTL. We have four planes an four values of $z_j$ for any given location in the two dimensional space defined by f0 and VTL. For each point, we can select as the most probable category the one whose value of $z_j$ is highest at the point in the space. Another way to look at this is that we select the highest plane at any given location in the space. 

```{r F12-1, fig.height = 3, fig.width=8, fig.cap = " -- ", echo = FALSE}

################################################################################
### Figure 12.1
###############################################################################

par(mar=c(4,7,.51,.51))
brmplot (fixef (model_multinomial)[c(1,4,5,2,6,7,3,8,9),], 
         horizontal=FALSE, col = rep(bmmb::cols[3:5],each=3))
mtext (side=1,line=3,"Coefficient")
```

Since the dependent variable is the score for each category, the parameters above are difficult to interpret in isolation. Also, keep in mind that scores need to be interpreted relative to the baseline category value of 0 (for boys), or two each other, rather than absolutely. For example, the negative coefficient for VTL for 'girl' (`mug_vtl`) indicates the a longer VTL made a girl response less likely. We can also see that increasing f0 made a 'woman' response less likely, and a 'male' response more likely.

We might wonder how well our model can predict listener judgements. We can do this by first predicting our data using our model:

```{r, eval = FALSE}
multi_pred_re = predict (model_multinomial)
```

The result of this is a three dimensional matrix. The first two dimensions represent the by now familiar summary matrices generated by `brms`. The first column is the posterior probability of category membership for each observation, the second is the standard error for each prediction, and the third and fourth represent the 2.5% and 97.5% credible intervals.

```{r}
head(multi_pred_re[,,1])
```

The third dimension indexes the response category. Above we saw the predictions for the first category (boy) and below we see them for the second category (girl):

```{r}
head(multi_pred_re[,,2])
```

We can also just select the second dimension from each matrix, resulting in a two-dimensional matrix. This matrix contains the posterior probability of being classified into each category across columns, for each observation across rows. 

```{r}
head(multi_pred_re[,1,])
```

Since these are probabilities, the sum of each row equals one, because only these four outcomes exist. For example, the first row above tells us that, according to our model, the first observation has a 0.29 probability of being identified as a boy, 0.64 probability of being identified as a boy, 0.001 probability of being identified as a man, and a 0.07 probability of being identified as a woman. 

```{r}
head(rowSums (multi_pred_re[,1,]))
```
We can use the code below to find the 'winning' category for each observation, that is, the category with the highest posterior probability in each row. We use the resulting column numbers to get category labels. 

```{r}
# find highest posterior prbability from each category
predicted = apply (multi_pred_re[,1,],1,which.max)
head (predicted)

# use modal category to get a category label
predicted_category = c("b","g","m","w")[predicted]
head (predicted_category)

```

Below, we cross-tabulate predicted and observed classifications. Each row shows speaker classifications into different categories, and model predictions vary across columns. This is a *confusion matrix*, introduced in chapter 5. Correct classifications fall on the main diagonal and all other values indicate mistakes. For example, we see that there were 258 correct classifications of boys as boys, and 88 incorrect classifications of boys as girls. A majority of observations fall along the main diagonal indicating that the model was relatively good at predicting listener behavior.

```{r}
xtabs (~ exp_data$C + predicted_category)
```

Below we find the probability of observing a correct classification overall, and individually for each category. We see that the model we able to predict listener judgments with a high degree of accuracy overall, but that some categories (man) were much easier to predict than others (boy).

```{r}
# overall correct
mean (predicted_category == exp_data$C)

# correct predictions by category
tab = xtabs (~ exp_data$C + predicted_category)
diag(tab) / rowSums(tab)
```

### Multinomial models and territorial maps

We discussed territorial maps for two categories along two dimensions in chapter 11 where we predicted the perception of femaleness based on speaker f0 and VTL. As we discussed then, when categories are defined by planes, the boundary between categories on the space is defined by the line representing the intersection of these planes. When we did (dichotomous) logistic regression in chapter 11, we found the intersection of one plane with a horizontal plane at $z=0$. In this chapter we still have a plane such that $z=0$ for all x and y (the reference category plane), but we also have three other planes with possible non-zero slopes. The boundary between each pair of categories forms a boundary made by a line. Since we have 6 unique pairings of our four response categories, we will have six boundary lines. 

We know that the boundary between two categories is where their respective planes intersect, i.e., the place where these planes have the same $z$ axis value. To find this, first we define the values of two planes, $z_1$ and $z_2$ based on their respective coefficients as in \@ref(eq:12-8).

$$
\begin{equation}
\begin{split}
z_1 = \mathrm{a} + \mathrm{b} \times x +  \mathrm{c} \times y \\
z_2 = \mathrm{d} + \mathrm{e} \times x +  \mathrm{f} \times y
\end{split}
(\#eq:12-8)
\end{equation}
$$

We set $z_1$ equal to $z_2$, which is equivalent to setting to right hand side of each equation to equal as in \@ref(eq:12-9).

$$
\begin{equation}
\begin{split}
z_1 = z_2 \\ 
\mathrm{a} + \mathrm{b} \times x +  \mathrm{c} \times y = \mathrm{d} + \mathrm{e} \times x +  \mathrm{f} \times y
\end{split}
(\#eq:12-9)
\end{equation}
$$

In order to get all these terms into the format for the equation of a line ($y = a + b \times x$), we need to isolate y on the left hand side as seen in \@ref(eq:12-10). 

$$
\begin{equation}
y = \frac {-\mathrm{a} + \mathrm{d}}{\mathrm{c} - \mathrm{f}} + \frac{-\mathrm{b} + \mathrm{e}}{\mathrm{c} - \mathrm{f}} \times x
(\#eq:12-10)
\end{equation}
$$

As mentioned above, we get 6 such line equations, one for the boundary between each of the four planes. Figure \@ref(fig:F12-2) presents each of these six boundaries compared to the modal classification for each speaker. 

```{r F12-2, fig.height = 4, fig.width=8, fig.cap = "boys (b), girls (g), men (m), and women (w).", echo = FALSE}

################################################################################
### Figure 12.2
###############################################################################

params = fixef (model_multinomial)
params = fixef (model_multinomial, summary = FALSE)
params = cbind (colMeans (params[,1:3]), 
                colMeans (params[,c(4,6,8)]),
                colMeans (params[,c(5,7,9)]))

params = rbind (c(0,0,0), params[1:3,])

tab = table (exp_data$S, exp_data$C)
mod_cat = apply (tab, 1,which.max)

par (mfrow = c(2,3), mar = c(0.2,0.2,0.2,0.2), oma = c(4.5,4.5,0.5,0.5))

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2,
     xaxt='n')
abline (find_intersection (params[1,], params[2,]),lwd=2, col = bmmb::cols[7]) # b vs g

text (1.5,1, "boy-girl", cex=1.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2,
     yaxt='n',xaxt='n')
abline (find_intersection (params[1,], params[3,]),lwd=2, col = bmmb::cols[8]) # b vs m

text (1.5,1, "boy-man", cex=1.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2,
     yaxt='n',xaxt='n')
abline (find_intersection (params[1,], params[4,]),lwd=2, col = bmmb::cols[9]) # b vs w

text (1.5,1, "boy-woman", cex=1.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2)
abline (find_intersection (params[2,], params[3,]),lwd=2, col = bmmb::cols[10]) # g vs m

text (1.5,1, "girl-man", cex=1.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2,
     yaxt='n')
abline (find_intersection (params[2,], params[4,]),lwd=2, col = bmmb::cols[13]) # g vs w

text (1.5,1, "girl-woman", cex=1.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],cex=2,
     yaxt='n')
abline (find_intersection (params[3,], params[4,]),lwd=2, col = bmmb::cols[14]) # m vs w

text (1.5,1, "man-woman", cex=1.5)

mtext (side=1, "Centered vocal tract length (cm)", outer = TRUE, line=3)
mtext (side=2, "Centered f0 / 100 (Hz)", outer = TRUE, line=3)

```

All six boundary lines are presented in the left plot of figure \@ref(fig:F12-3). One problem with considering the figure in this way is that many of the boundaries are not very relevant. For example, the boundary between girl and man will hardly matter for classification because these categories are divided by 'woman' and 'boy' classifications. The right plot of figure \@ref(fig:F12-3) presents only those boundaries that are *relevant*. This can be stated more formally as: The figure contains only those boundaries that represents scores equal to or greater than the maximal score, for that location, from among the response categories. For example, in the left plot we see that the boy-woman boundary bisects the are where man is a modal response. This line segment does not feature in the right plot because it has a lower value than the man plane in this area. In other words, who cares if its a boy or a woman because people are more likely to say man anyways. 

```{r F12-3, fig.height = 3, fig.width=8, fig.cap = "boys (b), girls (g), men (m), and women (w).", echo = FALSE}


################################################################################
### Figure 12.3
################################################################################


params = fixef (model_multinomial)
params = fixef (model_multinomial, summary = FALSE)
params = cbind (colMeans (params[,1:3]), 
                colMeans (params[,c(4,6,8)]),
                colMeans (params[,c(5,7,9)]))

params = rbind (c(0,0,0), params[1:3,])

tab = table (exp_data$S, exp_data$C)
mod_cat = apply (tab, 1,which.max)

par (mfrow = c(1,2), mar = c(.0,.0,.21,.2),oma=c(4,4,.1,.1))

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat])
abline (find_intersection (params[1,], params[2,]),lwd=3, col = bmmb::cols[7])
abline (find_intersection (params[1,], params[3,]),lwd=3, col = bmmb::cols[8])
abline (find_intersection (params[1,], params[4,]),lwd=3, col = bmmb::cols[9])
abline (find_intersection (params[2,], params[3,]),lwd=3, col = bmmb::cols[10])
abline (find_intersection (params[2,], params[4,]),lwd=3, col = bmmb::cols[13])
abline (find_intersection (params[3,], params[4,]),lwd=3, col = bmmb::cols[14])

points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)
#points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 1, col = 1,
#     lwd=2, cex=2)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],ylab="",yaxt="n")

#maps = make_map (t(params))

plot_map (maps, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)

points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)
#points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 1, col = 1,
#     lwd=2, cex=2)

mtext (side=1, "Centered vocal tract length (cm)", outer = TRUE, line=2.5)
mtext (side=2, "Centered f0 / 100 (Hz)", outer = TRUE, line=2.5)

```

We noticed something very strange when we made the territorial map in figure \@ref(fig:F12-3): The boy territory contains a large number of woman responses. In addition, the boy-woman boundary seems strangely high. If that is really the boundary between boys and women in the VYL by f0 space, then why is the model classifying all those women correctly? The answer to this question may lie in figure \@ref(fig:F12-4). 

In the left plot of figure \@ref(fig:F12-3), point colors represent modal listener judgments for each speaker. In the middle plot we see model predictions including speaker and listener random effects. When these are included the model predictions look very much like the listener judgments and the classifications don't make much sense relative to the territorial map. In the right plot of the same figure we see model predictions when random effects are *not* included. In this case we see that model predictions do *not* look like the listener judgments, but the classifications *do* make sense relative to the territorial map. So, it seems that the random effects may be causing this strange behavior in our model.

```{r F12-4, fig.height = 3, fig.width=8, fig.cap = "boys (b), girls (g), men (m), and women (w).", echo = FALSE}

################################################################################
### Figure 12.4
################################################################################


params = fixef (model_multinomial)
params = fixef (model_multinomial, summary = FALSE)
params = cbind (colMeans (params[,1:3]), 
                colMeans (params[,c(4,6,8)]),
                colMeans (params[,c(5,7,9)]))

params = rbind (c(0,0,0), params[1:3,])

tab = table (exp_data$S, exp_data$C)
mod_cat = apply (tab, 1,which.max)

cats = apply(multi_pred[,1,],1,which.max)
table (exp_data$C, cats)
tab2 = table (exp_data$S, cats)
mod_cat2 = apply (tab2, 1,which.max)

cats = apply(multi_pred_re[,1,],1,which.max)
table (exp_data$C, cats)
tab2 = table (exp_data$S, cats)
mod_cat3 = apply (tab2, 1,which.max)


par (mfrow = c(1,3), mar = c(.0,.0,.21,.2),oma=c(4,4,2,.1))

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],ylab="")
#maps = make_map (t(params))
mtext (side=3, text = "Listener Judgments", line = 0.5)

plot_map (maps, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat2],ylab="",yaxt="n")
plot_map (maps, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat3], cex = 2)
mtext (side=3, text = "Model Predictions (with RE)", line = 0.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat3],ylab="",yaxt="n")
plot_map (maps, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat2], cex = 2)
mtext (side=3, text = "Model Predictions (no RE)", line = 0.5)



mtext (side=1, "Centered vocal tract length (cm)", outer = TRUE, line=2.5)
mtext (side=2, "Centered f0 / 100 (Hz)", outer = TRUE, line=2.5)

```

Figure \@ref(fig:F12-5) presents the speaker random intercepts. Since there are three modeled categories, there are three random intercepts for each speaker. We can see that, in general, the speaker intercepts have small values that vary around zero, and have credible intervals that mostly include zero. However, many female speakers have intercepts that have large non-zero values for the female category, and whose credible intervals omit zero and very small values.

```{r F12-5, fig.height = 4, fig.width=8, fig.cap = "boys (b), girls (g), men (m), and women (w).", echo = FALSE}

################################################################################
### Figure 12.5
################################################################################

sranef = ranef(model_multinomial)$S

tab = table (exp_data$S, exp_data$C_v)
real_cat = apply (tab, 1,which.max)

par (mfrow = c(4,1), mar =c(.1,4,.1,.5), oma = c(.5,0,.5,0))
brmplot((sranef[,,1]+sranef[,,2]+sranef[,,3])/3, labels = '', 
        col = bmmb::cols[real_cat+1], ylim = c(-8,8))
text (1,7,"Boy category speaker intercepts", pos=4,cex=1.4)

brmplot(sranef[,,1], labels = '', col = bmmb::cols[real_cat+1], ylim = c(-8,8))
text (1,7,"Girl category speaker intercepts", pos=4,cex=1.4)

brmplot(sranef[,,2], labels = '', col = bmmb::cols[real_cat+1], ylim = c(-8,8))
text (1,7,"Man category speaker intercepts", pos=4,cex=1.4)

brmplot(sranef[,,3], labels = '', col = bmmb::cols[real_cat+1], ylim = c(-8,8))
text (1,7,"Woman category speaker intercepts", pos=4,cex=1.4)

```

Here is what we believe is happening. Think of the female response plane with a specific intercept, VTL slope and f0 slope. If female speaker categorizations were very predictable based on the value of this plane at a given location, all the female speaker effects would be zero or near zero. This is because if the score based on the plane explains classification, there is nothing left for the speaker intercept to explain. We can see this sort of behavior for adult male speakers: Adult male speakers are mostly easy to identify because of their unusually low voice f0.

In contrast, consider a situation where individual female speakers fall way off the plane, in a seemingly random but consistent manner. For example, imagine a female speaker whose score is way higher than the plane says it should be, but that every listener seems to behave this way for this speaker. This would mean that this is a consistent classification for this voice, that cannot be explained by the score according to the plane. In other words, the classification cannot be predicted based on the linear combination of voice VTL and f0. In such a situation, this consistent classification would be explained by the speaker intercept. Effectively, this tells your model "use the general female plane, but move it up/down this much specifically for this person". Why are we moving it up/down for this person? Our model can't tell us, however, it can tell us that the up/down adjustment is consistent for the speaker across listeners and improves model performance.

We can think about what these speaker effects might reflect. The information regarding gender and age in voices is subtle and complicated, and likely reflects subtle stylistic and prosodic cues. Basically, sounding 'feminine' and 'masculine' is much more complicated than just f0 or VTL. This is analogous to the fact that women tend to be shorter than men, but it would be ridiculous to suggest that masculinity/femininity are entirely predictable based on the height of a person. Size is perhaps an aspect of perceived femininity/masculinity but the whole of it is substantially more complicated. 

We again consider our model prediction accuracy, but this time consider predictions without any random effects.

```{r}
predicted_no_re = apply (multi_pred[,1,],1,which.max)
predicted_category_no_re = c("b","g","m","w")[predicted]
```

The picture without random effects is much more grim. Correct prediction is not *too* bad (relative to chance at 25%), however, some of the individual categories are predicted very poorly. As expected, accurate prediction of woman responses is particularly bad with only 22% of female responses being accurately predicted as such. 

```{r}
# overall correct
mean (predicted_category_no_re == exp_data$C)

# correct predictions by category
tab = xtabs (~ exp_data$C + predicted_category_no_re)
diag(tab) / rowSums(tab)
```

### Refitting the model without speaker random effects

The results of our previous model suggest that the inclusion of speaker random effects may lead to some unintended consequences. Model prediction is good as long as we include the speaker random effects. However, these do not let us understand the prediction of new speakers. Further, the territorial map we can generate using the figure is a bit unreliable because of its reliance on the speaker random effects included in the model. We will try fitting the model without speaker effects to see if we get a territorial map that is a better match for the listener judgments. We use the same priors we used before, and fit the same model save for the absence of speaker effects from our fromula: 

```{r, eval = FALSE}
model_multinomial_noS = 
  brms::brm (y|trials(size) ~ vtl+f0 + (vtl+f0|L), data=exp_data, 
             family=multinomial(), chains=4, cores=4, warmup=1000, iter = 5000, 
             thin = 4, prior = multinomial_prior)
```
```{r, eval = FALSE}
model_multinomial_noS = bmmb::get_model ("../models/12_model_multinomial_noS.RDS")
```
```{r}
#  saveRDS (model_multinomial_noS, "../../models/12_model_multinomial_noS.RDS")
model_multinomial_noS = readRDS ("../models/12_model_multinomial_noS.RDS")
```

```{r, cache = TRUE}
multi_pred_noS = predict (model_multinomial_noS, re_formula = NA)
multi_pred_re_noS = predict (model_multinomial_noS)
```

We just straight to plotting the territorial map represented by this model, again comparing listener judgments to model predictions with and without random effects (\@ref(fig:F12-6)). We can wee that the territorial maps in the figure seem to be a better match to the data.

```{r F12-6, fig.height = 3, fig.width=8, fig.cap = "boys (b), girls (g), men (m), and women (w).", echo = FALSE}

################################################################################
### Figure 12.6
################################################################################


params = fixef (model_multinomial_noS)
params = fixef (model_multinomial_noS, summary = FALSE)
params = cbind (colMeans (params[,1:3]), 
                colMeans (params[,c(4,6,8)]),
                colMeans (params[,c(5,7,9)]))

params = rbind (c(0,0,0), params[1:3,])

tab = table (exp_data$S, exp_data$C)
mod_cat = apply (tab, 1,which.max)

cats = apply(multi_pred_noS[,1,],1,which.max)
table (exp_data$C, cats)
tab2 = table (exp_data$S, cats)
mod_cat2 = apply (tab2, 1,which.max)

cats = apply(multi_pred_re_noS[,1,],1,which.max)
table (exp_data$C, cats)
tab2 = table (exp_data$S, cats)
mod_cat3 = apply (tab2, 1,which.max)


par (mfrow = c(1,3), mar = c(.0,.0,.21,.2),oma=c(4,4,2,.1))

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],ylab="")

maps_noS = make_map (t(params))

mtext (side=3, text = "Listener Judgments", line = 0.5)

plot_map (maps_noS, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat2],ylab="",yaxt="n")
plot_map (maps_noS, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat3], cex = 2)
mtext (side=3, text = "Model Predictions (with RE)", line = 0.5)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat3],ylab="",yaxt="n")
plot_map (maps_noS, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat2], cex = 2)
mtext (side=3, text = "Model Predictions (no RE)", line = 0.5)

mtext (side=1, "Centered vocal tract length (cm)", outer = TRUE, line=2.5)
mtext (side=2, "Centered f0 / 100 (Hz)", outer = TRUE, line=2.5)

```

Figure \@ref(fig:12-7) compares the territorial maps represented by our models with (left) and without (right) speaker information. In addition to being a better fit to the data, we think the new territorial maps make more 'sense'. This is because the map with speakers suggests that the difference between women and boys was almost entirely due to f0, with women being associated with the higher f0. This is despite boys being associated with shorter VTLs than adult females *and* a higher f0. The new map has basically no effect for f0 between these categories and makes it a primarily VTL difference, which is backed up by the distributions of these characteristics between these speaker types. 

```{r F12-7, fig.height = 3, fig.width=8, fig.cap = "(left) Territorial maps indicating which sections of the stimulus space are associated with: Boys (turquoise), girls (yellow), men (green), and women (red). Points represent individual speakers, colors represent modal classifications using the same colors as the territories.", echo = FALSE}

################################################################################
### Figure 12.7
################################################################################


params = fixef (model_multinomial_noS)
params = fixef (model_multinomial_noS, summary = FALSE)
params = cbind (colMeans (params[,1:3]), 
                colMeans (params[,c(4,6,8)]),
                colMeans (params[,c(5,7,9)]))

params = rbind (c(0,0,0), params[1:3,])

tab = table (exp_data$S, exp_data$C)
mod_cat = apply (tab, 1,which.max)

cats = apply(multi_pred_noS[,1,],1,which.max)
tab2 = table (exp_data$S, cats)
mod_cat2 = apply (tab2, 1,which.max)

cats = apply(multi_pred_re_noS[,1,],1,which.max)
tab2 = table (exp_data$S, cats)
mod_cat3 = apply (tab2, 1,which.max)


par (mfrow = c(1,2), mar = c(.0,.0,.21,.2),oma=c(4,4,2,.1))

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat],ylab="")

#maps_noS = make_map (t(params))

mtext (side=3, text = "model_multinomial", line = 0.5)

plot_map (maps, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)

plot(model_multinomial$data$vtl,model_multinomial$data$f0, ylim = c(-1.25,1.25), 
     xlim = c(-2.5,3), pch = 16, col = bmmb::cols[2:5][mod_cat2],ylab="",yaxt="n")
plot_map (maps_noS, colors = adjustcolor (bmmb::cols[2:5], alpha.f=.2), new=FALSE)
points(model_multinomial$data$vtl,model_multinomial$data$f0, pch = 16, col = bmmb::cols[2:5][mod_cat], cex = 2)
mtext (side=3, text = "model_multinomial_noS", line = 0.5)

mtext (side=1, "Centered vocal tract length (cm)", outer = TRUE, line=2.5)
mtext (side=2, "Centered f0 / 100 (Hz)", outer = TRUE, line=2.5)

```

One concern with omitting the speaker effects is that our model now thinks all observations for any one speaker are independent. Based on what we saw in figure (intercepts) we know that this is defnitely not the case. Instead, individual speakers were identified as one or another category consistently, indicating that these judgments were related across listeners. Tis can potentially have the effect of artificially decreasing our confidence intervals, as we see in chapter 6 (heck out details, it was for A1). Figure \@ref(fig:12-8) compares the fixed effects between our two models, suggesting that the omission of the speaker effects has not had a large effect on our parameters. The two largest differences are for the woman category: The intercept went from slightly negative to slightly positive, nd the effect for f0 went from zero to positive. 

```{r F12-8, fig.height = 3, fig.width=8, fig.cap = "-- ", echo = FALSE}
################################################################################
### Figure 12.8
###############################################################################

par (mar = c(4,8,1,1))
brmplot (fixef(model_multinomial)[c(1,4,5,2,6,7,3,8,9),], las = 2,
         horizontal = FALSE,col = 0, xlim = c(-5,6))
abline (h = seq(1,10),lty=3,col="grey")
brmplot (fixef(model_multinomial)[c(1,4,5,2,6,7,3,8,9),], add = TRUE,
         nudge = -0.2, labels = "", horizontal = FALSE, pch=16,
         col = rep(bmmb::cols[3:5],each=3))
brmplot (fixef(model_multinomial_noS)[c(1,4,5,2,6,7,3,8,9),], add = TRUE,
         nudge = 0.2, labels = "", horizontal = FALSE, pch=17,
         col = rep(bmmb::cols[3:5],each=3))

legend (2.5,9,legend =c("With Speaker","No Speaker"),bty='n',
        pch=16:17,pt.cex=1.3)
```

We again find the maximum a posteriori speaker classification and get a label for each trial. 
```{r}
predicted_noS = apply (multi_pred_re_noS[,1,],1,which.max)
predicted_category_noS = c("b","g","m","w")[predicted_noS]
```

And calculate correct classifications overall and by category. Performance is not as good as the model with speaker effect when random effects are included (82%) but not as bad as for the same model when random effects are not included (59%). In addition, we see very good classification of all categories except for 'boy'. 

```{r}
# overall correct
mean (predicted_category_noS == exp_data$C)

# correct predictions by category
tab = xtabs (~ exp_data$C + predicted_category_noS)
diag(tab) / rowSums(tab)
```

Importantly, we see that classification barely changes when random effects are not included, except for boy classifications which drop even below chance. 

```{r}
predicted_noS_no_re = apply (multi_pred_noS[,1,],1,which.max)
predicted_category_noS_no_re = c("b","g","m","w")[predicted_noS_no_re]

# overall correct
mean (predicted_category_noS_no_re == exp_data$C)

# correct predictions by category
tab = xtabs (~ exp_data$C + predicted_category_noS_no_re)
diag(tab) / rowSums(tab)
```

### Answering our research questions

We can use our models to answer the question we posed above:

Q1) Can we use speaker f0 and VTL to predict their apparent speaker category?

Yes, we can use speaker f0 and VTL to predict apparent speaker with relative accuracy. If we consider a baseline correctness by chance along of 25%, then our classification of 72% from two predictors (with no random effects) isn't bad at all. However, the importance of the speaker random effects for female speakers strongly suggests that there is 'something else' being used to identify women as women, apart from VTL and f0. So, our first model tells us that we should probably try to understand what that 'something else' is. The speaker random effects are not particularly useful for understanding the categorization of new speakers. However, understanding what causes the variation in these random effects is. Our model tells us that even though we know there is something else to it, we can still pretty much predict categorization from just these two predictors. So, the first model may be better to really try to understand what listeners are doing when they classify while the second model may be better to understand classification from just f0 and VTL. 

## Ordinal (logistic) regression

Ordinal logistic regression involves the prediction of ordered categories. Although in some senses ordinal regression is 'simpler' than multinomial regression, we decided to present it after multinomial regression. This is because multinomial regression is just a generalization of logistic regression, which was discussed in detail in chapter 10. In contrast, ordinal regression, although related to (dichotomous) logistic regression, is in many ways conceptually its own thing. We will present one way of thinking about logistic regression however, as usual, there are many others. 

A simple example of an ordinal variable is first, second, and third place in a race. These values are categorical and not numerical. For example fourth place is not 'double' anything with respect to second place (i.e., $2 \times second \neq fourth$). However, there is clearly an inherent ordering in the categories such that first < second < third < fourth < and so on. A common experimental example of ordered categorical data arises from survey data that asks listeners to respond to questions using a small number of discrete, categorical choices (e.g., a scale from one to five). The reason this is not a truly quantitative variable is because there are a limited number of discrete choices with nothing 'in between', and it is not necessarily the case that, for example, the second choice implied double the quantity of the second. These limitations mat result in subjects, for example, reserving categories 1 and 5 for 'extreme' cases in a way that would not arise for truly quantitative data. 

We don't actually have any ordinal variables in our experiment, but we still wanted to provide an example of an ordinal analysis. To do this, we're going to make a fake ordinal variable that we think is actually relatively plausible. Below we see a boxplot of apparent height judgments organized by apparent speaker category. Note that apparent boys and girls are rated at about the same apparent height, apparent women are judged to be a little taller than that, and apparent men are judged to be a little taller than women. Based on this, we could think of our speaker classifications as classifications of speakers into small (boys, girls), medium (women), and large (men) speakers. For example, based on the boxplot below we might imagine that if we *had* asked listeners to label speakers small medium and large, they would have labelled most apparent children as small, most apparent women as medium, and most apparent men are large. In any case, we are only presenting this as an example and are only interested in establishing that the conversion of speaker category into an ordinal small < medium < large variable is not completely unfounded.



```{r F12-9, fig.height = 3, fig.width=8, fig.cap = " -- ", echo = FALSE}

################################################################################
### Figure 12.9
################################################################################

exp_data$SG = 0
exp_data$SG[exp_data$C=='m'] = 3
exp_data$SG[exp_data$C=='w'] = 2
exp_data$SG[exp_data$C=='g'] = 1
exp_data$SG[exp_data$C=='b'] = 1


x = seq (100,200,.1)
y = x

par (mfrow = c(1,2), mar = c(.1,.1,.1,.1), oma = c(4,4,.5,.5))

boxplot (height_original ~ SG, data = exp_data,col=bmmb::cols[c(9,11,12)])

tmp = aggregate (height_original ~ SG, data = exp_data, FUN = mean)
abline (h = mean (tmp[1:2,2]), lwd = 6, col = bmmb::cols[8])
abline (h = mean (tmp[2:3,2]), lwd = 6, col = bmmb::cols[10])
boxplot (height_original ~ SG, data = exp_data,col=bmmb::cols[c(9,11,12)],
         add = TRUE)

plot (x,y, yaxt='n',type = 'l', xlim = c(120,190),ylim = c(120,190))
rect (100,100,200,mean(tmp[1:2,2]), col = bmmb::cols[9])
rect (100,mean(tmp[1:2,2]),200,mean(tmp[2:3,2]), col = bmmb::cols[11])
rect (100,mean(tmp[2:3,2]),200,400, col = bmmb::cols[12])
lines (x,y, lwd=4, col = bmmb::cols[2])

points (c(140,160,180),c(140,160,180),pch=16,col=bmmb::cols[2],cex=2)
abline (h = mean (tmp[1:2,2]), lwd = 6, col = bmmb::cols[8])
abline (h = mean (tmp[2:3,2]), lwd = 6, col = bmmb::cols[10])



```


```{r F12-10, fig.height = 3, fig.width=8, fig.cap = " -- ", echo = FALSE}

################################################################################
### Figure 12.10
################################################################################}

x = seq (-35,35,.1)
y = dlogis(x,0,5)

x_2 = seq (100,230,.1)
y_2 = x_2


par (mfrow = c(1,1), mar = c(4,.1,.1,.1), oma = c(.5,.5,.51,.51))

plot (x,y, yaxt='n',type = 'l', xlim = c(120,190),ylim = c(105,215),
      xlab = "Apparent Height (cm)")
rect (100,100,200,mean(tmp[1:2,2]), col = bmmb::cols[9])
rect (100,mean(tmp[1:2,2]),200,mean(tmp[2:3,2]), col = bmmb::cols[11])
rect (100,mean(tmp[2:3,2]),200,400, col = bmmb::cols[12])
lines (x_2,y_2, lwd=4, col = bmmb::cols[2])

spot = 160
lines (-y*150+spot, x+spot, ylim = c(120,190), xlim = c(-.35,0), xaxs='i',type='l',lwd=2)
lines (rep(spot,length(x)),x+spot,type="l",lwd=2)
points (spot,spot,pch=16,col=bmmb::cols[2],cex=2)
spot = 140
lines (-y*150+spot, x+spot, ylim = c(120,190), xlim = c(-.35,0), xaxs='i',type='l',lwd=2)
lines (rep(spot,length(x)),x+spot,type="l",lwd=2)
points (spot,spot,pch=16,col=bmmb::cols[2],cex=2)

spot = 180
lines (-y*150+spot, x+spot, ylim = c(120,190), xlim = c(-.35,0), xaxs='i',type='l',lwd=2)
lines (rep(spot,length(x)),x+spot,type="l",lwd=2)
points (spot,spot,pch=16,col=bmmb::cols[2],cex=2)

text (125,c(140,163,195), c("Small", "Medium", "Large"),cex=1.1)

abline (h = mean (tmp[1:2,2]), lwd = 6, col = bmmb::cols[8])
abline (h = mean (tmp[2:3,2]), lwd = 6, col = bmmb::cols[10])
```


Like multinomial regresion, ordinal logistic regression involves modeling a latent variable. 

Just like multinomial regression, ordinal regression involves modeling a latent variable. 

- weird latent variable
- unpredictable decision based on some choice. the distribution is the range of outcomes. 
- slide distribution like in regular regression
- except e assume logistic. 
- cumulative distribution function

- rather than one intercept, we have n-1 for n levels
- intercepts are fixed aspects of the model
- we model mu, and this changes responses as mu slides across intercepts
- you can also model the sd parameter
- there is also a normal model, but we will not be discussing here
- in practice little to no difference just like probit and logit for logistic



```{r}
# Fit the model yourself
set.seed (1)
options (contrasts = c('contr.sum','contr.sum'))

model_ordinal_small = brms::brm (SG ~ height, data=exp_data, family=cumulative("logit"), 
           chains=4, cores=4, warmup=1000, iter = 5000, thin = 4,
           prior = c(set_prior("student_t(3, 0, 3)", class = "Intercept"),
                     set_prior("student_t(3, 0, 3)", class = "b")))

#  saveRDS (model_ordinal_small, "12_model_ordinal_small.RDS")
```


```{r}
model_ordinal = readRDS ("../models/12_model_ordinal.RDS")
```




```{r}
par (mfrow = c(1,1), mar = c(4,4,1,1))

boxplot (height_original ~ C, data = exp_data,col=bmmb::cols[2:5])
abline (h = 45.42 * (1/0.29))
abline (h = 48.53 * (1/0.29))

int_height = exp_data$height_original

int_height[int_height<111] = 111
int_height[int_height>190.2] = 190

int_height = round(exp_data$height_original/10)

tmp_tab = t(table (exp_data$SG, int_height))

tmp_tab = tmp_tab / rowSums(tmp_tab)

mosaicplot (tmp_tab, col = 2:4)
```


```{r}
x = 10*(11:19)
predds = cbind (round (plogis (151, x),5), 
                round ((plogis (168, x)-plogis (151, x)),5),
                round (1-plogis (168, x), 5))


mosaicplot (predds, col = 2:4)


```





### Data and research questions



```{r, warning=FALSE, message=FALSE}
library (brms)
library (bmmb)
options (contrasts = c('contr.sum','contr.sum'))

data (exp_data)
exp_data = exp_data[exp_data$R=='a',]
```

We create a variable called `F`, which will equal our dependent variable. This variable equals 1 when listeners indicated hearing a female speaker and 0 when listeners indicated a male speaker. We will predict this using a single quantitative predictor, speaker VTL, which we center below. 

```{r}
exp_data$F = as.numeric (exp_data$G == 'f')
exp_data$vtl_original = exp_data$vtl
exp_data$vtl = exp_data$vtl - mean (exp_data$vtl)


exp_data$height_original = exp_data$height
exp_data$height = exp_data$height - mean (exp_data$height)


exp_data$f0_original = exp_data$f0 
exp_data$f0 = exp_data$f0 - mean(exp_data$f0)
exp_data$f0 = exp_data$f0 / 100
```


```{r}
exp_data$SG = 0
exp_data$SG[exp_data$C=='m'] = 3
exp_data$SG[exp_data$C=='w'] = 2
exp_data$SG[exp_data$C=='g'] = 1
exp_data$SG[exp_data$C=='b'] = 1
```


```{r}
tmp = aggregate (height ~ C + L, data = bmmb::exp_data, FUN = mean)

plot(tmp[tmp$C=='b',"height"]-tmp[tmp$C=='g',"height"])
```



### Description of the model


### Fitting and interpreting the model


```{r}
# Fit the model yourself
set.seed (1)
options (contrasts = c('contr.sum','contr.sum'))

model_ordinal = brms::brm (SG ~ vtl+f0 + (vtl+f0|L) + (1|S), data=exp_data, family=cumulative("logit"), 
           chains=4, cores=4, warmup=1000, iter = 5000, thin = 4,
           prior = c(set_prior("student_t(3, 0, 3)", class = "Intercept"),
                     set_prior("student_t(3, 0, 3)", class = "b"),
                     set_prior("student_t(3, 0, 3)", class = "sd"),
                     brms::set_prior("lkj_corr_cholesky (2)", class = "cor")))

#  saveRDS (model_ordinal, "12_model_ordinal.RDS")
```


```{r}
model_ordinal = readRDS ("../models/12_model_ordinal.RDS")
```






```{r}
preds = predict (model_ordinal, re_formula = NA)
```

```{r}

fixed = brms::fixef(model_ordinal)

x = model_ordinal$data$vtl * fixed[3,1] + model_ordinal$data$f0  * fixed[4,1]

predds = cbind (round (plogis (fixed[1,1], x),5), 
                round ((plogis (fixed[2,2], x)-plogis (fixed[1,1], x)),5),
                round (1-plogis (fixed[2,2], x), 5))

head (predds)
head (preds)

       
```

```{r}
tapply (bmmb::exp_data$vtl, bmmb::exp_data$C, mean)
tapply (bmmb::exp_data$f0, bmmb::exp_data$C, mean)

par (mar = c(.2,.2,.2,.2), oma = c(3,3,.5,.5), mfrow = c(4,4))
curve (dlogis (x), from=-7,to=7)
abline (v = fixed[1:2])
```



### Answering our research questions










## bench

```{r F12-00, fig.height = 4, fig.width=8, fig.cap = " -- ", echo = FALSE}

################################################################################
### Figure 12.00
################################################################################

exp_data$SG = 0
exp_data$SG[exp_data$C=='m'] = 3
exp_data$SG[exp_data$C=='w'] = 2
exp_data$SG[exp_data$C=='g'] = 1
exp_data$SG[exp_data$C=='b'] = 1

par (mfrow = c(3,5), mar = c(.1,.1,.1,.1), oma = c(4,4,.5,.5))

xaxts = c("n","n","n","n","n","n","n","n","n","n","s","s","s","s","s")
yaxts = c("s","n","n","n","n","s","n","n","n","n","s","n","n","n","n")

for (i in 1:15){
  boxplot (height ~ SG, data = exp_data[exp_data$L==i,],col=bmmb::cols[c(9,11,12)],
           xaxt = xaxts[i], yaxt = yaxts[i])
  tmp = aggregate (height ~ SG, data = exp_data[exp_data$L==i,], FUN = mean)
  abline (h = mean (tmp[1:2,2]), lwd = 2, col = bmmb::cols[8])
  abline (h = mean (tmp[2:3,2]), lwd = 2, col = bmmb::cols[10])
  boxplot (height ~ SG, data = exp_data[exp_data$L==i,],col=bmmb::cols[c(9,11,12)],
           xaxt = xaxts[i], yaxt = yaxts[i], add = TRUE)
}


```