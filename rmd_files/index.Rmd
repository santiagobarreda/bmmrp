--- 
title: "Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R"
author: "Santiago Bareda and Noah Silbert"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
highlight: tango
url: 'http\://santiagobarreda.com'
description: "Bayesian Models for Repeated-Measures"
geometry: margin=2cm
always_allow_html: true
---

# Preface

This book presents an introduction to the statistical analysis of repeated-measures data using Bayesian multilevel regression models. Our approach is to fit these models using the `brms` package (cite) and the `stan` programming language (cite) in R (cite). This book introduces mathematical and modeling concepts in plain English, and focuses on understanding concepts and the visual/geometric consequences of different regression model structures rather than on rigorous mathematical explanations of these. 

Statistical modeling is as much a coding challenge as it is a mathematical challenge. As any programmer with some experience knows, copying existing scripts and modifying them slightly is an excellent way to learn to code, and often a new skill can be learned shortly after an understandable example can be found. To that end, rather than use a different toy data set for every new topic introduced, this book presents a set of fully worked analyses involving increasingly complicated models fit to the same experimental data. 

We were both trained linguists and the experiment we analyze in this book is an experiment investigating a 'linguistic' research question. However, we don't think of this book as specifically for linguists or about linguistics. The sorts of models described in this book are useful for researchers in linguistics, however, they are also useful for many researchers in psychology, cognitive science, and many related (and unrelated) disciplines. In general, the information in this book will be useful to anyone that has similar sorts of data that they want to analyze regardless of the specifics of their research areas.

## Bayesian Multilevel models and repeated measures data

A more complete explanation of the following is presented in chapters 2 to 4, however we can say something about this here. A Bayesian model is one which bases reasoning on *posterior probabilities* rather than *likelihoods*. A multilevel model is one in which both you model variation in both your data and your parameters. There a 'multi(ple) levels' because there is variation in the data (conceptually 'below'), and in the parameters of the probability distributions (conceptually 'above'). A Bayesian multilevel model puts these concepts together and uses posterior probabilities to make inferences about variation in data and in parameters. 

Repeated measures data is data where multiple observations come from the same 'source' (discussed in more detail in section \@ref(c4-multilevel)). Basically, any time you have data with more than one observation from any given source, you have repeated measures data. Repeated measures data is very common in linguistics, and the norm in many linguistic sub-fields (phonetics, variationist sociolinguistics, psycholinguistics, etc.). 

For example, you might ask participants in an experiment to hit a button as soon as they hear a buzz, and repeat this for 100 trials per participant. Repeated measures data can naturally lead to independent data level variation (the lower level) and parameter level variation (the upper level). For example, the reactions times to hit a button vary within-participants (the data/lower level), but average reaction times will also likely vary between participants (the upper/parameter level). Using multilevel models to analyze repeated measures data lets you independently model these two levels of variation. Using a *Bayesian* multilevel models allows you to build flexible models that provide you will all sorts of useful information. 

One obstacle to the proper analysis of repeated measures data is that this requires models that are relatively 'complicated' and therefore usually not taught at the beginner level. In order to learn how to model repeated measures data, a student is often first expected to learn ‘traditional’ statistical approaches and designs. After this foundation is laid, the student can then move to the sorts of models they can *actually* use for their work, mainly multilevel models that can handle repeated-measures data. This approach has several drawbacks: It takes a long time, spends substantial energy on statistical approaches that most will rarely if ever use in their work, and front-loads difficult and abstract concepts before students can start working with data they really understand. As a result, students may become discouraged, become convinced that they’re ‘not good at math’, and may not realize how much they already intuitively understand about statistics.

This book starts at multilevel models and never looks back. It focuses on a realistic and complicated data set, and focuses from (nearly) the start (chapter 4) on realistic models that could actually be used in publishable research today.

## Whats missing from this book

There was a time when every Spider-Man movie started with Peter Parker being bitten by the spider and getting his powers, costume, etc. Filmmakers didn't trust that viewers know how Spider-Man got his powers, or that they could easily get this information somewhere, and so chose to spend precious movie minutes retelling what is perhaps the least interesting Spider-Man story. The problem is, the longer you spend on Peter Parker getting bit the less time you can spend on Spider-Man can swinging between buildings at high velocity. In the same way, many statistics books tell the statistics 'origin' story over and over to the detriment of getting to the sorts of really interesting model people actually need. In other cases, when complicated models are discussed, they are presented in a style and language only appropriate for an advanced reader. 

This book tries to find the 'Goldilocks zone' between too much and too little information: This book basically assumes you know who Spider-Man is or can easily find the origin story. It omits a basic introduction to R in addition to a detailed explanation of how the code used in the book works. It also omits a lot of explanation that is required to 'really' understand topics like, for example, correlation. However, there are dozens or hundreds of excellent introductions to R, and hundreds or thousands of places to find good information about basic statistical concepts like correlation. Rather than use precious pages on really getting into every topic that comes up, this book aim to get you flying between buildings at high velocity (or the statistical equivalent) as soon as possible. 

As a result, this book is narrowly focused on a specific subject: Introduction to Bayesian multilevel models for repeated measures data. It's not a general introduction to statistics nor to Bayesian models, or any number of other things. This narrow(ish) focus is both a strength and a weakness. We feel that it is  strength because it allows this books to cover material and provide examples of the sorts of models that are frequently needed in linguistic, social science, and psychology research but which, at the same time, rarely appears in statistics textbooks. It's a weakness because it means the book is to some extent 'incomplete' in terms of providing a full introduction to the field of (Bayesian) statistics, as noted above. As a result, the ideal reader will know a little about statistics or have some resource on introductory statistics on hand to look up things you might not know or understand. Similarly, the book does spend much time explaining how the things we do in R work, though examples of everything are given and the code is commented and made as transparent as we could. 

At the other end of the spectrum, this book is also missing many 'more complicated' but useful topics. For example, the book is entirely focused on linear modeling and does not discuss non linear modeling. We also do not discuss missing data, multivariate dependent variables, or transformations of the dependent variables, among other topics. All of these things, and more, are easily doable using `stan` and `brms`. 


## It takes a village of books {#c0-a-village}

- book recomendations

 

## Statistics as Procedural knowledge

Although statistical knowledge might seem like declarative knowledge, in many ways it is more similar to procedural knowledge. You would never read a chapter from a French textbook once and expect to have memorized all the vocabulary and irregular forms. Similarly, you would never practice a piano piece a single time and assume that you are just 'bad at the piano' because you can't play it flawlessly. And yet a student may read a chapter from this book once and feel disappointing that they do not already understand the concepts, or perhaps blame the book for being unclear.

We suggest thinking of acquiring statistical knowledge like learning a language, or musical instrument. It is normal, and in fact should be expected, that the reader will need to read some parts of the text multiple times, and *practice*, before being able to really *understand* all of the concepts presented here. We do not think getting good at statistics is about 'brain power' (whatever that is), as much as it is about a desire to learn, a genuine interest in the topics, and perseverance. In this way, learning statistics is very much like learning a language or an instrument. Buying a piano does make you good at the piano, only practice does. Reading a grammar of Spanish or even moving to Spain will not teach you Spanish, only getting out there and talking to people will. 

To that end, this book provides examples of analyses and data that can be re-analyzed in many similar yet different ways. As a result, readers have an opportunity to fit several parallel models, interpret them, make sure they understand them, and so on. In doing so, and in returning to challenging content periodically to 'practice', we hope that learners can get some 'practice' in with the sorts of models they need to fit, in order to support their understanding of the content in the book. 

### Practice vs brain power

John von Neumann was perhaps the greatest mathematical mind the world has ever seen. A glance at his contributions to mathematics on his Wikipedia page reveals an astonishing breadth and depth of mathematical abilities. Some quotes from his contemporaries about von Neumann:

  * "I have sometimes wondered whether a brain like von Neumann's does not indicate a species superior to that of man" - Hans Bethe 

  * "Johnny was the only student I was ever afraid of. If in the course of a lecture I stated an unsolved problem, the chances were he'd come to me at the end of the lecture with the complete solution scribbled on a slip of paper." - George Pólya 

And yet von Neumann is said to have said the following to a graduate student who complained about not *understanding* some mathematical abstraction:

  * "Young man, in mathematics you don't *understand* things. You just get *used to them*" - John von Neumann

This was von Neumann's experience, it has certainly been our [@@ SB - noah? Or are you superior to me and johnny V?] experience, and it will likely be yours. Some things will make no sense, and then one day they will. It won't be clear when they did or why they did, but all of the sudden a combination of repetition, practice and *time* will make the difference. It is likely that no amount or thinking and raw brain power alone will help you *understand* statistics right away on a first pass. 

That being said, the things we talk about in this chapter will be come up in every chapter, so if things don't all make sense right now that's fine, you will have plenty of chances to *get used to them*. Things will make more sense bit by bit as we learn how to use more and more complicated models. After reading a few chapters you should come back and read earlier chapter again (and again). You may notice that a lot of things are discussed in this chapter that you did not notice the first time you read it. 

## How to use this book

The design of this book centers around the ability of readers to repeat and modify the information in the book. This is in order to facilitate the *practice* of the concepts presented in the book, in addition to simply reading each chapter. 

The chapters of this book, from chapter 3 on, are organized in terms of regression model components, e.g., intercepts, slopes, interactions, 'random' effects, and so on. We will discuss how these relate to experimental designs, statistical concepts, and the geometry of figures based on the data and model coefficients. In each chapter, we will learn how to use these components to ‘build’ progressively more complicated models to answer more complicated research questions. An analogy may be drawn to learning to be a carpenter. Building a chair requires knowledge regarding the construction of several different components (i.e., the flat seat, the cylindrical legs, supports for stability, etc.). Learning to build a chair requires that the carpenter first learns to make the individual components, and then learns to put them together in a specific way. 

The example analyses in each chapter are each presented with the general structure of a lab report or academic write up. This is done as a pedagogical tool to help readers ‘copy’ the work they see in each chapter and modify this to suit their needs. The general structure for the presentation of new model components: 1) Introduce a type of research question (e.g., are the means of these groups the same?). Explain how this relates to model design concepts and give an example of real-world data associated with this sort of design. 2) Present the structure of a model that can be used to analyze the data, and to answer this sort of research question. Fit the model. 3) Interpret the model output and coefficients. Explain what all the information presented in the model output means, explain how coefficients relate to our research question. 4) Beyond coefficient values, discuss what the model ‘means’ and attempt to provide an answer to our research questions based on the model. The correspond approximately to the 1) introduction, 2) methods, 3) results, and 4) discussion/conclusion sections found in a typical research paper.  

### Supplemental Resources

The code needed to follow along with all the analyses presented in the book is provided in each chapter. There is also a book website that presents the code necessary to make all the plots in the book. Finally, the book GitHub page contains `.Rmd` files containing the all the code chunks and figures code for the book. The book GitHub page also contains all the models referred to in the book and some of the data.

## Our target audience

Although we think no statistical background is needed to get something out of this book, readers will some statistical background will be in a better position to take full advantage. This book does assume a basic familiarity with R. However, the book provides fully worked examples of all analyses (including the scripts to generate all figures) so that readers only need to know enough R to follow along. We identify a few (non-exhaustive) types of people who might get good use out of this book: The self-starter, the convert, and the instructor. 

### The self starter

The self starter is a person interested in multilevel models, who has little to no background in statistics, and perhaps little to no knowledge of R. However, the self starter enjoys learning on their own, and is motivated to use Wikipedia, Stack overflow, Google, and so on in order to supplement the weaknesses of this book. In particular, self starters may benefit by 'going along for the ride' to some extent, and focusing on practicing and working through examples without expecting to *understand* everything the first time. 

### The convert

Converts are readers who are already proficient with more 'traditional' analysis methods, and may want to ‘translate’ their skills over to a Bayesian framework. As much as possible, this book adopts the 'jargon' of more 'traditional' methods, and we also provide explicit comparisons with other sorts of models in several chapters. If this sort of reader is reasonably familiar with R, and in particular if they are familiar with the `lme4` package in R, the content and examples in this book should be very accessible.  

### The instructor

We believe linguistics, and many disciplines with similar sorts of data, are in the beginning of a paradigm shift towards Bayesian statistical methods. Although we don't include many of the smaller exercises found in the typical statistics textbook, the book was written for use as a (semi) introductory book for a senior undergraduate or graduate statistics class. In addition, the data and scripts provided allow for a broad range of in class activities and out of class assignments to be easily created based on the topics covered in each chapter, and examples are given at the end of most chapters. 

In general, the exercises suggested center around the analysis and interpretation of complete models similar in structure to what is presented in each chapter. The result of this is that the exercises we suggest resemble the actual analyses that students will need to carry out when they eventually analyze their own data. For example, students can be asked to replicate an analysis from a chapter but to make some modification, analyzing a different dependent variable or reparametrizing the model in some way. Because of the open-ended nature of the data exploration and the incredible customizability of Bayesian multilevel models, assignments using the same data set and analysis scripts can easily vary from very simple to quite sophisticated. In addition, since usable models are presented from the second chapter on, students can use the course to analyze their own data, building and interpreting progressively more complicated model as the course progresses. 


## What you need installed to ue this book {#c0-installed}


In order to use this book you need to install R, which you can get at: 

If you're R installation is more than 1 year old you may want to consider updating R, and will also want to update R periodically. That's because some of the packages we will use in this book sometimes don't play nice with 'older' (relatively speaking) versions of R. If you're trinyg to do something and R crashes for no apparent reason, it may be time to update R and all your packages. 

You will also need to install (minimally) the `brms`, `devtools`, and `bmmb` packages. You can get the first two by running `install.packages('packageName')`. You can get the `bmmb` package from the package GitHub by running: 

```{R, eval = FALSE}
devtools::install_github("santiagobarreda/bmmb")
```

After installing `devtools` of course. We also recommend installing RStudio, an integrated development environment (IDE) for R. This is basically just software that makes it more convenient to use R, and it honestly *does* make it very convenient. Installing RStudio is only recommend it but we recommend it like we recommend indoor plumbing: After trying it we think you will not want to live without it. 

## Why go Bayesian?

We are not particularly interested in Bayesian statistics for their philosophical aspects, although we agree that this is interesting. Instead, we are interested in Bayesianism, and suggest you should also be, because it lets you do things that are difficult to do with other approaches, gives you information that other approaches don't, and gives you a flexibility and resilience that may be difficult to find elsewhere. Even though we think Bayesian modeling has its advantages, we are not like the man with the hammer, we do not think that every problem requires a Bayesian solution. Instead, you may find that the models in this book are best for some situations, and other sorts of models are best for other situations. 

One advantage of going Bayesian, however, is that these approaches often provide a flexibility that is difficult to find through other approaches. Returning to the woodworking analogy, learning to 'build' Bayesian models from their components lets you build exactly the 'furniture' (model) you want. In contrast, working with some traditional models feels more like going to Ikea, you can pick from a set of predetermined models, but are often constrained in terms of how these pre-built pieces can be modified. 

### Why brms?

The `brms` package is basically a useful way for us to use the `stan` programming language, the real star of the show. We could write our own models for all the of analyses presented in this book and fit them directly in `stan`. However, `brms` is a very convenient way to create, fit, and generally work with different sort of models. The `brm` function will write models for us, and these models will be written to fit as efficiently as possible. The helper functions in the package then make working with the posterior samples very simple, and work well with a wide range of other packages related to `stan`. 

However, despite the fact that this book centers entirely about the use of `brms`, we don't really think of this book as being *about* `brms`. We think this information in this book applies to modeling more generally, and is also useful for people that write their own models directly in `stan`. The main difference is these readers would need to do a lot of things 'by hand' or find other solutions to many of the things the `brms` package makes very simple to do. 

